[{"content":"<h2 id=\"-pattern-time-series\">Pattern: Time series</h2><p>The <code>APPEND</code> command can be used to create a very compact representation of a\nlist of fixed-size samples, usually referred as <em>time series</em>.\nEvery time a new sample arrives we can store it using the command</p><p>Accessing individual elements in the time series is not hard:</p><ul>\n<li><code>STRLEN</code> can be used in order to obtain the number of samples.</li>\n<li><code>GETRANGE</code> allows for random access of elements.\nIf our time series have associated time information we can easily implement\na binary search to get range combining <code>GETRANGE</code> with the Lua scripting\nengine available in Redis 2.6.</li>\n<li><code>SETRANGE</code> can be used to overwrite an existing time series.</li>\n</ul><p>The limitation of this pattern is that we are forced into an append-only mode\nof operation, there is no way to cut the time series to a given size easily\nbecause Redis currently lacks a command able to trim string objects.\nHowever the space efficiency of time series stored in this way is remarkable.</p><p>Hint: it is possible to switch to a different key based on the current Unix\ntime, in this way it is possible to have just a relatively small amount of\nsamples per key, to avoid dealing with very big keys, and to make this pattern\nmore friendly to be distributed across many Redis instances.</p><p>An example sampling the temperature of a sensor using fixed-size strings (using\na binary format is better in real implementations).</p>","link":"./alpha/commands/append.html","spaLink":"#/alpha/commands/append","title":"PATTERN: TIME SERIES"},{"content":"<h2 id=\"-pattern-real-time-metrics-using-bitmaps\">Pattern: real-time metrics using bitmaps</h2><p>Bitmaps are a very space-efficient representation of certain kinds of\ninformation.\nOne example is a Web application that needs the history of user visits, so that\nfor instance it is possible to determine what users are good targets of beta\nfeatures.</p><p>Using the <code>SETBIT</code> command this is trivial to accomplish, identifying every day\nwith a small progressive integer.\nFor instance day 0 is the first day the application was put online, day 1 the\nnext day, and so forth.</p><p>Every time a user performs a page view, the application can register that in\nthe current day the user visited the web site using the <code>SETBIT</code> command setting\nthe bit corresponding to the current day.</p><p>Later it will be trivial to know the number of single days the user visited the\nweb site simply calling the <code>BITCOUNT</code> command against the bitmap.</p><p>A similar pattern where user IDs are used instead of days is described\nin the article called “<a href=\"http://blog.getspool.com/2011/11/29/fast-easy-realtime-metrics-using-redis-bitmaps\">Fast easy realtime metrics using Redis\nbitmaps</a>“.</p>","link":"./alpha/commands/bitcount.html","spaLink":"#/alpha/commands/bitcount","title":"PATTERN: REAL-TIME METRICS USING BITMAPS"},{"content":"<h2 id=\"-performance-considerations\">Performance considerations</h2><p>In the above example of counting days, even after 10 years the application is\nonline we still have just <code>365*10</code> bits of data per user, that is just 456 bytes\nper user.\nWith this amount of data <code>BITCOUNT</code> is still as fast as any other O(1) Redis\ncommand like <code>GET</code> or <code>INCR</code>.</p><p>When the bitmap is big, there are two alternatives:</p><ul>\n<li>Taking a separated key that is incremented every time the bitmap is modified.\nThis can be very efficient and atomic using a small Redis Lua script.</li>\n<li>Running the bitmap incrementally using the <code>BITCOUNT</code> <em>start</em> and <em>end</em>\noptional parameters, accumulating the results client-side, and optionally\ncaching the result into a key.</li>\n</ul>","link":"./alpha/commands/bitcount.html","spaLink":"#/alpha/commands/bitcount","title":"PERFORMANCE CONSIDERATIONS"},{"content":"<h2 id=\"-handling-of-strings-with-different-lengths\">Handling of strings with different lengths</h2><p>When an operation is performed between strings having different lengths, all the\nstrings shorter than the longest string in the set are treated as if they were\nzero-padded up to the length of the longest string.</p><p>The same holds true for non-existent keys, that are considered as a stream of\nzero bytes up to the length of the longest string.</p><p>@return</p><p>@integer-reply</p><p>The size of the string stored in the destination key, that is equal to the\nsize of the longest input string.</p><p>@examples</p>","link":"./alpha/commands/bitop.html","spaLink":"#/alpha/commands/bitop","title":"HANDLING OF STRINGS WITH DIFFERENT LENGTHS"},{"content":"<h2 id=\"-pattern-real-time-metrics-using-bitmaps\">Pattern: real time metrics using bitmaps</h2><p><code>BITOP</code> is a good complement to the pattern documented in the <code>BITCOUNT</code> command\ndocumentation.\nDifferent bitmaps can be combined in order to obtain a target bitmap where\nthe population counting operation is performed.</p><p>See the article called “<a href=\"http://blog.getspool.com/2011/11/29/fast-easy-realtime-metrics-using-redis-bitmaps\">Fast easy realtime metrics using Redis\nbitmaps</a>“ for a interesting use cases.</p>","link":"./alpha/commands/bitop.html","spaLink":"#/alpha/commands/bitop","title":"PATTERN: REAL TIME METRICS USING BITMAPS"},{"content":"<h2 id=\"-performance-considerations\">Performance considerations</h2><p><code>BITOP</code> is a potentially slow command as it runs in O(N) time.\nCare should be taken when running it against long input strings.</p><p>For real-time metrics and statistics involving large inputs a good approach is\nto use a slave (with read-only option disabled) where the bit-wise\noperations are performed to avoid blocking the master instance.</p>","link":"./alpha/commands/bitop.html","spaLink":"#/alpha/commands/bitop","title":"PERFORMANCE CONSIDERATIONS"},{"content":"<h1 id=\"redis-administration\">Redis Administration</h1><p>This page contains topics related to the administration of Redis instances.\nEvery topic is self contained in form of a FAQ. New topics will be created in the future.</p>","link":"./alpha/topics/admin.html","spaLink":"#/alpha/topics/admin","title":"REDIS ADMINISTRATION"},{"content":"<h2 id=\"redis-administration-redis-setup-hints\">Redis setup hints</h2><ul>\n<li>We suggest deploying Redis using the <strong>Linux operating system</strong>. Redis is also tested heavily on OS X, and tested from time to time on FreeBSD and OpenBSD systems. However Linux is where we do all the major stress testing, and where most production deployments are working.</li>\n<li>Make sure to set the Linux kernel <strong>overcommit memory setting to 1</strong>. Add <code>vm.overcommit_memory = 1</code> to <code>/etc/sysctl.conf</code> and then reboot or run the command <code>sysctl vm.overcommit_memory=1</code> for this to take effect immediately.</li>\n<li>Make sure to disable Linux kernel feature <em>transparent huge pages</em>, it will affect greatly both memory usage and latency in a negative way. This is accomplished with the following command: <code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code>.</li>\n<li>Make sure to <strong>setup some swap</strong> in your system (we suggest as much as swap as memory). If Linux does not have swap and your Redis instance accidentally consumes too much memory, either Redis will crash for out of memory or the Linux kernel OOM killer will kill the Redis process.</li>\n<li>Set an explicit <code>maxmemory</code> option limit in your instance in order to make sure that the instance will report errors instead of failing when the system memory limit is near to be reached.</li>\n<li>If you are using Redis in a very write-heavy application, while saving an RDB file on disk or rewriting the AOF log <strong>Redis may use up to 2 times the memory normally used</strong>. The additional memory used is proportional to the number of memory pages modified by writes during the saving process, so it is often proportional to the number of keys (or aggregate types items) touched during this time. Make sure to size your memory accordingly.</li>\n<li>Use <code>daemonize no</code> when run under daemontools.</li>\n<li>Even if you have persistence disabled, Redis will need to perform RDB saves if you use replication, unless you use the new diskless replication feature, which is currently experimental.</li>\n<li>If you are using replication, make sure that either your master has persistence enabled, or that it does not automatically restarts on crashes: slaves will try to be an exact copy of the master, so if a master restarts with an empty data set, slaves will be wiped as well.</li>\n<li>By default Redis does not require <strong>any authentication and listens to all the network interfaces</strong>. This is a big security issue if you leave Redis exposed on the internet or other places where attackers can reach it. See for example <a href=\"http://antirez.com/news/96\">this attack</a> to see how dangerous it can be. Please check our <a href=\"/topics/security\">security page</a> and the <a href=\"/topic/quickstart\">quick start</a> for information about how to secure Redis.</li>\n</ul>","link":"./alpha/topics/admin.html","spaLink":"#/alpha/topics/admin","title":"REDIS SETUP HINTS"},{"content":"<h2 id=\"redis-administration-running-redis-on-ec2\">Running Redis on EC2</h2><ul>\n<li>Use HVM based instances, not PV based instances.</li>\n<li>Don’t use old instances families, for example: use m3.medium with HVM instead of m1.medium with PV.</li>\n<li>The use of Redis persistence with <strong>EC2 EBS volumes</strong> needs to be handled with care since sometimes EBS volumes have high latency characteristics.</li>\n<li>You may want to try the new <strong>diskless replication</strong> (currently experimental) if you have issues when slaves are synchronizing with the master.</li>\n</ul>","link":"./alpha/topics/admin.html","spaLink":"#/alpha/topics/admin","title":"RUNNING REDIS ON EC2"},{"content":"<h2 id=\"redis-administration-upgrading-or-restarting-a-redis-instance-without-downtime\">Upgrading or restarting a Redis instance without downtime</h2><p>Redis is designed to be a very long running process in your server.\nFor instance many configuration options can be modified without any kind of restart using the <a href=\"/commands/config-set\">CONFIG SET command</a>.</p><p>Starting from Redis 2.2 it is even possible to switch from AOF to RDB snapshots persistence or the other way around without restarting Redis. Check the output of the <code>CONFIG GET *</code> command for more information.</p><p>However from time to time a restart is mandatory, for instance in order to upgrade the Redis process to a newer version, or when you need to modify some configuration parameter that is currently not supported by the CONFIG command.</p><p>The following steps provide a very commonly used way in order to avoid any downtime.</p><ul>\n<li>Setup your new Redis instance as a slave for your current Redis instance. In order to do so you need a different server, or a server that has enough RAM to keep two instances of Redis running at the same time.</li>\n<li>If you use a single server, make sure that the slave is started in a different port than the master instance, otherwise the slave will not be able to start at all.</li>\n<li>Wait for the replication initial synchronization to complete (check the slave log file).</li>\n<li>Make sure using INFO that there are the same number of keys in the master and in the slave. Check with redis-cli that the slave is working as you wish and is replying to your commands.</li>\n<li>Allow writes to the slave using <strong>CONFIG SET slave-read-only no</strong></li>\n<li>Configure all your clients in order to use the new instance (that is, the slave).</li>\n<li>Once you are sure that the master is no longer receiving any query (you can check this with the <a href=\"/commands/monitor\">MONITOR command</a>), elect the slave to master using the <strong>SLAVEOF NO ONE</strong> command, and shut down your master.</li>\n</ul>","link":"./alpha/topics/admin.html","spaLink":"#/alpha/topics/admin","title":"UPGRADING OR RESTARTING A REDIS INSTANCE WITHOUT DOWNTIME"},{"content":"<h1 id=\"how-fast-is-redis\">How fast is Redis?</h1><p>Redis includes the <code>redis-benchmark</code> utility that simulates running commands done\nby N clients at the same time sending M total queries (it is similar to the\nApache’s <code>ab</code> utility). Below you’ll find the full output of a benchmark executed\nagainst a Linux box.</p><p>The following options are supported:</p><p>You need to have a running Redis instance before launching the benchmark.\nA typical example would be:</p><p>Using this tool is quite easy, and you can also write your own benchmark,\nbut as with any benchmarking activity, there are some pitfalls to avoid.</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"HOW FAST IS REDIS?"},{"content":"<h2 id=\"how-fast-is-redis-running-only-a-subset-of-the-tests\">Running only a subset of the tests</h2><p>You don’t need to run all the default tests every time you execute redis-benchmark.\nThe simplest thing to select only a subset of tests is to use the <code>-t</code> option\nlike in the following example:</p><p>In the above example we asked to just run test the SET and LPUSH commands,\nin quiet mode (see the <code>-q</code> switch).</p><p>It is also possible to specify the command to benchmark directly like in the\nfollowing example:</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"RUNNING ONLY A SUBSET OF THE TESTS"},{"content":"<h2 id=\"how-fast-is-redis-selecting-the-size-of-the-key-space\">Selecting the size of the key space</h2><p>By default the benchmark runs against a single key. In Redis the difference\nbetween such a synthetic benchmark and a real one is not huge since it is an\nin-memory system, however it is possible to stress cache misses and in general\nto simulate a more real-world work load by using a large key space.</p><p>This is obtained by using the <code>-r</code> switch. For instance if I want to run\none million SET operations, using a random key for every operation out of\n100k possible keys, I’ll use the following command line:</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"SELECTING THE SIZE OF THE KEY SPACE"},{"content":"<h2 id=\"how-fast-is-redis-using-pipelining\">Using pipelining</h2><p>By default every client (the benchmark simulates 50 clients if not otherwise\nspecified with <code>-c</code>) sends the next command only when the reply of the previous\ncommand is received, this means that the server will likely need a read call\nin order to read each command from every client. Also RTT is paid as well.</p><p>Redis supports <a href=\"pipelining\">/topics/pipelining</a>, so it is possible to send\nmultiple commands at once, a feature often exploited by real world applications.\nRedis pipelining is able to dramatically improve the number of operations per\nsecond a server is able do deliver.</p><p>This is an example of running the benchmark in a MacBook Air 11” using a\npipelining of 16 commands:</p><p>Using pipelining results in a significant increase in performance.</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"USING PIPELINING"},{"content":"<h2 id=\"how-fast-is-redis-pitfalls-and-misconceptions\">Pitfalls and misconceptions</h2><p>The first point is obvious: the golden rule of a useful benchmark is to\nonly compare apples and apples. Different versions of Redis can be compared\non the same workload for instance. Or the same version of Redis, but with\ndifferent options. If you plan to compare Redis to something else, then it is\nimportant to evaluate the functional and technical differences, and take them\nin account.</p><ul>\n<li>Redis is a server: all commands involve network or IPC round trips. It is\nmeaningless to compare it to embedded data stores such as SQLite, Berkeley DB,\nTokyo/Kyoto Cabinet, etc … because the cost of most operations is\nprimarily in network/protocol management.</li>\n<li>Redis commands return an acknowledgment for all usual commands. Some other\ndata stores do not (for instance MongoDB does not implicitly acknowledge write\noperations). Comparing Redis to stores involving one-way queries is only\nmildly useful.</li>\n<li>Naively iterating on synchronous Redis commands does not benchmark Redis\nitself, but rather measure your network (or IPC) latency. To really test Redis,\nyou need multiple connections (like redis-benchmark) and/or to use pipelining\nto aggregate several commands and/or multiple threads or processes.</li>\n<li>Redis is an in-memory data store with some optional persistence options. If\nyou plan to compare it to transactional servers (MySQL, PostgreSQL, etc …),\nthen you should consider activating AOF and decide on a suitable fsync policy.</li>\n<li>Redis is a single-threaded server. It is not designed to benefit from\nmultiple CPU cores. People are supposed to launch several Redis instances to\nscale out on several cores if needed. It is not really fair to compare one\nsingle Redis instance to a multi-threaded data store.</li>\n</ul><p>A common misconception is that redis-benchmark is designed to make Redis\nperformances look stellar, the throughput achieved by redis-benchmark being\nsomewhat artificial, and not achievable by a real application. This is\nactually plain wrong.</p><p>The redis-benchmark program is a quick and useful way to get some figures and\nevaluate the performance of a Redis instance on a given hardware. However,\nby default, it does not represent the maximum throughput a Redis instance can\nsustain. Actually, by using pipelining and a fast client (hiredis), it is fairly\neasy to write a program generating more throughput than redis-benchmark. The\ndefault behavior of redis-benchmark is to achieve throughput by exploiting\nconcurrency only (i.e. it creates several connections to the server).\nIt does not use pipelining or any parallelism at all (one pending query per\nconnection at most, and no multi-threading).</p><p>To run a benchmark using pipelining mode (and achieve higher throughput),\nyou need to explicitly use the -P option. Please note that it is still a\nrealistic behavior since a lot of Redis based applications actively use\npipelining to improve performance.</p><p>Finally, the benchmark should apply the same operations, and work in the same way\nwith the multiple data stores you want to compare. It is absolutely pointless to\ncompare the result of redis-benchmark to the result of another benchmark\nprogram and extrapolate.</p><p>For instance, Redis and memcached in single-threaded mode can be compared on\nGET/SET operations. Both are in-memory data stores, working mostly in the same\nway at the protocol level. Provided their respective benchmark application is\naggregating queries in the same way (pipelining) and use a similar number of\nconnections, the comparison is actually meaningful.</p><p>This perfect example is illustrated by the dialog between Redis (antirez) and\nmemcached (dormando) developers.</p><p><a href=\"http://antirez.com/post/redis-memcached-benchmark.html\">antirez 1 - On Redis, Memcached, Speed, Benchmarks and The Toilet</a></p><p><a href=\"http://dormando.livejournal.com/525147.html\">dormando - Redis VS Memcached (slightly better bench)</a></p><p><a href=\"http://antirez.com/post/update-on-memcached-redis-benchmark.html\">antirez 2 - An update on the Memcached/Redis benchmark</a></p><p>You can see that in the end, the difference between the two solutions is not\nso staggering, once all technical aspects are considered. Please note both\nRedis and memcached have been optimized further after these benchmarks.</p><p>Finally, when very efficient servers are benchmarked (and stores like Redis\nor memcached definitely fall in this category), it may be difficult to saturate\nthe server. Sometimes, the performance bottleneck is on client side,\nand not server-side. In that case, the client (i.e. the benchmark program itself)\nmust be fixed, or perhaps scaled out, in order to reach the maximum throughput.</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"PITFALLS AND MISCONCEPTIONS"},{"content":"<h2 id=\"how-fast-is-redis-factors-impacting-redis-performance\">Factors impacting Redis performance</h2><p>There are multiple factors having direct consequences on Redis performance.\nWe mention them here, since they can alter the result of any benchmarks.\nPlease note however, that a typical Redis instance running on a low end,\nuntuned box usually provides good enough performance for most applications.</p><ul>\n<li>Network bandwidth and latency usually have a direct impact on the performance.\nIt is a good practice to use the ping program to quickly check the latency\nbetween the client and server hosts is normal before launching the benchmark.\nRegarding the bandwidth, it is generally useful to estimate\nthe throughput in Gbit/s and compare it to the theoretical bandwidth\nof the network. For instance a benchmark setting 4 KB strings\nin Redis at 100000 q/s, would actually consume 3.2 Gbit/s of bandwidth\nand probably fit within a 10 Gbit/s link, but not a 1 Gbit/s one. In many real\nworld scenarios, Redis throughput is limited by the network well before being\nlimited by the CPU. To consolidate several high-throughput Redis instances\non a single server, it worth considering putting a 10 Gbit/s NIC\nor multiple 1 Gbit/s NICs with TCP/IP bonding.</li>\n<li>CPU is another very important factor. Being single-threaded, Redis favors\nfast CPUs with large caches and not many cores. At this game, Intel CPUs are\ncurrently the winners. It is not uncommon to get only half the performance on\nan AMD Opteron CPU compared to similar Nehalem EP/Westmere EP/Sandy Bridge\nIntel CPUs with Redis. When client and server run on the same box, the CPU is\nthe limiting factor with redis-benchmark.</li>\n<li>Speed of RAM and memory bandwidth seem less critical for global performance\nespecially for small objects. For large objects (&gt;10 KB), it may become\nnoticeable though. Usually, it is not really cost-effective to buy expensive\nfast memory modules to optimize Redis.</li>\n<li>Redis runs slower on a VM compared to running without virtualization using\nthe same hardware. If you have the chance to run Redis on a physical machine\nthis is preferred. However this does not mean that Redis is slow in\nvirtualized environments, the delivered performances are still very good\nand most of the serious performance issues you may incur in virtualized\nenvironments are due to over-provisioning, non-local disks with high latency,\nor old hypervisor software that have slow <code>fork</code> syscall implementation.</li>\n<li>When the server and client benchmark programs run on the same box, both\nthe TCP/IP loopback and unix domain sockets can be used. Depending on the\nplatform, unix domain sockets can achieve around 50% more throughput than\nthe TCP/IP loopback (on Linux for instance). The default behavior of\nredis-benchmark is to use the TCP/IP loopback.</li>\n<li>The performance benefit of unix domain sockets compared to TCP/IP loopback\ntends to decrease when pipelining is heavily used (i.e. long pipelines).</li>\n<li>When an ethernet network is used to access Redis, aggregating commands using\npipelining is especially efficient when the size of the data is kept under\nthe ethernet packet size (about 1500 bytes). Actually, processing 10 bytes,\n100 bytes, or 1000 bytes queries almost result in the same throughput.\nSee the graph below.</li>\n</ul><p><img src=\"https://github.com/dspezia/redis-doc/raw/client_command/topics/Data_size.png\" alt=\"Data size impact\"></p><ul>\n<li>On multi CPU sockets servers, Redis performance becomes dependent on the\nNUMA configuration and process location. The most visible effect is that\nredis-benchmark results seem non-deterministic because client and server\nprocesses are distributed randomly on the cores. To get deterministic results,\nit is required to use process placement tools (on Linux: taskset or numactl).\nThe most efficient combination is always to put the client and server on two\ndifferent cores of the same CPU to benefit from the L3 cache.\nHere are some results of 4 KB SET benchmark for 3 server CPUs (AMD Istanbul,\nIntel Nehalem EX, and Intel Westmere) with different relative placements.\nPlease note this benchmark is not meant to compare CPU models between themselves\n(CPUs exact model and frequency are therefore not disclosed).</li>\n</ul><p><img src=\"https://github.com/dspezia/redis-doc/raw/6374a07f93e867353e5e946c1e39a573dfc83f6c/topics/NUMA_chart.gif\" alt=\"NUMA chart\"></p><ul>\n<li>With high-end configurations, the number of client connections is also an\nimportant factor. Being based on epoll/kqueue, the Redis event loop is quite\nscalable. Redis has already been benchmarked at more than 60000 connections,\nand was still able to sustain 50000 q/s in these conditions. As a rule of thumb,\nan instance with 30000 connections can only process half the throughput\nachievable with 100 connections. Here is an example showing the throughput of\na Redis instance per number of connections:</li>\n</ul><p><img src=\"https://github.com/dspezia/redis-doc/raw/system_info/topics/Connections_chart.png\" alt=\"connections chart\"></p><ul>\n<li>With high-end configurations, it is possible to achieve higher throughput by\ntuning the NIC(s) configuration and associated interruptions. Best throughput\nis achieved by setting an affinity between Rx/Tx NIC queues and CPU cores,\nand activating RPS (Receive Packet Steering) support. More information in this\n<a href=\"https://groups.google.com/forum/#!msg/redis-db/gUhc19gnYgc/BruTPCOroiMJ\">thread</a>.\nJumbo frames may also provide a performance boost when large objects are used.</li>\n<li>Depending on the platform, Redis can be compiled against different memory\nallocators (libc malloc, jemalloc, tcmalloc), which may have different behaviors\nin term of raw speed, internal and external fragmentation.\nIf you did not compile Redis yourself, you can use the INFO command to check\nthe mem_allocator field. Please note most benchmarks do not run long enough to\ngenerate significant external fragmentation (contrary to production Redis\ninstances).</li>\n</ul>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"FACTORS IMPACTING REDIS PERFORMANCE"},{"content":"<h2 id=\"how-fast-is-redis-other-things-to-consider\">Other things to consider</h2><p>One important goal of any benchmark is to get reproducible results, so they\ncan be compared to the results of other tests.</p><ul>\n<li>A good practice is to try to run tests on isolated hardware as much as possible.\nIf it is not possible, then the system must be monitored to check the benchmark\nis not impacted by some external activity.</li>\n<li>Some configurations (desktops and laptops for sure, some servers as well)\nhave a variable CPU core frequency mechanism. The policy controlling this\nmechanism can be set at the OS level. Some CPU models are more aggressive than\nothers at adapting the frequency of the CPU cores to the workload. To get\nreproducible results, it is better to set the highest possible fixed frequency\nfor all the CPU cores involved in the benchmark.</li>\n<li>An important point is to size the system accordingly to the benchmark.\nThe system must have enough RAM and must not swap. On Linux, do not forget\nto set the overcommit_memory parameter correctly. Please note 32 and 64 bit\nRedis instances do not have the same memory footprint.</li>\n<li>If you plan to use RDB or AOF for your benchmark, please check there is no other\nI/O activity in the system. Avoid putting RDB or AOF files on NAS or NFS shares,\nor on any other devices impacting your network bandwidth and/or latency\n(for instance, EBS on Amazon EC2).</li>\n<li>Set Redis logging level (loglevel parameter) to warning or notice. Avoid putting\nthe generated log file on a remote filesystem.</li>\n<li>Avoid using monitoring tools which can alter the result of the benchmark. For\ninstance using INFO at regular interval to gather statistics is probably fine,\nbut MONITOR will impact the measured performance significantly.</li>\n</ul>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"OTHER THINGS TO CONSIDER"},{"content":"<h1 id=\"benchmark-results-on-different-virtualized-and-bare-metal-servers\">Benchmark results on different virtualized and bare-metal servers.</h1><ul>\n<li>The test was done with 50 simultaneous clients performing 2 million requests.</li>\n<li>Redis 2.6.14 is used for all the tests.</li>\n<li>Test was executed using the loopback interface.</li>\n<li>Test was executed using a key space of 1 million keys.</li>\n<li>Test was executed with and without pipelining (16 commands pipeline).</li>\n</ul><p><strong>Intel(R) Xeon(R) CPU E5520  @ 2.27GHz (with pipelining)</strong></p><p><strong>Intel(R) Xeon(R) CPU E5520  @ 2.27GHz (without pipelining)</strong></p><p><strong>Linode 2048 instance (with pipelining)</strong></p><p><strong>Linode 2048 instance (without pipelining)</strong></p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"BENCHMARK RESULTS ON DIFFERENT VIRTUALIZED AND BARE-METAL SERVERS."},{"content":"<h2 id=\"benchmark-results-on-different-virtualized-and-bare-metal-servers-more-detailed-tests-without-pipelining\">More detailed tests without pipelining</h2><p>Notes: changing the payload from 256 to 1024 or 4096 bytes does not change the\nnumbers significantly (but reply packets are glued together up to 1024 bytes so\nGETs may be slower with big payloads). The same for the number of clients, from\n50 to 256 clients I got the same numbers. With only 10 clients it starts to get\na bit slower.</p><p>You can expect different results from different boxes. For example a low\nprofile box like <em>Intel core duo T5500 clocked at 1.66 GHz running Linux 2.6</em>\nwill output the following:</p><p>Another one using a 64-bit box, a Xeon L5420 clocked at 2.5 GHz:</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"MORE DETAILED TESTS WITHOUT PIPELINING"},{"content":"<h1 id=\"example-of-benchmark-results-with-optimized-high-end-server-hardware\">Example of benchmark results with optimized high-end server hardware</h1><ul>\n<li>Redis version <strong>2.4.2</strong></li>\n<li>Default number of connections, payload size = 256</li>\n<li>The Linux box is running <em>SLES10 SP3 2.6.16.60-0.54.5-smp</em>, CPU is 2 x <em>Intel X5670 @ 2.93 GHz</em>.</li>\n<li>Test executed while running Redis server and benchmark client on the same CPU, but different cores.</li>\n</ul><p>Using a unix domain socket:</p><p>Using the TCP loopback:</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"EXAMPLE OF BENCHMARK RESULTS WITH OPTIMIZED HIGH-END SERVER HARDWARE"},{"content":"<h1 id=\"redis-clients-handling\">Redis Clients Handling</h1><p>This document provides information about how Redis handles clients from the\npoint of view of the network layer: connections, timeouts, buffers, and\nother similar topics are covered here.</p><p>The information contained in this document is <strong>only applicable to Redis version 2.6 or greater</strong>.</p>","link":"./alpha/topics/clients.html","spaLink":"#/alpha/topics/clients","title":"REDIS CLIENTS HANDLING"},{"content":"<h2 id=\"redis-clients-handling-how-client-connections-are-accepted\">How client connections are accepted</h2><p>Redis accepts clients connections on the configured listening TCP port and\non the Unix socket if enabled. When a new client connection is accepted\nthe following operations are performed:</p><ul>\n<li>The client socket is put in non-blocking state since Redis uses multiplexing and non-blocking I/O.</li>\n<li>The <code>TCP_NODELAY</code> option is set in order to ensure that we don’t have delays in our connection.</li>\n<li>A <em>readable</em> file event is created so that Redis is able to collect the client queries as soon as new data is available to be read on the socket.</li>\n</ul><p>After the client is initialized, Redis checks if we are already at the limit\nof the number of clients that it is possible to handle simultaneously\n(this is configured using the <code>maxclients</code> configuration directive, see the\nnext section of this document for further information).</p><p>In case it can’t accept the current client because the maximum number of clients\nwas already accepted, Redis tries to send an error to the client in order to\nmake it aware of this condition, and closes the connection immediately.\nThe error message will be able to reach the client even if the connection is\nclosed immediately by Redis because the new socket output buffer is usually\nbig enough to contain the error, so the kernel will handle the transmission\nof the error.</p>","link":"./alpha/topics/clients.html","spaLink":"#/alpha/topics/clients","title":"HOW CLIENT CONNECTIONS ARE ACCEPTED"},{"content":"<h2 id=\"redis-clients-handling-in-what-order-clients-are-served\">In what order clients are served</h2><p>The order is determined by a combination of the client socket file descriptor\nnumber and order in which the kernel reports events, so the order is to be\nconsidered as unspecified.</p><p>However Redis does the following two things when serving clients:</p><ul>\n<li>It only performs a single <code>read()</code> system call every time there is something new to read from the client socket, in order to ensure that if we have multiple clients connected, and a few are very demanding clients sending queries at an high rate, other clients are not penalized and will not experience a bad latency figure.</li>\n<li>However once new data is read from a client, all the queries contained in the current buffers are processed sequentially. This improves locality and does not need iterating a second time to see if there are clients that need some processing time.</li>\n</ul>","link":"./alpha/topics/clients.html","spaLink":"#/alpha/topics/clients","title":"IN WHAT ORDER CLIENTS ARE SERVED"},{"content":"<h2 id=\"redis-clients-handling-maximum-number-of-clients\">Maximum number of clients</h2><p>In Redis 2.4 there was an hard-coded limit about the maximum number of clients\nthat was possible to handle simultaneously.</p><p>In Redis 2.6 this limit is dynamic: by default is set to 10000 clients, unless\notherwise stated by the <code>maxclients</code> directive in Redis.conf.</p><p>However Redis checks with the kernel what is the maximum number of file\ndescriptors that we are able to open (the <em>soft limit</em> is checked), if the\nlimit is smaller than the maximum number of clients we want to handle, plus\n32 (that is the number of file descriptors Redis reserves for internal uses),\nthen the number of maximum clients is modified by Redis to match the amount\nof clients we are <em>really able to handle</em> under the current operating system\nlimit.</p><p>When the configured number of maximum clients can not be honored, the condition\nis logged at startup as in the following example:</p><p>When Redis is configured in order to handle a specific number of clients it\nis a good idea to make sure that the operating system limit to the maximum\nnumber of file descriptors per process is also set accordingly.</p><p>Under Linux these limits can be set both in the current session and as a\nsystem-wide setting with the following commands:</p><ul>\n<li>ulimit -Sn 100000 # This will only work if hard limit is big enough.</li>\n<li>sysctl -w fs.file-max=100000</li>\n</ul>","link":"./alpha/topics/clients.html","spaLink":"#/alpha/topics/clients","title":"MAXIMUM NUMBER OF CLIENTS"},{"content":"<h2 id=\"redis-clients-handling-output-buffers-limits\">Output buffers limits</h2><p>Redis needs to handle a variable-length output buffer for every client, since\na command can produce a big amount of data that needs to be transferred to the\nclient.</p><p>However it is possible that a client sends more commands producing more output\nto serve at a faster rate at which Redis can send the existing output to the\nclient. This is especially true with Pub/Sub clients in case a client is not\nable to process new messages fast enough.</p><p>Both the conditions will cause the client output buffer to grow and consume\nmore and more memory. For this reason by default Redis sets limits to the\noutput buffer size for different kind of clients. When the limit is reached\nthe client connection is closed and the event logged in the Redis log file.</p><p>There are two kind of limits Redis uses:</p><ul>\n<li>The <strong>hard limit</strong> is a fixed limit that when reached will make Redis closing the client connection as soon as possible.</li>\n<li>The <strong>soft limit</strong> instead is a limit that depends on the time, for instance a soft limit of 32 megabytes per 10 seconds means that if the client has an output buffer bigger than 32 megabytes for, continuously, 10 seconds, the connection gets closed.</li>\n</ul><p>Different kind of clients have different default limits:</p><ul>\n<li><strong>Normal clients</strong> have a default limit of 0, that means, no limit at all, because most normal clients use blocking implementations sending a single command and waiting for the reply to be completely read before sending the next command, so it is always not desirable to close the connection in case of a normal client.</li>\n<li><strong>Pub/Sub clients</strong> have a default hard limit of 32 megabytes and a soft limit of 8 megabytes per 60 seconds.</li>\n<li><strong>Slaves</strong> have a default hard limit of 256 megabytes and a soft limit of 64 megabyte per 60 second.</li>\n</ul><p>It is possible to change the limit at runtime using the <code>CONFIG SET</code> command or in a permanent way using the Redis configuration file <code>redis.conf</code>. See the example <code>redis.conf</code> in the Redis distribution for more information about how to set the limit.</p>","link":"./alpha/topics/clients.html","spaLink":"#/alpha/topics/clients","title":"OUTPUT BUFFERS LIMITS"},{"content":"<h2 id=\"redis-clients-handling-query-buffer-hard-limit\">Query buffer hard limit</h2><p>Every client is also subject to a query buffer limit. This is a non-configurable hard limit that will close the connection when the client query buffer (that is the buffer we use to accumulate commands from the client) reaches 1 GB, and is actually only an extreme limit to avoid a server crash in case of client or server software bugs.</p>","link":"./alpha/topics/clients.html","spaLink":"#/alpha/topics/clients","title":"QUERY BUFFER HARD LIMIT"},{"content":"<h2 id=\"redis-clients-handling-client-timeouts\">Client timeouts</h2><p>By default recent versions of Redis don’t close the connection with the client\nif the client is idle for many seconds: the connection will remain open forever.</p><p>However if you don’t like this behavior, you can configure a timeout, so that\nif the client is idle for more than the specified number of seconds, the client connection will be closed.</p><p>You can configure this limit via <code>redis.conf</code> or simply using <code>CONFIG SET timeout &lt;value&gt;</code>.</p><p>Note that the timeout only applies to number clients and it <strong>does not apply to Pub/Sub clients</strong>, since a Pub/Sub connection is a <em>push style</em> connection so a client that is idle is the norm.</p><p>Even if by default connections are not subject to timeout, there are two conditions when it makes sense to set a timeout:</p><ul>\n<li>Mission critical applications where a bug in the client software may saturate the Redis server with idle connections, causing service disruption.</li>\n<li>As a debugging mechanism in order to be able to connect with the server if a bug in the client software saturates the server with idle connections, making it impossible to interact with the server.</li>\n</ul><p>Timeouts are not to be considered very precise: Redis avoids to set timer events or to run O(N) algorithms in order to check idle clients, so the check is performed incrementally from time to time. This means that it is possible that while the timeout is set to 10 seconds, the client connection will be closed, for instance, after 12 seconds if many clients are connected at the same time.</p>","link":"./alpha/topics/clients.html","spaLink":"#/alpha/topics/clients","title":"CLIENT TIMEOUTS"},{"content":"<h2 id=\"redis-clients-handling-client-command\">CLIENT command</h2><p>The Redis client command allows to inspect the state of every connected client, to kill a specific client, to set names to connections. It is a very powerful debugging tool if you use Redis at scale.</p><p><code>CLIENT LIST</code> is used in order to obtain a list of connected clients and their state:</p><p>In the above example session two clients are connected to the Redis server. The meaning of a few of the most interesting fields is the following:</p><ul>\n<li><strong>addr</strong>: The client address, that is, the client IP and the remote port number it used to connect with the Redis server.</li>\n<li><strong>fd</strong>: The client socket file descriptor number.</li>\n<li><strong>name</strong>: The client name as set by <code>CLIENT SETNAME</code>.</li>\n<li><strong>age</strong>: The number of seconds the connection existed for.</li>\n<li><strong>idle</strong>: The number of seconds the connection is idle.</li>\n<li><strong>flags</strong>: The kind of client (N means normal client, check the <a href=\"http://redis.io/commands/client-list\">full list of flags</a>).</li>\n<li><strong>omem</strong>: The amount of memory used by the client for the output buffer.</li>\n<li><strong>cmd</strong>: The last executed command.</li>\n</ul><p>See the <a href=\"http://redis.io/commands/client-list\">CLIENT LIST</a> documentation for the full list of fields and their meaning.</p><p>Once you have the list of clients, you can easily close the connection with a client using the <code>CLIENT KILL</code> command specifying the client address as argument.</p><p>The commands <code>CLIENT SETNAME</code> and <code>CLIENT GETNAME</code> can be used to set and get the connection name.</p>","link":"./alpha/topics/clients.html","spaLink":"#/alpha/topics/clients","title":"CLIENT COMMAND"},{"content":"<h1 id=\"redis-cluster-specification\">Redis Cluster Specification</h1><p>Welcome to the <strong>Redis Cluster Specification</strong>. Here you’ll find information\nabout algorithms and design rationales of Redis Cluster. This document is a work\nin progress as it is continuously synchronized with the actual implementation\nof Redis.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"REDIS CLUSTER SPECIFICATION"},{"content":"<h1 id=\"main-properties-and-rationales-of-the-design\">Main properties and rationales of the design</h1>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"MAIN PROPERTIES AND RATIONALES OF THE DESIGN"},{"content":"<h2 id=\"main-properties-and-rationales-of-the-design-redis-cluster-goals\">Redis Cluster goals</h2><p>Redis Cluster is a distributed implementation of Redis with the following goals, in order of importance in the design:</p><ul>\n<li>High performance and linear scalability up to 1000 nodes. There are no proxies, asynchronous replication is used, and no merge operations are performed on values.</li>\n<li>Acceptable degree of write safety: the system tries (in a best-effort way) to retain all the writes originating from clients connected with the majority of the master nodes. Usually there are small windows where acknowledged writes can be lost. Windows to lose acknowledged writes are larger when clients are in a minority partition.</li>\n<li>Availability: Redis Cluster is able to survive partitions where the majority of the master nodes are reachable and there is at least one reachable slave for every master node that is no longer reachable. Moreover using <em>replicas migration</em>, masters no longer replicated by any slave will receive one from a master which is covered by multiple slaves.</li>\n</ul><p>What is described in this document is implemented in Redis 3.0 or greater.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"REDIS CLUSTER GOALS"},{"content":"<h2 id=\"main-properties-and-rationales-of-the-design-implemented-subset\">Implemented subset</h2><p>Redis Cluster implements all the single key commands available in the\nnon-distributed version of Redis. Commands performing complex multi-key\noperations like Set type unions or intersections are implemented as well\nas long as the keys all belong to the same node.</p><p>Redis Cluster implements a concept called <strong>hash tags</strong> that can be used\nin order to force certain keys to be stored in the same node. However during\nmanual reshardings, multi-key operations may become unavailable for some time\nwhile single key operations are always available.</p><p>Redis Cluster does not support multiple databases like the stand alone version\nof Redis. There is just database 0 and the <code>SELECT</code> command is not allowed.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"IMPLEMENTED SUBSET"},{"content":"<h2 id=\"main-properties-and-rationales-of-the-design-clients-and-servers-roles-in-the-redis-cluster-protocol\">Clients and Servers roles in the Redis Cluster protocol</h2><p>In Redis Cluster nodes are responsible for holding the data,\nand taking the state of the cluster, including mapping keys to the right nodes.\nCluster nodes are also able to auto-discover other nodes, detect non-working\nnodes, and promote slave nodes to master when needed in order\nto continue to operate when a failure occurs.</p><p>To perform their tasks all the cluster nodes are connected using a\nTCP bus and a binary protocol, called the <strong>Redis Cluster Bus</strong>.\nEvery node is connected to every other node in the cluster using the cluster\nbus. Nodes use a gossip protocol to propagate information about the cluster\nin order to discover new nodes, to send ping packets to make sure all the\nother nodes are working properly, and to send cluster messages needed to\nsignal specific conditions. The cluster bus is also used in order to\npropagate Pub/Sub messages across the cluster and to orchestrate manual\nfailovers when requested by users (manual failovers are failovers which\nare not initiated by the Redis Cluster failure detector, but by the\nsystem administrator directly).</p><p>Since cluster nodes are not able to proxy requests, clients may be redirected\nto other nodes using redirection errors <code>-MOVED</code> and <code>-ASK</code>.\nThe client is in theory free to send requests to all the nodes in the cluster,\ngetting redirected if needed, so the client is not required to hold the\nstate of the cluster. However clients that are able to cache the map between\nkeys and nodes can improve the performance in a sensible way.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"CLIENTS AND SERVERS ROLES IN THE REDIS CLUSTER PROTOCOL"},{"content":"<h2 id=\"main-properties-and-rationales-of-the-design-write-safety\">Write safety</h2><p>Redis Cluster uses asynchronous replication between nodes, and <strong>last failover wins</strong> implicit merge function. This means that the last elected master dataset eventually replaces all the other replicas. There is always a window of time when it is possible to lose writes during partitions. However these windows are very different in the case of a client that is connected to the majority of masters, and a client that is connected to the minority of masters.</p><p>Redis Cluster tries harder to retain writes that are performed by clients connected to the majority of masters, compared to writes performed in the minority side.\nThe following are examples of scenarios that lead to loss of acknowledged\nwrites received in the majority partitions during failures:</p><p>A write may reach a master, but while the master may be able to reply to the client, the write may not be propagated to slaves via the asynchronous replication used between master and slave nodes. If the master dies without the write reaching the slaves, the write is lost forever if the master is unreachable for a long enough period that one of its slaves is promoted. This is usually hard to observe in the case of a total, sudden failure of a master node since masters try to reply to clients (with the acknowledge of the write) and slaves (propagating the write) at about the same time. However it is a real world failure mode.</p><p>Another theoretically possible failure mode where writes are lost is the following:</p><p>A master is unreachable because of a partition.</p><p>The second failure mode is unlikely to happen because master nodes unable to communicate with the majority of the other masters for enough time to be failed over will no longer accept writes, and when the partition is fixed writes are still refused for a small amount of time to allow other nodes to inform about configuration changes. This failure mode also requires that the client’s routing table has not yet been updated.</p><p>Writes targeting the minority side of a partition have a larger window in which to get lost. For example, Redis Cluster loses a non-trivial number of writes on partitions where there is a minority of masters and at least one or more clients, since all the writes sent to the masters may potentially get lost if the masters are failed over in the majority side.</p><p>Specifically, for a master to be failed over it must be unreachable by the majority of masters for at least <code>NODE_TIMEOUT</code>, so if the partition is fixed before that time, no writes are lost. When the partition lasts for more than <code>NODE_TIMEOUT</code>, all the writes performed in the minority side up to that point may be lost. However the minority side of a Redis Cluster will start refusing writes as soon as <code>NODE_TIMEOUT</code> time has elapsed without contact with the majority, so there is a maximum window after which the minority becomes no longer available. Hence, no writes are accepted or lost after that time.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"WRITE SAFETY"},{"content":"<h2 id=\"main-properties-and-rationales-of-the-design-availability\">Availability</h2><p>Redis Cluster is not available in the minority side of the partition. In the majority side of the partition assuming that there are at least the majority of masters and a slave for every unreachable master, the cluster becomes available again after <code>NODE_TIMEOUT</code> time plus a few more seconds required for a slave to get elected and failover its master (failovers are usually executed in a matter of 1 or 2 seconds).</p><p>This means that Redis Cluster is designed to survive failures of a few nodes in the cluster, but it is not a suitable solution for applications that require availability in the event of large net splits.</p><p>In the example of a cluster composed of N master nodes where every node has a single slave, the majority side of the cluster will remain available as long as a single node is partitioned away, and will remain available with a probability of <code>1-(1/(N*2-1))</code> when two nodes are partitioned away (after the first node fails we are left with <code>N*2-1</code> nodes in total, and the probability of the only master without a replica to fail is <code>1/(N*2-1))</code>.</p><p>For example, in a cluster with 5 nodes and a single slave per node, there is a <code>1/(5*2-1) = 11.11%</code> probability that after two nodes are partitioned away from the majority, the cluster will no longer be available.</p><p>Thanks to a Redis Cluster feature called <strong>replicas migration</strong> the Cluster\navailability is improved in many real world scenarios by the fact that\nreplicas migrate to orphaned masters (masters no longer having replicas).\nSo at every successful failure event, the cluster may reconfigure the slaves\nlayout in order to better resist the next failure.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"AVAILABILITY"},{"content":"<h2 id=\"main-properties-and-rationales-of-the-design-performance\">Performance</h2><p>In Redis Cluster nodes don’t proxy commands to the right node in charge for a given key, but instead they redirect clients to the right nodes serving a given portion of the key space.</p><p>Eventually clients obtain an up-to-date representation of the cluster and which node serves which subset of keys, so during normal operations clients directly contact the right nodes in order to send a given command.</p><p>Because of the use of asynchronous replication, nodes do not wait for other nodes’ acknowledgment of writes (if not explicitly requested using the <code>WAIT</code> command).</p><p>Also, because multi-key commands are only limited to <em>near</em> keys, data is never moved between nodes except when resharding.</p><p>Normal operations are handled exactly as in the case of a single Redis instance. This means that in a Redis Cluster with N master nodes you can expect the same performance as a single Redis instance multiplied by N as the design scales linearly. At the same time the query is usually performed in a single round trip, since clients usually retain persistent connections with the nodes, so latency figures are also the same as the single standalone Redis node case.</p><p>Very high performance and scalability while preserving weak but\nreasonable forms of data safety and availability is the main goal of\nRedis Cluster.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"PERFORMANCE"},{"content":"<h2 id=\"main-properties-and-rationales-of-the-design-why-merge-operations-are-avoided\">Why merge operations are avoided</h2><p>Redis Cluster design avoids conflicting versions of the same key-value pair in multiple nodes as in the case of the Redis data model this is not always desirable. Values in Redis are often very large; it is common to see lists or sorted sets with millions of elements. Also data types are semantically complex. Transferring and merging these kind of values can be a major bottleneck and/or may require the non-trivial involvement of application-side logic, additional memory to store meta-data, and so forth.</p><p>There are no strict technological limits here. CRDTs or synchronously replicated\nstate machines can model complex data types similar to Redis. However, the\nactual run time behavior of such systems would not be similar to Redis Cluster.\nRedis Cluster was designed in order to cover the exact use cases of the\nnon-clustered Redis version.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"WHY MERGE OPERATIONS ARE AVOIDED"},{"content":"<h1 id=\"overview-of-redis-cluster-main-components\">Overview of Redis Cluster main components</h1>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"OVERVIEW OF REDIS CLUSTER MAIN COMPONENTS"},{"content":"<h2 id=\"overview-of-redis-cluster-main-components-keys-distribution-model\">Keys distribution model</h2><p>The key space is split into 16384 slots, effectively setting an upper limit\nfor the cluster size of 16384 master nodes (however the suggested max size of\nnodes is in the order of ~ 1000 nodes).</p><p>Each master node in a cluster handles a subset of the 16384 hash slots.\nThe cluster is <strong>stable</strong> when there is no cluster reconfiguration in\nprogress (i.e. where hash slots are being moved from one node to another).\nWhen the cluster is stable, a single hash slot will be served by a single node\n(however the serving node can have one or more slaves that will replace it in the case of net splits or failures,\nand that can be used in order to scale read operations where reading stale data is acceptable).</p><p>The base algorithm used to map keys to hash slots is the following\n(read the next paragraph for the hash tag exception to this rule):</p><p>The CRC16 is specified as follows:</p><ul>\n<li>Name: XMODEM (also known as ZMODEM or CRC-16/ACORN)</li>\n<li>Width: 16 bit</li>\n<li>Poly: 1021 (That is actually x^16 + x^12 + x^5 + 1)</li>\n<li>Initialization: 0000</li>\n<li>Reflect Input byte: False</li>\n<li>Reflect Output CRC: False</li>\n<li>Xor constant to output CRC: 0000</li>\n<li>Output for “123456789”: 31C3</li>\n</ul><p>14 out of 16 CRC16 output bits are used (this is why there is\na modulo 16384 operation in the formula above).</p><p>In our tests CRC16 behaved remarkably well in distributing different kinds of\nkeys evenly across the 16384 slots.</p><p><strong>Note</strong>: A reference implementation of the CRC16 algorithm used is available in the Appendix A of this document.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"KEYS DISTRIBUTION MODEL"},{"content":"<h2 id=\"overview-of-redis-cluster-main-components-keys-hash-tags\">Keys hash tags</h2><p>There is an exception for the computation of the hash slot that is used in order\nto implement <strong>hash tags</strong>. Hash tags are a way to ensure that multiple keys\nare allocated in the same hash slot. This is used in order to implement\nmulti-key operations in Redis Cluster.</p><p>In order to implement hash tags, the hash slot for a key is computed in a\nslightly different way in certain conditions.\nIf the key contains a “{…}” pattern only the substring between\n<code>{</code> and <code>}</code> is hashed in order to obtain the hash slot. However since it is\npossible that there are multiple occurrences of <code>{</code> or <code>}</code> the algorithm is\nwell specified by the following rules:</p><ul>\n<li>IF the key contains a <code>{</code> character.</li>\n<li>AND IF there is a <code>}</code> character to the right of <code>{</code></li>\n<li>AND IF there are one or more characters between the first occurrence of <code>{</code> and the first occurrence of <code>}</code>.</li>\n</ul><p>Then instead of hashing the key, only what is between the first occurrence of <code>{</code> and the following first occurrence of <code>}</code> is hashed.</p><p>Examples:</p><ul>\n<li>The two keys <code>{user1000}.following</code> and <code>{user1000}.followers</code> will hash to the same hash slot since only the substring <code>user1000</code> will be hashed in order to compute the hash slot.</li>\n<li>For the key <code>foo{}{bar}</code> the whole key will be hashed as usually since the first occurrence of <code>{</code> is followed by <code>}</code> on the right without characters in the middle.</li>\n<li>For the key <code>foo{{bar}}zap</code> the substring <code>{bar</code> will be hashed, because it is the substring between the first occurrence of <code>{</code> and the first occurrence of <code>}</code> on its right.</li>\n<li>For the key <code>foo{bar}{zap}</code> the substring <code>bar</code> will be hashed, since the algorithm stops at the first valid or invalid (without bytes inside) match of <code>{</code> and <code>}</code>.</li>\n<li>What follows from the algorithm is that if the key starts with <code>{}</code>, it is guaranteed to be hashed as a whole. This is useful when using binary data as key names.</li>\n</ul><p>Adding the hash tags exception, the following is an implementation of the <code>HASH_SLOT</code> function in Ruby and C language.</p><p>Ruby example code:</p><p>C example code:</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"KEYS HASH TAGS"},{"content":"<h2 id=\"overview-of-redis-cluster-main-components-cluster-nodes-attributes\">Cluster nodes attributes</h2><p>Every node has a unique name in the cluster. The node name is the\nhex representation of a 160 bit random number, obtained the first time a\nnode is started (usually using /dev/urandom).\nThe node will save its ID in the node configuration file, and will use the\nsame ID forever, or at least as long as the node configuration file is not\ndeleted by the system administrator, or a <em>hard reset</em> is requested\nvia the <code>CLUSTER RESET</code> command.</p><p>The node ID is used to identify every node across the whole cluster.\nIt is possible for a given node to change its IP address without any need\nto also change the node ID. The cluster is also able to detect the change\nin IP/port and reconfigure using the gossip protocol running over the cluster\nbus.</p><p>The node ID is not the only information associated with each node, but is\nthe only one that is always globally consistent. Every node has also the\nfollowing set of information associated. Some information is about the\ncluster configuration detail of this specific node, and is eventually\nconsistent across the cluster. Some other information, like the last time\na node was pinged, is instead local to each node.</p><p>Every node maintains the following information about other nodes that it is\naware of in the cluster: The node ID, IP and port of the node, a set of\nflags, what is the master of the node if it is flagged as <code>slave</code>, last time\nthe node was pinged and the last time the pong was received, the current\n<em>configuration epoch</em> of the node (explained later in this specification),\nthe link state and finally the set of hash slots served.</p><p>A detailed <a href=\"http://redis.io/commands/cluster-nodes\">explanation of all the node fields</a> is described in the <code>CLUSTER NODES</code> documentation.</p><p>The <code>CLUSTER NODES</code> command can be sent to any node in the cluster and provides the state of the cluster and the information for each node according to the local view the queried node has of the cluster.</p><p>The following is sample output of the <code>CLUSTER NODES</code> command sent to a master\nnode in a small cluster of three nodes.</p><p>In the above listing the different fields are in order: node id, address:port, flags, last ping sent, last pong received, configuration epoch, link state, slots. Details about the above fields will be covered as soon as we talk of specific parts of Redis Cluster.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"CLUSTER NODES ATTRIBUTES"},{"content":"<h2 id=\"overview-of-redis-cluster-main-components-the-cluster-bus\">The Cluster bus</h2><p>Every Redis Cluster node has an additional TCP port for receiving\nincoming connections from other Redis Cluster nodes. This port is at a fixed\noffset from the normal TCP port used to receive incoming connections\nfrom clients. To obtain the Redis Cluster port, 10000 should be added to\nthe normal commands port. For example, if a Redis node is listening for\nclient connections on port 6379, the Cluster bus port 16379 will also be\nopened.</p><p>Node-to-node communication happens exclusively using the Cluster bus and\nthe Cluster bus protocol: a binary protocol composed of frames\nof different types and sizes. The Cluster bus binary protocol is not\npublicly documented since it is not intended for external software devices\nto talk with Redis Cluster nodes using this protocol. However you can\nobtain more details about the Cluster bus protocol by reading the\n<code>cluster.h</code> and <code>cluster.c</code> files in the Redis Cluster source code.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"THE CLUSTER BUS"},{"content":"<h2 id=\"overview-of-redis-cluster-main-components-cluster-topology\">Cluster topology</h2><p>Redis Cluster is a full mesh where every node is connected with every other node using a TCP connection.</p><p>In a cluster of N nodes, every node has N-1 outgoing TCP connections, and N-1 incoming connections.</p><p>These TCP connections are kept alive all the time and are not created on demand.\nWhen a node expects a pong reply in response to a ping in the cluster bus, before waiting long enough to mark the node as unreachable, it will try to\nrefresh the connection with the node by reconnecting from scratch.</p><p>While Redis Cluster nodes form a full mesh, <strong>nodes use a gossip protocol and\na configuration update mechanism in order to avoid exchanging too many\nmessages between nodes during normal conditions</strong>, so the number of messages\nexchanged is not exponential.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"CLUSTER TOPOLOGY"},{"content":"<h2 id=\"overview-of-redis-cluster-main-components-nodes-handshake\">Nodes handshake</h2><p>Nodes always accept connections on the cluster bus port, and even reply to\npings when received, even if the pinging node is not trusted.\nHowever, all other packets will be discarded by the receiving node if the\nsending node is not considered part of the cluster.</p><p>A node will accept another node as part of the cluster only in two ways:</p><ul>\n<li><p>If a node presents itself with a <code>MEET</code> message. A meet message is exactly\nlike a <code>PING</code> message, but forces the receiver to accept the node as part of\nthe cluster. Nodes will send <code>MEET</code> messages to other nodes <strong>only if</strong> the system administrator requests this via the following command:</p>\n<p>  CLUSTER MEET ip port</p>\n</li>\n<li><p>A node will also register another node as part of the cluster if a node that is already trusted will gossip about this other node. So if A knows B, and B knows C, eventually B will send gossip messages to A about C. When this happens, A will register C as part of the network, and will try to connect with C.</p>\n</li>\n</ul><p>If a node presents itself with a <code>MEET</code> message. A meet message is exactly\nlike a <code>PING</code> message, but forces the receiver to accept the node as part of\nthe cluster. Nodes will send <code>MEET</code> messages to other nodes <strong>only if</strong> the system administrator requests this via the following command:</p><p>  CLUSTER MEET ip port</p><p>A node will also register another node as part of the cluster if a node that is already trusted will gossip about this other node. So if A knows B, and B knows C, eventually B will send gossip messages to A about C. When this happens, A will register C as part of the network, and will try to connect with C.</p><p>This means that as long as we join nodes in any connected graph, they’ll eventually form a fully connected graph automatically. This means that the cluster is able to auto-discover other nodes, but only if there is a trusted relationship that was forced by the system administrator.</p><p>This mechanism makes the cluster more robust but prevents different Redis clusters from accidentally mixing after change of IP addresses or other network related events.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"NODES HANDSHAKE"},{"content":"<h1 id=\"redirection-and-resharding\">Redirection and resharding</h1>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"REDIRECTION AND RESHARDING"},{"content":"<h2 id=\"redirection-and-resharding-moved-redirection\">MOVED Redirection</h2><p>A Redis client is free to send queries to every node in the cluster, including\nslave nodes. The node will analyze the query, and if it is acceptable\n(that is, only a single key is mentioned in the query, or the multiple keys\nmentioned are all to the same hash slot) it will lookup what\nnode is responsible for the hash slot where the key or keys belong.</p><p>If the hash slot is served by the node, the query is simply processed, otherwise\nthe node will check its internal hash slot to node map, and will reply\nto the client with a MOVED error, like in the following example:</p><p>The error includes the hash slot of the key (3999) and the ip:port of the\ninstance that can serve the query. The client needs to reissue the query\nto the specified node’s IP address and port.\nNote that even if the client waits a long time before reissuing the query,\nand in the meantime the cluster configuration changed, the destination node\nwill reply again with a MOVED error if the hash slot 3999 is now served by\nanother node. The same happens if the contacted node had no updated information.</p><p>So while from the point of view of the cluster nodes are identified by\nIDs we try to simplify our interface with the client just exposing a map\nbetween hash slots and Redis nodes identified by IP:port pairs.</p><p>The client is not required to, but should try to memorize that hash slot\n3999 is served by 127.0.0.1:6381. This way once a new command needs to\nbe issued it can compute the hash slot of the target key and have a\ngreater chance of choosing the right node.</p><p>An alternative is to just refresh the whole client-side cluster layout\nusing the <code>CLUSTER NODES</code> or <code>CLUSTER SLOTS</code> commands\nwhen a MOVED redirection is received. When a redirection is encountered, it\nis likely multiple slots were reconfigured rather than just one, so updating\nthe client configuration as soon as possible is often the best strategy.</p><p>Note that when the Cluster is stable (no ongoing changes in the configuration),\neventually all the clients will obtain a map of hash slots -&gt; nodes, making\nthe cluster efficient, with clients directly addressing the right nodes\nwithout redirections, proxies or other single point of failure entities.</p><p>A client <strong>must be also able to handle -ASK redirections</strong> that are described\nlater in this document, otherwise it is not a complete Redis Cluster client.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"MOVED REDIRECTION"},{"content":"<h2 id=\"redirection-and-resharding-cluster-live-reconfiguration\">Cluster live reconfiguration</h2><p>Redis Cluster supports the ability to add and remove nodes while the cluster\nis running. Adding or removing a node is abstracted into the same\noperation: moving a hash slot from one node to another. This means\nthat the same basic mechanism can be used in order to rebalance the cluster, add\nor remove nodes, and so forth.</p><ul>\n<li>To add a new node to the cluster an empty node is added to the cluster and some set of hash slots are moved from existing nodes to the new node.</li>\n<li>To remove a node from the cluster the hash slots assigned to that node are moved to other existing nodes.</li>\n<li>To rebalance the cluster a given set of hash slots are moved between nodes.</li>\n</ul><p>The core of the implementation is the ability to move hash slots around.\nFrom a practical point of view a hash slot is just a set of keys, so\nwhat Redis Cluster really does during <em>resharding</em> is to move keys from\nan instance to another instance. Moving a hash slot means moving all the keys\nthat happen to hash into this hash slot.</p><p>To understand how this works we need to show the <code>CLUSTER</code> subcommands\nthat are used to manipulate the slots translation table in a Redis Cluster node.</p><p>The following subcommands are available (among others not useful in this case):</p><ul>\n<li><code>CLUSTER ADDSLOTS</code> slot1 [slot2] … [slotN]</li>\n<li><code>CLUSTER DELSLOTS</code> slot1 [slot2] … [slotN]</li>\n<li><code>CLUSTER SETSLOT</code> slot NODE node</li>\n<li><code>CLUSTER SETSLOT</code> slot MIGRATING node</li>\n<li><code>CLUSTER SETSLOT</code> slot IMPORTING node</li>\n</ul><p>The first two commands, <code>ADDSLOTS</code> and <code>DELSLOTS</code>, are simply used to assign\n(or remove) slots to a Redis node. Assigning a slot means to tell a given\nmaster node that it will be in charge of storing and serving content for\nthe specified hash slot.</p><p>After the hash slots are assigned they will propagate across the cluster\nusing the gossip protocol, as specified later in the\n<em>configuration propagation</em> section.</p><p>The <code>ADDSLOTS</code> command is usually used when a new cluster is created\nfrom scratch to assign each master node a subset of all the 16384 hash\nslots available.</p><p>The <code>DELSLOTS</code> is mainly used for manual modification of a cluster configuration\nor for debugging tasks: in practice it is rarely used.</p><p>The <code>SETSLOT</code> subcommand is used to assign a slot to a specific node ID if\nthe <code>SETSLOT &lt;slot&gt; NODE</code> form is used. Otherwise the slot can be set in the\ntwo special states <code>MIGRATING</code> and <code>IMPORTING</code>. Those two special states\nare used in order to migrate a hash slot from one node to another.</p><ul>\n<li>When a slot is set as MIGRATING, the node will accept all queries that\nare about this hash slot, but only if the key in question\nexists, otherwise the query is forwarded using a <code>-ASK</code> redirection to the\nnode that is target of the migration.</li>\n<li>When a slot is set as IMPORTING, the node will accept all queries that\nare about this hash slot, but only if the request is\npreceded by an <code>ASKING</code> command. If the <code>ASKING</code> command was not given\nby the client, the query is redirected to the real hash slot owner via\na <code>-MOVED</code> redirection error, as would happen normally.</li>\n</ul><p>Let’s make this clearer with an example of hash slot migration.\nAssume that we have two Redis master nodes, called A and B.\nWe want to move hash slot 8 from A to B, so we issue commands like this:</p><ul>\n<li>We send B: CLUSTER SETSLOT 8 IMPORTING A</li>\n<li>We send A: CLUSTER SETSLOT 8 MIGRATING B</li>\n</ul><p>All the other nodes will continue to point clients to node “A” every time\nthey are queried with a key that belongs to hash slot 8, so what happens\nis that:</p><ul>\n<li>All queries about existing keys are processed by “A”.</li>\n<li>All queries about non-existing keys in A are processed by “B”, because “A” will redirect clients to “B”.</li>\n</ul><p>This way we no longer create new keys in “A”.\nIn the meantime, a special program called <code>redis-trib</code> used during reshardings\nand Redis Cluster configuration will migrate existing keys in\nhash slot 8 from A to B.\nThis is performed using the following command:</p><p>The above command will return <code>count</code> keys in the specified hash slot.\nFor every key returned, <code>redis-trib</code> sends node “A” a <code>MIGRATE</code> command, that\nwill migrate the specified key from A to B in an atomic way (both instances\nare locked for the time (usually very small time) needed to migrate a key so\nthere are no race conditions). This is how <code>MIGRATE</code> works:</p><p><code>MIGRATE</code> will connect to the target instance, send a serialized version of\nthe key, and once an OK code is received will delete the old key from its own\ndataset. From the point of view of an external client a key exists either\nin A or B at any given time.</p><p>In Redis Cluster there is no need to specify a database other than 0, but\n<code>MIGRATE</code> is a general command that can be used for other tasks not\ninvolving Redis Cluster.\n<code>MIGRATE</code> is optimized to be as fast as possible even when moving complex\nkeys such as long lists, but in Redis Cluster reconfiguring the\ncluster where big keys are present is not considered a wise procedure if\nthere are latency constraints in the application using the database.</p><p>When the migration process is finally finished, the <code>SETSLOT &lt;slot&gt; NODE &lt;node-id&gt;</code> command is sent to the two nodes involved in the migration in order to\nset the slots to their normal state again. The same command is usually\nsent to all other nodes to avoid waiting for the natural\npropagation of the new configuration across the cluster.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"CLUSTER LIVE RECONFIGURATION"},{"content":"<h2 id=\"redirection-and-resharding-ask-redirection\">ASK redirection</h2><p>In the previous section we briefly talked about ASK redirection. Why can’t\nwe simply use MOVED redirection? Because while MOVED means that\nwe think the hash slot is permanently served by a different node and the\nnext queries should be tried against the specified node, ASK means to\nsend only the next query to the specified node.</p><p>This is needed because the next query about hash slot 8 can be about a\nkey that is still in A, so we always want the client to try A and\nthen B if needed. Since this happens only for one hash slot out of 16384\navailable, the performance hit on the cluster is acceptable.</p><p>We need to force that client behavior, so to make sure\nthat clients will only try node B after A was tried, node B will only\naccept queries of a slot that is set as IMPORTING if the client sends the\nASKING command before sending the query.</p><p>Basically the ASKING command sets a one-time flag on the client that forces\na node to serve a query about an IMPORTING slot.</p><p>The full semantics of ASK redirection from the point of view of the client is as follows:</p><ul>\n<li>If ASK redirection is received, send only the query that was redirected to the specified node but continue sending subsequent queries to the old node.</li>\n<li>Start the redirected query with the ASKING command.</li>\n<li>Don’t yet update local client tables to map hash slot 8 to B.</li>\n</ul><p>Once hash slot 8 migration is completed, A will send a MOVED message and\nthe client may permanently map hash slot 8 to the new IP and port pair.\nNote that if a buggy client performs the map earlier this is not\na problem since it will not send the ASKING command before issuing the query,\nso B will redirect the client to A using a MOVED redirection error.</p><p>Slots migration is explained in similar terms but with different wording\n(for the sake of redundancy in the documentation) in the <code>CLUSTER SETSLOT</code>\ncommand documentation.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"ASK REDIRECTION"},{"content":"<h2 id=\"redirection-and-resharding-clients-first-connection-and-handling-of-redirections\">Clients first connection and handling of redirections</h2><p>While it is possible to have a Redis Cluster client implementation that does not\nremember the slots configuration (the map between slot numbers and addresses of\nnodes serving it) in memory and only works by contacting random nodes waiting to\nbe redirected, such a client would be very inefficient.</p><p>Redis Cluster clients should try to be smart enough to memorize the slots\nconfiguration. However this configuration is not <em>required</em> to be up to date.\nSince contacting the wrong node will simply result in a redirection, that\nshould trigger an update of the client view.</p><p>Clients usually need to fetch a complete list of slots and mapped node\naddresses in two different situations:</p><ul>\n<li>At startup in order to populate the initial slots configuration.</li>\n<li>When a <code>MOVED</code> redirection is received.</li>\n</ul><p>Note that a client may handle the <code>MOVED</code> redirection by updating just the\nmoved slot in its table, however this is usually not efficient since often\nthe configuration of multiple slots is modified at once (for example if a\nslave is promoted to master, all the slots served by the old master will\nbe remapped). It is much simpler to react to a <code>MOVED</code> redirection by\nfetching the full map of slots to nodes from scratch.</p><p>In order to retrieve the slots configuration Redis Cluster offers\nan alternative to the <code>CLUSTER NODES</code> command that does not\nrequire parsing, and only provides the information strictly needed to clients.</p><p>The new command is called <code>CLUSTER SLOTS</code> and provides an array of slots\nranges, and the associated master and slave nodes serving the specified range.</p><p>The following is an example of output of <code>CLUSTER SLOTS</code>:</p><p>The first two sub-elements of every element of the returned array are the\nstart-end slots of the range. The additional elements represent address-port\npairs. The first address-port pair is the master serving the slot, and the\nadditional address-port pairs are all the slaves serving the same slot\nthat are not in an error condition (i.e. the FAIL flag is not set).</p><p>For example the first element of the output says that slots from 5461 to 10922\n(start and end included) are served by 127.0.0.1:7001, and it is possible\nto scale read-only load contacting the slave at 127.0.0.1:7004.</p><p><code>CLUSTER SLOTS</code> is not guaranteed to return ranges that cover the full\n16384 slots if the cluster is misconfigured, so clients should initialize the\nslots configuration map filling the target nodes with NULL objects, and\nreport an error if the user tries to execute commands about keys\nthat belong to unassigned slots.</p><p>Before returning an error to the caller when a slot is found to\nbe unassigned, the client should try to fetch the slots configuration\nagain to check if the cluster is now configured properly.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"CLIENTS FIRST CONNECTION AND HANDLING OF REDIRECTIONS"},{"content":"<h2 id=\"redirection-and-resharding-multiple-keys-operations\">Multiple keys operations</h2><p>Using hash tags, clients are free to use multi-key operations.\nFor example the following operation is valid:</p><p>Multi-key operations may become unavailable when a resharding of the\nhash slot the keys belong to is in progress.</p><p>More specifically, even during a resharding the multi-key operations\ntargeting keys that all exist and are all still in the same node (either\nthe source or destination node) are still available.</p><p>Operations on keys that don’t exist or are - during the resharding - split\nbetween the source and destination nodes, will generate a <code>-TRYAGAIN</code> error.\nThe client can try the operation after some time, or report back the error.</p><p>As soon as migration of the specified hash slot has terminated, all\nmulti-key operations are available again for that hash slot.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"MULTIPLE KEYS OPERATIONS"},{"content":"<h2 id=\"redirection-and-resharding-scaling-reads-using-slave-nodes\">Scaling reads using slave nodes</h2><p>Normally slave nodes will redirect clients to the authoritative master for\nthe hash slot involved in a given command, however clients can use slaves\nin order to scale reads using the <code>READONLY</code> command.</p><p><code>READONLY</code> tells a Redis Cluster slave node that the client is ok reading\npossibly stale data and is not interested in running write queries.</p><p>When the connection is in readonly mode, the cluster will send a redirection\nto the client only if the operation involves keys not served\nby the slave’s master node. This may happen because:</p><p>When this happens the client should update its hashslot map as explained in\nthe previous sections.</p><p>The readonly state of the connection can be cleared using the <code>READWRITE</code> command.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"SCALING READS USING SLAVE NODES"},{"content":"<h1 id=\"fault-tolerance\">Fault Tolerance</h1>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"FAULT TOLERANCE"},{"content":"<h2 id=\"fault-tolerance-heartbeat-and-gossip-messages\">Heartbeat and gossip messages</h2><p>Redis Cluster nodes continuously exchange ping and pong packets. Those two kind of packets have the same structure, and both carry important configuration information. The only actual difference is the message type field. We’ll refer to the sum of ping and pong packets as <em>heartbeat packets</em>.</p><p>Usually nodes send ping packets that will trigger the receivers to reply with pong packets. However this is not necessarily true. It is possible for nodes to just send pong packets to send information to other nodes about their configuration, without triggering a reply. This is useful, for example, in order to broadcast a new configuration as soon as possible.</p><p>Usually a node will ping a few random nodes every second so that the total number of ping packets sent (and pong packets received) by each node is a constant amount regardless of the number of nodes in the cluster.</p><p>However every node makes sure to ping every other node that hasn’t sent a ping or received a pong for longer than half the <code>NODE_TIMEOUT</code> time. Before <code>NODE_TIMEOUT</code> has elapsed, nodes also try to reconnect the TCP link with another node to make sure nodes are not believed to be unreachable only because there is a problem in the current TCP connection.</p><p>The number of messages globally exchanged can be sizable if <code>NODE_TIMEOUT</code> is set to a small figure and the number of nodes (N) is very large, since every node will try to ping every other node for which they don’t have fresh information every half the <code>NODE_TIMEOUT</code> time.</p><p>For example in a 100 node cluster with a node timeout set to 60 seconds, every node will try to send 99 pings every 30 seconds, with a total amount of pings of 3.3 per second. Multiplied by 100 nodes, this is 330 pings per second in the total cluster.</p><p>There are ways to lower the number of messages, however there have been no\nreported issues with the bandwidth currently used by Redis Cluster failure\ndetection, so for now the obvious and direct design is used. Note that even\nin the above example, the 330 packets per second exchanged are evenly\ndivided among 100 different nodes, so the traffic each node receives\nis acceptable.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"HEARTBEAT AND GOSSIP MESSAGES"},{"content":"<h2 id=\"fault-tolerance-heartbeat-packet-content\">Heartbeat packet content</h2><p>Ping and pong packets contain a header that is common to all types of packets (for instance packets to request a failover vote), and a special Gossip Section that is specific of Ping and Pong packets.</p><p>The common header has the following information:</p><ul>\n<li>Node ID, a 160 bit pseudorandom string that is assigned the first time a node is created and remains the same for all the life of a Redis Cluster node.</li>\n<li>The <code>currentEpoch</code> and <code>configEpoch</code> fields of the sending node that are used to mount the distributed algorithms used by Redis Cluster (this is explained in detail in the next sections). If the node is a slave the <code>configEpoch</code> is the last known <code>configEpoch</code> of its master.</li>\n<li>The node flags, indicating if the node is a slave, a master, and other single-bit node information.</li>\n<li>A bitmap of the hash slots served by the sending node, or if the node is a slave, a bitmap of the slots served by its master.</li>\n<li>The sender TCP base port (that is, the port used by Redis to accept client commands; add 10000 to this to obtain the cluster bus port).</li>\n<li>The state of the cluster from the point of view of the sender (down or ok).</li>\n<li>The master node ID of the sending node, if it is a slave.</li>\n</ul><p>Ping and pong packets also contain a gossip section. This section offers to the receiver a view of what the sender node thinks about other nodes in the cluster. The gossip section only contains information about a few random nodes among the set of nodes known to the sender. The number of nodes mentioned in a gossip section is proportional to the cluster size.</p><p>For every node added in the gossip section the following fields are reported:</p><ul>\n<li>Node ID.</li>\n<li>IP and port of the node.</li>\n<li>Node flags.</li>\n</ul><p>Gossip sections allow receiving nodes to get information about the state of other nodes from the point of view of the sender. This is useful both for failure detection and to discover other nodes in the cluster.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"HEARTBEAT PACKET CONTENT"},{"content":"<h2 id=\"fault-tolerance-failure-detection\">Failure detection</h2><p>Redis Cluster failure detection is used to recognize when a master or slave node is no longer reachable by the majority of nodes and then respond by promoting a slave to the role of master. When slave promotion is not possible the cluster is put in an error state to stop receiving queries from clients.</p><p>As already mentioned, every node takes a list of flags associated with other known nodes. There are two flags that are used for failure detection that are called <code>PFAIL</code> and <code>FAIL</code>. <code>PFAIL</code> means <em>Possible failure</em>, and is a non-acknowledged failure type. <code>FAIL</code> means that a node is failing and that this condition was confirmed by a majority of masters within a fixed amount of time.</p><p><strong>PFAIL flag:</strong></p><p>A node flags another node with the <code>PFAIL</code> flag when the node is not reachable for more than <code>NODE_TIMEOUT</code> time. Both master and slave nodes can flag another node as <code>PFAIL</code>, regardless of its type.</p><p>The concept of non-reachability for a Redis Cluster node is that we have an <strong>active ping</strong> (a ping that we sent for which we have yet to get a reply) pending for longer than <code>NODE_TIMEOUT</code>. For this mechanism to work the <code>NODE_TIMEOUT</code> must be large compared to the network round trip time. In order to add reliability during normal operations, nodes will try to reconnect with other nodes in the cluster as soon as half of the <code>NODE_TIMEOUT</code> has elapsed without a reply to a ping. This mechanism ensures that connections are kept alive so broken connections usually won’t result in false failure reports between nodes.</p><p><strong>FAIL flag:</strong></p><p>The <code>PFAIL</code> flag alone is just local information every node has about other nodes, but it is not sufficient to trigger a slave promotion. For a node to be considered down the <code>PFAIL</code> condition needs to be escalated to a <code>FAIL</code> condition.</p><p>As outlined in the node heartbeats section of this document, every node sends gossip messages to every other node including the state of a few random known nodes. Every node eventually receives a set of node flags for every other node. This way every node has a mechanism to signal other nodes about failure conditions they have detected.</p><p>A <code>PFAIL</code> condition is escalated to a <code>FAIL</code> condition when the following set of conditions are met:</p><ul>\n<li>Some node, that we’ll call A, has another node B flagged as <code>PFAIL</code>.</li>\n<li>Node A collected, via gossip sections, information about the state of B from the point of view of the majority of masters in the cluster.</li>\n<li>The majority of masters signaled the <code>PFAIL</code> or <code>PFAIL</code> condition within <code>NODE_TIMEOUT * FAIL_REPORT_VALIDITY_MULT</code> time. (The validity factor is set to 2 in the current implementation, so this is just two times the <code>NODE_TIMEOUT</code> time).</li>\n</ul><p>If all the above conditions are true, Node A will:</p><ul>\n<li>Mark the node as <code>FAIL</code>.</li>\n<li>Send a <code>FAIL</code> message to all the reachable nodes.</li>\n</ul><p>The <code>FAIL</code> message will force every receiving node to mark the node in <code>FAIL</code> state, whether or not it already flagged the node in <code>PFAIL</code> state.</p><p>Note that <em>the FAIL flag is mostly one way</em>. That is, a node can go from <code>PFAIL</code> to <code>FAIL</code>, but a <code>FAIL</code> flag can only be cleared in the following situations:</p><ul>\n<li>The node is already reachable and is a slave. In this case the <code>FAIL</code> flag can be cleared as slaves are not failed over.</li>\n<li>The node is already reachable and is a master not serving any slot. In this case the <code>FAIL</code> flag can be cleared as masters without slots do not really participate in the cluster and are waiting to be configured in order to join the cluster.</li>\n<li>The node is already reachable and is a master, but a long time (N times the <code>NODE_TIMEOUT</code>) has elapsed without any detectable slave promotion. It’s better for it to rejoin the cluster and continue in this case.</li>\n</ul><p>It is useful to note that while the <code>PFAIL</code> -&gt; <code>FAIL</code> transition uses a form of agreement, the agreement used is weak:</p><p>However the Redis Cluster failure detection has a liveness requirement: eventually all the nodes should agree about the state of a given node. There are two cases that can originate from split brain conditions. Either some minority of nodes believe the node is in <code>FAIL</code> state, or a minority of nodes believe the node is not in <code>FAIL</code> state. In both the cases eventually the cluster will have a single view of the state of a given node:</p><p><strong>Case 1</strong>: If a majority of masters have flagged a node as <code>FAIL</code>, because of failure detection and the <em>chain effect</em> it generates, every other node will eventually flag the master as <code>FAIL</code>, since in the specified window of time enough failures will be reported.</p><p><strong>Case 2</strong>: When only a minority of masters have flagged a node as <code>FAIL</code>, the slave promotion will not happen (as it uses a more formal algorithm that makes sure everybody knows about the promotion eventually) and every node will clear the <code>FAIL</code> state as per the <code>FAIL</code> state clearing rules above (i.e. no promotion after N times the <code>NODE_TIMEOUT</code> has elapsed).</p><p><strong>The <code>FAIL</code> flag is only used as a trigger to run the safe part of the algorithm</strong> for the slave promotion. In theory a slave may act independently and start a slave promotion when its master is not reachable, and wait for the masters to refuse to provide the acknowledgment if the master is actually reachable by the majority. However the added complexity of the <code>PFAIL -&gt; FAIL</code> state, the weak agreement, and the <code>FAIL</code> message forcing the propagation of the state in the shortest amount of time in the reachable part of the cluster, have practical advantages. Because of these mechanisms, usually all the nodes will stop accepting writes at about the same time if the cluster is in an error state. This is a desirable feature from the point of view of applications using Redis Cluster. Also erroneous election attempts initiated by slaves that can’t reach its master due to local problems (the master is otherwise reachable by the majority of other master nodes) are avoided.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"FAILURE DETECTION"},{"content":"<h1 id=\"configuration-handling-propagation-and-failovers\">Configuration handling, propagation, and failovers</h1>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"CONFIGURATION HANDLING, PROPAGATION, AND FAILOVERS"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-cluster-current-epoch\">Cluster current epoch</h2><p>Redis Cluster uses a concept similar to the Raft algorithm “term”. In Redis Cluster the term is called epoch instead, and it is used in order to give incremental versioning to events. When multiple nodes provide conflicting information, it becomes possible for another node to understand which state is the most up to date.</p><p>The <code>currentEpoch</code> is a 64 bit unsigned number.</p><p>At node creation every Redis Cluster node, both slaves and master nodes, set the <code>currentEpoch</code> to 0.</p><p>Every time a packet is received from another node, if the epoch of the sender (part of the cluster bus messages header) is greater than the local node epoch, the <code>currentEpoch</code> is updated to the sender epoch.</p><p>Because of these semantics, eventually all the nodes will agree to the greatest <code>configEpoch</code> in the cluster.</p><p>This information is used when the state of the cluster is changed and a node seeks agreement in order to perform some action.</p><p>Currently this happens only during slave promotion, as described in the next section. Basically the epoch is a logical clock for the cluster and dictates that given information wins over one with a smaller epoch.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"CLUSTER CURRENT EPOCH"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-configuration-epoch\">Configuration epoch</h2><p>Every master always advertises its <code>configEpoch</code> in ping and pong packets along with a bitmap advertising the set of slots it serves.</p><p>The <code>configEpoch</code> is set to zero in masters when a new node is created.</p><p>A new <code>configEpoch</code> is created during slave election. Slaves trying to replace\nfailing masters increment their epoch and try to get authorization from\na majority of masters. When a slave is authorized, a new unique <code>configEpoch</code>\nis created and the slave turns into a master using the new <code>configEpoch</code>.</p><p>As explained in the next sections the <code>configEpoch</code> helps to resolve conflicts when different nodes claim divergent configurations (a condition that may happen because of network partitions and node failures).</p><p>Slave nodes also advertise the <code>configEpoch</code> field in ping and pong packets, but in the case of slaves the field represents the <code>configEpoch</code> of its master as of the last time they exchanged packets. This allows other instances to detect when a slave has an old configuration that needs to be updated (master nodes will not grant votes to slaves with an old configuration).</p><p>Every time the <code>configEpoch</code> changes for some known node, it is permanently stored in the nodes.conf file by all the nodes that receive this information. The same also happens for the <code>currentEpoch</code> value. These two variables are guaranteed to be saved and <code>fsync-ed</code> to disk when updated before a node continues its operations.</p><p>The <code>configEpoch</code> values generated using a simple algorithm during failovers\nare guaranteed to be new, incremental, and unique.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"CONFIGURATION EPOCH"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-slave-election-and-promotion\">Slave election and promotion</h2><p>Slave election and promotion is handled by slave nodes, with the help of master nodes that vote for the slave to promote.\nA slave election happens when a master is in <code>FAIL</code> state from the point of view of at least one of its slaves that has the prerequisites in order to become a master.</p><p>In order for a slave to promote itself to master, it needs to start an election and win it. All the slaves for a given master can start an election if the master is in <code>FAIL</code> state, however only one slave will win the election and promote itself to master.</p><p>A slave starts an election when the following conditions are met:</p><ul>\n<li>The slave’s master is in <code>FAIL</code> state.</li>\n<li>The master was serving a non-zero number of slots.</li>\n<li>The slave replication link was disconnected from the master for no longer than a given amount of time, in order to ensure the promoted slave’s data is reasonably fresh. This time is user configurable.</li>\n</ul><p>In order to be elected, the first step for a slave is to increment its <code>currentEpoch</code> counter, and request votes from master instances.</p><p>Votes are requested by the slave by broadcasting a <code>FAILOVER_AUTH_REQUEST</code> packet to every master node of the cluster. Then it waits for a maximum time of two times the <code>NODE_TIMEOUT</code> for replies to arrive (but always for at least 2 seconds).</p><p>Once a master has voted for a given slave, replying positively with a <code>FAILOVER_AUTH_ACK</code>, it can no longer vote for another slave of the same master for a period of <code>NODE_TIMEOUT * 2</code>. In this period it will not be able to reply to other authorization requests for the same master. This is not needed to guarantee safety, but useful for preventing multiple slaves from getting elected (even if with a different <code>configEpoch</code>) at around the same time, which is usually not wanted.</p><p>A slave discards any <code>AUTH_ACK</code> replies with an epoch that is less than the <code>currentEpoch</code> at the time the vote request was sent. This ensures it doesn’t count votes intended for a previous election.</p><p>Once the slave receives ACKs from the majority of masters, it wins the election.\nOtherwise if the majority is not reached within the period of two times <code>NODE_TIMEOUT</code> (but always at least 2 seconds), the election is aborted and a new one will be tried again after <code>NODE_TIMEOUT * 4</code> (and always at least 4 seconds).</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"SLAVE ELECTION AND PROMOTION"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-slave-rank\">Slave rank</h2><p>As soon as a master is in <code>FAIL</code> state, a slave waits a short period of time before trying to get elected. That delay is computed as follows:</p><p>The fixed delay ensures that we wait for the <code>FAIL</code> state to propagate across the cluster, otherwise the slave may try to get elected while the masters are still unaware of the <code>FAIL</code> state, refusing to grant their vote.</p><p>The random delay is used to desynchronize slaves so they’re unlikely to start an election at the same time.</p><p>The <code>SLAVE_RANK</code> is the rank of this slave regarding the amount of replication data it has processed from the master.\nSlaves exchange messages when the master is failing in order to establish a (best effort) rank:\nthe slave with the most updated replication offset is at rank 0, the second most updated at rank 1, and so forth.\nIn this way the most updated slaves try to get elected before others.</p><p>Rank order is not strictly enforced; if a slave of higher rank fails to be\nelected, the others will try shortly.</p><p>Once a slave wins the election, it obtains a new unique and incremental <code>configEpoch</code> which is higher than that of any other existing master. It starts advertising itself as master in ping and pong packets, providing the set of served slots with a <code>configEpoch</code> that will win over the past ones.</p><p>In order to speedup the reconfiguration of other nodes, a pong packet is broadcast to all the nodes of the cluster. Currently unreachable nodes will eventually be reconfigured when they receive a ping or pong packet from another node or will receive an <code>UPDATE</code> packet from another node if the information it publishes via heartbeat packets are detected to be out of date.</p><p>The other nodes will detect that there is a new master serving the same slots served by the old master but with a greater <code>configEpoch</code>, and will upgrade their configuration. Slaves of the old master (or the failed over master if it rejoins the cluster) will not just upgrade the configuration but will also reconfigure to replicate from the new master. How nodes rejoining the cluster are configured is explained in the next sections.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"SLAVE RANK"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-masters-reply-to-slave-vote-request\">Masters reply to slave vote request</h2><p>In the previous section it was discussed how slaves try to get elected. This section explains what happens from the point of view of a master that is requested to vote for a given slave.</p><p>Masters receive requests for votes in form of <code>FAILOVER_AUTH_REQUEST</code> requests from slaves.</p><p>For a vote to be granted the following conditions need to be met:</p><p>Example of the issue caused by not using rule number 3:</p><p>Master <code>currentEpoch</code> is 5, lastVoteEpoch is 1 (this may happen after a few failed elections)</p><ul>\n<li>Slave <code>currentEpoch</code> is 3.</li>\n<li>Slave tries to be elected with epoch 4 (3+1), master replies with an ok with <code>currentEpoch</code> 5, however the reply is delayed.</li>\n<li><p>Slave will try to be elected again, at a later time, with epoch 5 (4+1), the delayed reply reaches the slave with <code>currentEpoch</code> 5, and is accepted as valid.</p>\n</li>\n<li><p>Masters don’t vote for a slave of the same master before <code>NODE_TIMEOUT * 2</code> has elapsed if a slave of that master was already voted for. This is not strictly required as it is not possible for two slaves to win the election in the same epoch. However, in practical terms it ensures that when a slave is elected it has plenty of time to inform the other slaves and avoid the possibility that another slave will win a new election, performing an unnecessary second failover.</p>\n</li>\n<li>Masters make no effort to select the best slave in any way. If the slave’s master is in <code>FAIL</code> state and the master did not vote in the current term, a positive vote is granted. The best slave is the most likely to start an election and win it before the other slaves, since it will usually be able to start the voting process earlier because of its <em>higher rank</em> as explained in the previous section.</li>\n<li>When a master refuses to vote for a given slave there is no negative response, the request is simply ignored.</li>\n<li>Masters don’t vote for slaves sending a <code>configEpoch</code> that is less than any <code>configEpoch</code> in the master table for the slots claimed by the slave. Remember that the slave sends the <code>configEpoch</code> of its master, and the bitmap of the slots served by its master. This means that the slave requesting the vote must have a configuration for the slots it wants to failover that is newer or equal the one of the master granting the vote.</li>\n</ul><p>Slave will try to be elected again, at a later time, with epoch 5 (4+1), the delayed reply reaches the slave with <code>currentEpoch</code> 5, and is accepted as valid.</p><p>Masters don’t vote for a slave of the same master before <code>NODE_TIMEOUT * 2</code> has elapsed if a slave of that master was already voted for. This is not strictly required as it is not possible for two slaves to win the election in the same epoch. However, in practical terms it ensures that when a slave is elected it has plenty of time to inform the other slaves and avoid the possibility that another slave will win a new election, performing an unnecessary second failover.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"MASTERS REPLY TO SLAVE VOTE REQUEST"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-practical-example-of-configuration-epoch-usefulness-during-partitions\">Practical example of configuration epoch usefulness during partitions</h2><p>This section illustrates how the epoch concept is used to make the slave promotion process more resistant to partitions.</p><ul>\n<li>A master is no longer reachable indefinitely. The master has three slaves A, B, C.</li>\n<li>Slave A wins the election and is promoted to master.</li>\n<li>A network partition makes A not available for the majority of the cluster.</li>\n<li>Slave B wins the election and is promoted as master.</li>\n<li>A partition makes B not available for the majority of the cluster.</li>\n<li>The previous partition is fixed, and A is available again.</li>\n</ul><p>At this point B is down and A is available again with a role of master (actually <code>UPDATE</code> messages would reconfigure it promptly, but here we assume all <code>UPDATE</code> messages were lost). At the same time, slave C will try to get elected in order to fail over B. This is what happens:</p><p>As you’ll see in the next sections, a stale node rejoining a cluster\nwill usually get notified as soon as possible about the configuration change\nbecause as soon as it pings any other node, the receiver will detect it\nhas stale information and will send an <code>UPDATE</code> message.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"PRACTICAL EXAMPLE OF CONFIGURATION EPOCH USEFULNESS DURING PARTITIONS"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-hash-slots-configuration-propagation\">Hash slots configuration propagation</h2><p>An important part of Redis Cluster is the mechanism used to propagate the information about which cluster node is serving a given set of hash slots. This is vital to both the startup of a fresh cluster and the ability to upgrade the configuration after a slave was promoted to serve the slots of its failing master.</p><p>The same mechanism allows nodes partitioned away for an indefinite amount of\ntime to rejoin the cluster in a sensible way.</p><p>There are two ways hash slot configurations are propagated:</p><p>The receiver of a heartbeat or <code>UPDATE</code> message uses certain simple rules in\norder to update its table mapping hash slots to nodes. When a new Redis Cluster node is created, its local hash slot table is simply initialized to <code>NULL</code> entries so that each hash slot is not bound or linked to any node. This looks similar to the following:</p><p>The first rule followed by a node in order to update its hash slot table is the following:</p><p><strong>Rule 1</strong>: If a hash slot is unassigned (set to <code>NULL</code>), and a known node claims it, I’ll modify my hash slot table and associate the claimed hash slots to it.</p><p>So if we receive a heartbeat from node A claiming to serve hash slots 1 and 2 with a configuration epoch value of 3, the table will be modified to:</p><p>When a new cluster is created, a system administrator needs to manually assign (using the <code>CLUSTER ADDSLOTS</code> command, via the redis-trib command line tool, or by any other means) the slots served by each master node only to the node itself, and the information will rapidly propagate across the cluster.</p><p>However this rule is not enough. We know that hash slot mapping can change\nduring two events:</p><p>For now let’s focus on failovers. When a slave fails over its master, it obtains\na configuration epoch which is guaranteed to be greater than the one of its\nmaster (and more generally greater than any other configuration epoch\ngenerated previously). For example node B, which is a slave of A, may failover\nB with configuration epoch of 4. It will start to send heartbeat packets\n(the first time mass-broadcasting cluster-wide) and because of the following\nsecond rule, receivers will update their hash slot tables:</p><p><strong>Rule 2</strong>: If a hash slot is already assigned, and a known node is advertising it using a <code>configEpoch</code> that is greater than the <code>configEpoch</code> of the master currently associated with the slot, I’ll rebind the hash slot to the new node.</p><p>So after receiving messages from B that claim to serve hash slots 1 and 2 with configuration epoch of 4, the receivers will update their table in the following way:</p><p>Liveness property: because of the second rule, eventually all nodes in the cluster will agree that the owner of a slot is the one with the greatest <code>configEpoch</code> among the nodes advertising it.</p><p>This mechanism in Redis Cluster is called <strong>last failover wins</strong>.</p><p>The same happens during reshardings. When a node importing a hash slot\ncompletes the import operation, its configuration epoch is incremented to make\nsure the change will be propagated throughout the cluster.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"HASH SLOTS CONFIGURATION PROPAGATION"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-update-messages-a-closer-look\">UPDATE messages, a closer look</h2><p>With the previous section in mind, it is easier to see how update messages\nwork. Node A may rejoin the cluster after some time. It will send heartbeat\npackets where it claims it serves hash slots 1 and 2 with configuration epoch\nof 3. All the receivers with updated information will instead see that\nthe same hash slots are associated with node B having an higher configuration\nepoch. Because of this they’ll send an <code>UPDATE</code> message to A with the new\nconfiguration for the slots. A will update its configuration because of the\n<strong>rule 2</strong> above.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"UPDATE MESSAGES, A CLOSER LOOK"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-how-nodes-rejoin-the-cluster\">How nodes rejoin the cluster</h2><p>The same basic mechanism is used when a node rejoins a cluster.\nContinuing with the example above, node A will be notified\nthat hash slots 1 and 2 are now served by B. Assuming that these two were\nthe only hash slots served by A, the count of hash slots served by A will\ndrop to 0! So A will <strong>reconfigure to be a slave of the new master</strong>.</p><p>The actual rule followed is a bit more complex than this. In general it may\nhappen that A rejoins after a lot of time, in the meantime it may happen that\nhash slots originally served by A are served by multiple nodes, for example\nhash slot 1 may be served by B, and hash slot 2 by C.</p><p>So the actual <em>Redis Cluster node role switch rule</em> is: <strong>A master node will change its configuration to replicate (be a slave of) the node that stole its last hash slot</strong>.</p><p>During reconfiguration, eventually the number of served hash slots will drop to zero, and the node will reconfigure accordingly. Note that in the base case this just means that the old master will be a slave of the slave that replaced it after a failover. However in the general form the rule covers all possible cases.</p><p>Slaves do exactly the same: they reconfigure to replicate the node that\nstole the last hash slot of its former master.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"HOW NODES REJOIN THE CLUSTER"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-replica-migration\">Replica migration</h2><p>Redis Cluster implements a concept called <em>replica migration</em> in order to\nimprove the availability of the system. The idea is that in a cluster with\na master-slave setup, if the map between slaves and masters is fixed\navailability is limited over time if multiple independent failures of single\nnodes happen.</p><p>For example in a cluster where every master has a single slave, the cluster\ncan continue operations as long as either the master or the slave fail, but not\nif both fail the same time. However there is a class of failures that are\nthe independent failures of single nodes caused by hardware or software issues\nthat can accumulate over time. For example:</p><ul>\n<li>Master A has a single slave A1.</li>\n<li>Master A fails. A1 is promoted as new master.</li>\n<li>Three hours later A1 fails in an independent manner (unrelated to the failure of A). No other slave is available for promotion since node A is still down. The cluster cannot continue normal operations.</li>\n</ul><p>If the map between masters and slaves is fixed, the only way to make the cluster\nmore resistant to the above scenario is to add slaves to every master, however\nthis is costly as it requires more instances of Redis to be executed, more\nmemory, and so forth.</p><p>An alternative is to create an asymmetry in the cluster, and let the cluster\nlayout automatically change over time. For example the cluster may have three\nmasters A, B, C. A and B have a single slave each, A1 and B1. However the master\nC is different and has two slaves: C1 and C2.</p><p>Replica migration is the process of automatic reconfiguration of a slave\nin order to <em>migrate</em> to a master that has no longer coverage (no working\nslaves). With replica migration the scenario mentioned above turns into the\nfollowing:</p><ul>\n<li>Master A fails. A1 is promoted.</li>\n<li>C2 migrates as slave of A1, that is otherwise not backed by any slave.</li>\n<li>Three hours later A1 fails as well.</li>\n<li>C2 is promoted as new master to replace A1.</li>\n<li>The cluster can continue the operations.</li>\n</ul>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"REPLICA MIGRATION"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-replica-migration-algorithm\">Replica migration algorithm</h2><p>The migration algorithm does not use any form of agreement since the slave\nlayout in a Redis Cluster is not part of the cluster configuration that needs\nto be consistent and/or versioned with config epochs. Instead it uses an\nalgorithm to avoid mass-migration of slaves when a master is not backed.\nThe algorithm guarantees that eventually (once the cluster configuration is\nstable) every master will be backed by at least one slave.</p><p>This is how the algorithm works. To start we need to define what is a\n<em>good slave</em> in this context: a good slave is a slave not in <code>FAIL</code> state\nfrom the point of view of a given node.</p><p>The execution of the algorithm is triggered in every slave that detects that\nthere is at least a single master without good slaves. However among all the\nslaves detecting this condition, only a subset should act. This subset is\nactually often a single slave unless different slaves have in a given moment\na slightly different view of the failure state of other nodes.</p><p>The <em>acting slave</em> is the slave among the masters with the maximum number\nof attached slaves, that is not in FAIL state and has the smallest node ID.</p><p>So for example if there are 10 masters with 1 slave each, and 2 masters with\n5 slaves each, the slave that will try to migrate is - among the 2 masters\nhaving 5 slaves - the one with the lowest node ID. Given that no agreement\nis used, it is possible that when the cluster configuration is not stable,\na race condition occurs where multiple slaves believe themselves to be\nthe non-failing slave with the lower node ID (it is unlikely for this to happen\nin practice). If this happens, the result is multiple slaves migrating to the\nsame master, which is harmless. If the race happens in a way that will leave\nthe ceding master without slaves, as soon as the cluster is stable again\nthe algorithm will be re-executed again and will migrate a slave back to\nthe original master.</p><p>Eventually every master will be backed by at least one slave. However,\nthe normal behavior is that a single slave migrates from a master with\nmultiple slaves to an orphaned master.</p><p>The algorithm is controlled by a user-configurable parameter called\n<code>cluster-migration-barrier</code>: the number of good slaves a master\nmust be left with before a slave can migrate away. For example, if this\nparameter is set to 2, a slave can try to migrate only if its master remains\nwith two working slaves.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"REPLICA MIGRATION ALGORITHM"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-configepoch-conflicts-resolution-algorithm\">configEpoch conflicts resolution algorithm</h2><p>When new <code>configEpoch</code> values are created via slave promotion during\nfailovers, they are guaranteed to be unique.</p><p>However there are two distinct events where new configEpoch values are\ncreated in an unsafe way, just incrementing the local <code>currentEpoch</code> of\nthe local node and hoping there are no conflicts at the same time.\nBoth the events are system-administrator triggered:</p><p>Specifically, during manual reshardings, when a hash slot is migrated from\na node A to a node B, the resharding program will force B to upgrade\nits configuration to an epoch which is the greatest found in the cluster,\nplus 1 (unless the node is already the one with the greatest configuration\nepoch), without requiring agreement from other nodes.\nUsually a real world resharding involves moving several hundred hash slots\n(especially in small clusters). Requiring an agreement to generate new\nconfiguration epochs during reshardings, for each hash slot moved, is\ninefficient. Moreover it requires an fsync in each of the cluster nodes\nevery time in order to store the new configuration. Because of the way it is\nperformed instead, we only need a new config epoch when the first hash slot is moved,\nmaking it much more efficient in production environments.</p><p>However because of the two cases above, it is possible (though unlikely) to end\nwith multiple nodes having the same configuration epoch. A resharding operation\nperformed by the system administrator, and a failover happening at the same\ntime (plus a lot of bad luck) could cause <code>currentEpoch</code> collisions if\nthey are not propagated fast enough.</p><p>Moreover, software bugs and filesystem corruptions can also contribute\nto multiple nodes having the same configuration epoch.</p><p>When masters serving different hash slots have the same <code>configEpoch</code>, there\nare no issues. It is more important that slaves failing over a master have\nunique configuration epochs.</p><p>That said, manual interventions or reshardings may change the cluster\nconfiguration in different ways. The Redis Cluster main liveness property\nrequires that slot configurations always converge, so under every circumstance\nwe really want all the master nodes to have a different <code>configEpoch</code>.</p><p>In order to enforce this, <strong>a conflict resolution algorithm</strong> is used in the\nevent that two nodes end up with the same <code>configEpoch</code>.</p><ul>\n<li>IF a master node detects another master node is advertising itself with\nthe same <code>configEpoch</code>.</li>\n<li>AND IF the node has a lexicographically smaller Node ID compared to the other node claiming the same <code>configEpoch</code>.</li>\n<li>THEN it increments its <code>currentEpoch</code> by 1, and uses it as the new <code>configEpoch</code>.</li>\n</ul><p>If there are any set of nodes with the same <code>configEpoch</code>, all the nodes but the one with the greatest Node ID will move forward, guaranteeing that, eventually, every node will pick a unique configEpoch regardless of what happened.</p><p>This mechanism also guarantees that after a fresh cluster is created, all\nnodes start with a different <code>configEpoch</code> (even if this is not actually\nused) since <code>redis-trib</code> makes sure to use <code>CONFIG SET-CONFIG-EPOCH</code> at startup.\nHowever if for some reason a node is left misconfigured, it will update\nits configuration to a different configuration epoch automatically.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"CONFIGEPOCH CONFLICTS RESOLUTION ALGORITHM"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-node-resets\">Node resets</h2><p>Nodes can be software reset (without restarting them) in order to be reused\nin a different role or in a different cluster. This is useful in normal\noperations, in testing, and in cloud environments where a given node can\nbe reprovisioned to join a different set of nodes to enlarge or create a new\ncluster.</p><p>In Redis Cluster nodes are reset using the <code>CLUSTER RESET</code> command. The\ncommand is provided in two variants:</p><ul>\n<li><code>CLUSTER RESET SOFT</code></li>\n<li><code>CLUSTER RESET HARD</code></li>\n</ul><p>The command must be sent directly to the node to reset. If no reset type is\nprovided, a soft reset is performed.</p><p>The following is a list of operations performed by a reset:</p><p>Master nodes with non-empty data sets can’t be reset (since normally you want to reshard data to the other nodes). However, under special conditions when this is appropriate (e.g. when a cluster is totally destroyed with the intent of creating a new one), <code>FLUSHALL</code> must be executed before proceeding with the reset.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"NODE RESETS"},{"content":"<h2 id=\"configuration-handling-propagation-and-failovers-removing-nodes-from-a-cluster\">Removing nodes from a cluster</h2><p>It is possible to practically remove a node from an existing cluster by\nresharding all its data to other nodes (if it is a master node) and\nshutting it down. However, the other nodes will still remember its node\nID and address, and will attempt to connect with it.</p><p>For this reason, when a node is removed we want to also remove its entry\nfrom all the other nodes tables. This is accomplished by using the\n<code>CLUSTER FORGET &lt;node-id&gt;</code> command.</p><p>The command does two things:</p><p>The second operation is needed because Redis Cluster uses gossip in order to auto-discover nodes, so removing the node X from node A, could result in node B gossiping about node X to A again. Because of the 60 second ban, the Redis Cluster administration tools have 60 seconds in order to remove the node from all the nodes, preventing the re-addition of the node due to auto discovery.</p><p>Further information is available in the <code>CLUSTER FORGET</code> documentation.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"REMOVING NODES FROM A CLUSTER"},{"content":"<h1 id=\"publishsubscribe\">Publish/Subscribe</h1><p>In a Redis Cluster clients can subscribe to every node, and can also\npublish to every other node. The cluster will make sure that published\nmessages are forwarded as needed.</p><p>The current implementation will simply broadcast each published message\nto all other nodes, but at some point this will be optimized either\nusing Bloom filters or other algorithms.</p>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"PUBLISH/SUBSCRIBE"},{"content":"<h1 id=\"appendix\">Appendix</h1>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"APPENDIX"},{"content":"<h2 id=\"appendix-appendix-a-crc16-reference-implementation-in-ansi-c\">Appendix A: CRC16 reference implementation in ANSI C</h2>","link":"./alpha/topics/cluster-spec.html","spaLink":"#/alpha/topics/cluster-spec","title":"APPENDIX A: CRC16 REFERENCE IMPLEMENTATION IN ANSI C"},{"content":"<h1 id=\"redis-cluster-tutorial\">Redis cluster tutorial</h1><p>This document is a gentle introduction to Redis Cluster, that does not use\ncomplex to understand distributed systems concepts. It provides instructions\nabout how to setup a cluster, test, and operate it, without\ngoing into the details that are covered in\nthe <a href=\"/topics/cluster-spec\">Redis Cluster specification</a> but just describing\nhow the system behaves from the point of view of the user.</p><p>However this tutorial tries to provide information about the availability\nand consistency characteristics of Redis Cluster from the point of view\nof the final user, stated in a simple to understand way.</p><p>Note this tutorial requires Redis version 3.0 or higher.</p><p>If you plan to run a serious Redis Cluster deployment, the\nmore formal specification is a suggested reading, even if not\nstrictly required. However it is a good idea to start from this document,\nplay with Redis Cluster some time, and only later read the specification.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER TUTORIAL"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-101\">Redis Cluster 101</h2><p>Redis Cluster provides a way to run a Redis installation where data is\n<strong>automatically sharded across multiple Redis nodes</strong>.</p><p>Redis Cluster also provides <strong>some degree of availability during partitions</strong>,\nthat is in practical terms the ability to continue the operations when\nsome nodes fail or are not able to communicate. However the cluster stops\nto operate in the event of larger failures (for example when the majority of\nmasters are unavailable).</p><p>So in practical terms, what you get with Redis Cluster?</p><ul>\n<li>The ability to <strong>automatically split your dataset among multiple nodes</strong>.</li>\n<li>The ability to <strong>continue operations when a subset of the nodes are experiencing failures</strong> or are unable to communicate with the rest of the cluster.</li>\n</ul>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER 101"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-tcp-ports\">Redis Cluster TCP ports</h2><p>Every Redis Cluster node requires two TCP connections open. The normal Redis\nTCP port used to serve clients, for example 6379, plus the port obtained by\nadding 10000 to the data port, so 16379 in the example.</p><p>This second <em>high</em> port is used for the Cluster bus, that is a node-to-node\ncommunication channel using a binary protocol. The Cluster bus is used by\nnodes for failure detection, configuration update, failover authorization\nand so forth. Clients should never try to communicate with the cluster bus\nport, but always with the normal Redis command port, however make sure you\nopen both ports in your firewall, otherwise Redis cluster nodes will be\nnot able to communicate.</p><p>The command port and cluster bus port offset is fixed and is always 10000.</p><p>Note that for a Redis Cluster to work properly you need, for each node:</p><p>If you don’t open both TCP ports, your cluster will not work as expected.</p><p>The cluster bus uses a different, binary protocol, for node to node data\nexchange, which is more suited to exchange information between nodes using\nlittle bandwidth and processing time.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER TCP PORTS"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-and-docker\">Redis Cluster and Docker</h2><p>Currently Redis Cluster does not support NATted environments and in general\nenvironments where IP addresses or TCP ports are remapped.</p><p>Docker uses a technique called <em>port mapping</em>: programs running inside Docker\ncontainers may be exposed with a different port compared to the one the\nprogram believes to be using. This is useful in order to run multiple\ncontainers using the same ports, at the same time, in the same server.</p><p>In order to make Docker compatible with Redis Cluster you need to use\nthe <strong>host networking mode</strong> of Docker. Please check the <code>--net=host</code> option\nin the <a href=\"https://docs.docker.com/engine/userguide/networking/dockernetworks/\">Docker documentation</a> for more information.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER AND DOCKER"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-data-sharding\">Redis Cluster data sharding</h2><p>Redis Cluster does not use consistent hashing, but a different form of sharding\nwhere every key is conceptually part of what we call an <strong>hash slot</strong>.</p><p>There are 16384 hash slots in Redis Cluster, and to compute what is the hash\nslot of a given key, we simply take the CRC16 of the key modulo\n16384.</p><p>Every node in a Redis Cluster is responsible for a subset of the hash slots,\nso for example you may have a cluster with 3 nodes, where:</p><ul>\n<li>Node A contains hash slots from 0 to 5500.</li>\n<li>Node B contains hash slots from 5501 to 11000.</li>\n<li>Node C contains hash slots from 11001 to 16383.</li>\n</ul><p>This allows to add and remove nodes in the cluster easily. For example if\nI want to add a new node D, I need to move some hash slot from nodes A, B, C\nto D. Similarly if I want to remove node A from the cluster I can just\nmove the hash slots served by A to B and C. When the node A will be empty\nI can remove it from the cluster completely.</p><p>Because moving hash slots from a node to another does not require to stop\noperations, adding and removing nodes, or changing the percentage of hash\nslots hold by nodes, does not require any downtime.</p><p>Redis Cluster supports multiple key operations as long as all the keys involved\ninto a single command execution (or whole transaction, or Lua script\nexecution) all belong to the same hash slot. The user can force multiple keys\nto be part of the same hash slot by using a concept called <em>hash tags</em>.</p><p>Hash tags are documented in the Redis Cluster specification, but the gist is\nthat if there is a substring between {} brackets in a key, only what is\ninside the string is hashed, so for example <code>this{foo}key</code> and <code>another{foo}key</code>\nare guaranteed to be in the same hash slot, and can be used together in a\ncommand with multiple keys as arguments.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER DATA SHARDING"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-master-slave-model\">Redis Cluster master-slave model</h2><p>In order to remain available when a subset of master nodes are failing or are\nnot able to communicate with the majority of nodes, Redis Cluster uses a\nmaster-slave model where every hash slot has from 1 (the master itself) to N\nreplicas (N-1 additional slaves nodes).</p><p>In our example cluster with nodes A, B, C, if node B fails the cluster is not\nable to continue, since we no longer have a way to serve hash slots in the\nrange 5501-11000.</p><p>However when the cluster is created (or at a latter time) we add a slave\nnode to every master, so that the final cluster is composed of A, B, C\nthat are masters nodes, and A1, B1, C1 that are slaves nodes, the system is\nable to continue if node B fails.</p><p>Node B1 replicates B, and B fails, the cluster will promote node B1 as the new\nmaster and will continue to operate correctly.</p><p>However note that if nodes B and B1 fail at the same time Redis Cluster is not\nable to continue to operate.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER MASTER-SLAVE MODEL"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-consistency-guarantees\">Redis Cluster consistency guarantees</h2><p>Redis Cluster is not able to guarantee <strong>strong consistency</strong>. In practical\nterms this means that under certain conditions it is possible that Redis\nCluster will lose writes that were acknowledged by the system to the client.</p><p>The first reason why Redis Cluster can lose writes is because it uses\nasynchronous replication. This means that during writes the following\nhappens:</p><ul>\n<li>Your client writes to the master B.</li>\n<li>The master B replies OK to your client.</li>\n<li>The master B propagates the write to its slaves B1, B2 and B3.</li>\n</ul><p>As you can see B does not wait for an acknowledge from B1, B2, B3 before\nreplying to the client, since this would be a prohibitive latency penalty\nfor Redis, so if your client writes something, B acknowledges the write,\nbut crashes before being able to send the write to its slaves, one of the\nslaves (that did not receive the write) can be promoted to master, losing\nthe write forever.</p><p>This is <strong>very similar to what happens</strong> with most databases that are\nconfigured to flush data to disk every second, so it is a scenario you\nare already able to reason about because of past experiences with traditional\ndatabase systems not involving distributed systems. Similarly you can\nimprove consistency by forcing the database to flush data on disk before\nreplying to the client, but this usually results into prohibitively low\nperformance. That would be the equivalent of synchronous replication in\nthe case of Redis Cluster.</p><p>Basically there is a trade-off to take between performance and consistency.</p><p>Redis Cluster has support for synchronous writes when absolutely needed,\nimplemented via the <code>WAIT</code> command, this makes losing writes a lot less\nlikely, however note that Redis Cluster does not implement strong consistency\neven when synchronous replication is used: it is always possible under more\ncomplex failure scenarios that a slave that was not able to receive the write\nis elected as master.</p><p>There is another notable scenario where Redis Cluster will lose writes, that\nhappens during a network partition where a client is isolated with a minority\nof instances including at least a master.</p><p>Take as an example our 6 nodes cluster composed of A, B, C, A1, B1, C1,\nwith 3 masters and 3 slaves. There is also a client, that we will call Z1.</p><p>After a partition occurs, it is possible that in one side of the\npartition we have A, C, A1, B1, C1, and in the other side we have B and Z1.</p><p>Z1 is still able to write to B, that will accept its writes. If the\npartition heals in a very short time, the cluster will continue normally.\nHowever if the partition lasts enough time for B1 to be promoted to master\nin the majority side of the partition, the writes that Z1 is sending to B\nwill be lost.</p><p>Note that there is a <strong>maximum window</strong> to the amount of writes Z1 will be able\nto send to B: if enough time has elapsed for the majority side of the\npartition to elect a slave as master, every master node in the minority\nside stops accepting writes.</p><p>This amount of time is a very important configuration directive of Redis\nCluster, and is called the <strong>node timeout</strong>.</p><p>After node timeout has elapsed, a master node is considered to be failing,\nand can be replaced by one of its replicas.\nSimilarly after node timeout has elapsed without a master node to be able\nto sense the majority of the other master nodes, it enters an error state\nand stops accepting writes.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER CONSISTENCY GUARANTEES"},{"content":"<h1 id=\"redis-cluster-configuration-parameters\">Redis Cluster configuration parameters</h1><p>We are about to create an example cluster deployment. Before to continue\nlet’s introduce the configuration parameters that Redis Cluster introduces\nin the <code>redis.conf</code> file. Some will be obvious, others will be more clear\nas you continue reading.</p><ul>\n<li><strong>cluster-enabled <code>&lt;yes/no&gt;</code></strong>: If yes enables Redis Cluster support in a specific Redis instance. Otherwise the instance starts as a stand alone instance as usually.</li>\n<li><strong>cluster-config-file <code>&lt;filename&gt;</code></strong>: Note that despite the name of this option, this is not an user editable configuration file, but the file where a Redis Cluster node automatically persists the cluster configuration (the state, basically) every time there is a change, in order to be able to re-read it at startup. The file lists things like the other nodes in the cluster, their state, persistent variables, and so forth. Often this file is rewritten and flushed on disk as a result of some message reception.</li>\n<li><strong>cluster-node-timeout <code>&lt;milliseconds&gt;</code></strong>: The maximum amount of time a Redis Cluster node can be unavailable, without it being considered as failing. If a master node is not reachable for more than the specified amount of time, it will be failed over by its slaves. This parameter controls other important things in Redis Cluster. Notably, every node that can’t reach the majority of master nodes for the specified amount of time, will stop accepting queries.</li>\n<li><strong>cluster-slave-validity-factor <code>&lt;factor&gt;</code></strong>: If set to zero, a slave will always try to failover a master, regardless of the amount of time the link between the master and the slave remained disconnected. If the value is positive, a maximum disconnection time is calculated as the <em>node timeout</em> value multiplied by the factor provided with this option, and if the node is a slave, it will not try to start a failover if the master link was disconnected for more than the specified amount of time. For example if the node timeout is set to 5 seconds, and the validity factor is set to 10, a slave disconnected from the master for more than 50 seconds will not try to failover its master. Note that any value different than zero may result in Redis Cluster to be unavailable after a master failure if there is no slave able to failover it. In that case the cluster will return back available only when the original master rejoins the cluster.</li>\n<li><strong>cluster-migration-barrier <code>&lt;count&gt;</code></strong>: Minimum number of slaves a master will remain connected with, for another slave to migrate to a master which is no longer covered by any slave. See the appropriate section about replica migration in this tutorial for more information.</li>\n<li><strong>cluster-require-full-coverage <code>&lt;yes/no&gt;</code></strong>: If this is set to yes, as it is by default, the cluster stops accepting writes if some percentage of the key space is not covered by any node. If the option is set to no, the cluster will still serve queries even if only requests about a subset of keys can be processed.</li>\n</ul>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER CONFIGURATION PARAMETERS"},{"content":"<h1 id=\"creating-and-using-a-redis-cluster\">Creating and using a Redis Cluster</h1><p>Note: to deploy a Redis Cluster manually is <strong>very important to learn</strong> certain\noperation aspects of it. However if you want to get a cluster up and running\nASAP skip this section and the next one and go directly to <strong>Creating a Redis Cluster using the create-cluster script</strong>.</p><p>To create a cluster, the first thing we need is to have a few empty\nRedis instances running in <strong>cluster mode</strong>. This basically means that\nclusters are not created using normal Redis instances, but a special mode\nneeds to be configured so that the Redis instance will enable the Cluster\nspecific features and commands.</p><p>The following is a minimal Redis cluster configuration file:</p><p>As you can see what enables the cluster mode is simply the <code>cluster-enabled</code>\ndirective. Every instance also contains the path of a file where the\nconfiguration for this node is stored, that by default is <code>nodes.conf</code>.\nThis file is never touched by humans, it is simply generated at startup\nby the Redis Cluster instances, and updated every time it is needed.</p><p>Note that the <strong>minimal cluster</strong> that works as expected requires to contain\nat least three master nodes. For your first tests it is strongly suggested\nto start a six nodes cluster with three masters and three slaves.</p><p>To do so, enter a new directory, and create the following directories named\nafter the port number of the instance we’ll run inside any given directory.</p><p>Something like:</p><p>Create a <code>redis.conf</code> file inside each of the directories, from 7000 to 7005.\nAs a template for your configuration file just use the small example above,\nbut make sure to replace the port number <code>7000</code> with the right port number\naccording to the directory name.</p><p>Now copy your redis-server executable, <strong>compiled from the latest sources in the unstable branch at GitHub</strong>, into the <code>cluster-test</code> directory, and finally open 6 terminal tabs in your favorite terminal application.</p><p>Start every instance like that, one every tab:</p><p>As you can see from the logs of every instance, since no <code>nodes.conf</code> file\nexisted, every node assigns itself a new ID.</p><p>This ID will be used forever by this specific instance in order for the instance\nto have a unique name in the context of the cluster. Every node\nremembers every other node using this IDs, and not by IP or port.\nIP addresses and ports may change, but the unique node identifier will never\nchange for all the life of the node. We call this identifier simply <strong>Node ID</strong>.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"CREATING AND USING A REDIS CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-creating-the-cluster\">Creating the cluster</h2><p>Now that we have a number of instances running, we need to create our\ncluster by writing some meaningful configuration to the nodes.</p><p>This is very easy to accomplish as we are helped by the Redis Cluster\ncommand line utility called <code>redis-trib</code>, a Ruby program\nexecuting special commands on instances in order to create new clusters,\ncheck or reshard an existing cluster, and so forth.</p><p>The <code>redis-trib</code> utility is in the <code>src</code> directory of the Redis source code\ndistribution.\nYou need to install <code>redis</code> gem to be able to run <code>redis-trib</code>.</p><p> To create your cluster simply type:</p><p>The command used here is <strong>create</strong>, since we want to create a new cluster.\nThe option <code>--replicas 1</code> means that we want a slave for every master created.\nThe other arguments are the list of addresses of the instances I want to use\nto create the new cluster.</p><p>Obviously the only setup with our requirements is to create a cluster with\n3 masters and 3 slaves.</p><p>Redis-trib will propose you a configuration. Accept typing <strong>yes</strong>.\nThe cluster will be configured and <em>joined</em>, that means, instances will be\nbootstrapped into talking with each other. Finally if everything went ok\nyou’ll see a message like that:</p><p>This means that there is at least a master instance serving each of the\n16384 slots available.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"CREATING THE CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-creating-a-redis-cluster-using-the-create-cluster-script\">Creating a Redis Cluster using the create-cluster script</h2><p>If you don’t want to create a Redis Cluster by configuring and executing\nindividual instances manually as explained above, there is a much simpler\nsystem (but you’ll not learn the same amount of operational details).</p><p>Just check <code>utils/create-cluster</code> directory in the Redis distribution.\nThere is a script called <code>create-cluster</code> inside (same name as the directory\nit is contained into), it’s a simple bash script. In order to start\na 6 nodes cluster with 3 masters and 3 slaves just type the following\ncommands:</p><p>Reply to <code>yes</code> in step 2 when the <code>redis-trib</code> utility wants you to accept\nthe cluster layout.</p><p>You can now interact with the cluster, the first node will start at port 30001\nby default. When you are done, stop the cluster with:</p><p>Please read the <code>README</code> inside this directory for more information on how\nto run the script.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"CREATING A REDIS CLUSTER USING THE CREATE-CLUSTER SCRIPT"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-playing-with-the-cluster\">Playing with the cluster</h2><p>At this stage one of the problems with Redis Cluster is the lack of\nclient libraries implementations.</p><p>I’m aware of the following implementations:</p><ul>\n<li><a href=\"http://github.com/antirez/redis-rb-cluster\">redis-rb-cluster</a> is a Ruby implementation written by me (@antirez) as a reference for other languages. It is a simple wrapper around the original redis-rb, implementing the minimal semantics to talk with the cluster efficiently.</li>\n<li><a href=\"https://github.com/Grokzen/redis-py-cluster\">redis-py-cluster</a> A port of redis-rb-cluster to Python. Supports majority of <em>redis-py</em> functionality. Is in active development.</li>\n<li>The popular <a href=\"https://github.com/nrk/predis\">Predis</a> has support for Redis Cluster, the support was recently updated and is in active development.</li>\n<li>The most used Java client, <a href=\"https://github.com/xetorthio/jedis\">Jedis</a> recently added support for Redis Cluster, see the <em>Jedis Cluster</em> section in the project README.</li>\n<li><a href=\"https://github.com/StackExchange/StackExchange.Redis\">StackExchange.Redis</a> offers support for C# (and should work fine with most .NET languages; VB, F#, etc)</li>\n<li><a href=\"https://github.com/thunks/thunk-redis\">thunk-redis</a> offers support for Node.js and io.js, it is a thunk/promise-based redis client with pipelining and cluster.</li>\n<li><a href=\"https://github.com/chasex/redis-go-cluster\">redis-go-cluster</a> is an implementation of Redis Cluster for the Go language using the <a href=\"https://github.com/garyburd/redigo\">Redigo library client</a> as the base client. Implements MGET/MSET via result aggregation.</li>\n<li>The <code>redis-cli</code> utility in the unstable branch of the Redis repository at GitHub implements a very basic cluster support when started with the <code>-c</code> switch.</li>\n</ul><p>An easy way to test Redis Cluster is either to try any of the above clients\nor simply the <code>redis-cli</code> command line utility. The following is an example\nof interaction using the latter:</p><p><strong>Note:</strong> if you created the cluster using the script your nodes may listen\nto different ports, starting from 30001 by default.</p><p>The redis-cli cluster support is very basic so it always uses the fact that\nRedis Cluster nodes are able to redirect a client to the right node.\nA serious client is able to do better than that, and cache the map between\nhash slots and nodes addresses, to directly use the right connection to the\nright node. The map is refreshed only when something changed in the cluster\nconfiguration, for example after a failover or after the system administrator\nchanged the cluster layout by adding or removing nodes.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"PLAYING WITH THE CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-writing-an-example-app-with-redis-rb-cluster\">Writing an example app with redis-rb-cluster</h2><p>Before going forward showing how to operate the Redis Cluster, doing things\nlike a failover, or a resharding, we need to create some example application\nor at least to be able to understand the semantics of a simple Redis Cluster\nclient interaction.</p><p>In this way we can run an example and at the same time try to make nodes\nfailing, or start a resharding, to see how Redis Cluster behaves under real\nworld conditions. It is not very helpful to see what happens while nobody\nis writing to the cluster.</p><p>This section explains some basic usage of redis-rb-cluster showing two\nexamples. The first is the following, and is the <code>example.rb</code> file inside\nthe redis-rb-cluster distribution:</p><p>The application does a very simple thing, it sets keys in the form <code>foo&lt;number&gt;</code> to <code>number</code>, one after the other. So if you run the program the result is the\nfollowing stream of commands:</p><ul>\n<li>SET foo0 0</li>\n<li>SET foo1 1</li>\n<li>SET foo2 2</li>\n<li>And so forth…</li>\n</ul><p>The program looks more complex than it should usually as it is designed to\nshow errors on the screen instead of exiting with an exception, so every\noperation performed with the cluster is wrapped by <code>begin</code> <code>rescue</code> blocks.</p><p>The <strong>line 7</strong> is the first interesting line in the program. It creates the\nRedis Cluster object, using as argument a list of <em>startup nodes</em>, the maximum\nnumber of connections this object is allowed to take against different nodes,\nand finally the timeout after a given operation is considered to be failed.</p><p>The startup nodes don’t need to be all the nodes of the cluster. The important\nthing is that at least one node is reachable. Also note that redis-rb-cluster\nupdates this list of startup nodes as soon as it is able to connect with the\nfirst node. You should expect such a behavior with any other serious client.</p><p>Now that we have the Redis Cluster object instance stored in the <strong>rc</strong> variable\nwe are ready to use the object like if it was a normal Redis object instance.</p><p>This is exactly what happens in <strong>line 11 to 19</strong>: when we restart the example\nwe don’t want to start again with <code>foo0</code>, so we store the counter inside\nRedis itself. The code above is designed to read this counter, or if the\ncounter does not exist, to assign it the value of zero.</p><p>However note how it is a while loop, as we want to try again and again even\nif the cluster is down and is returning errors. Normal applications don’t need\nto be so careful.</p><p><strong>Lines between 21 and 30</strong> start the main loop where the keys are set or\nan error is displayed.</p><p>Note the <code>sleep</code> call at the end of the loop. In your tests you can remove\nthe sleep if you want to write to the cluster as fast as possible (relatively\nto the fact that this is a busy loop without real parallelism of course, so\nyou’ll get the usually 10k ops/second in the best of the conditions).</p><p>Normally writes are slowed down in order for the example application to be\neasier to follow by humans.</p><p>Starting the application produces the following output:</p><p>This is not a very interesting program and we’ll use a better one in a moment\nbut we can already see what happens during a resharding when the program\nis running.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"WRITING AN EXAMPLE APP WITH REDIS-RB-CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-resharding-the-cluster\">Resharding the cluster</h2><p>Now we are ready to try a cluster resharding. To do this please\nkeep the example.rb program running, so that you can see if there is some\nimpact on the program running. Also you may want to comment the <code>sleep</code>\ncall in order to have some more serious write load during resharding.</p><p>Resharding basically means to move hash slots from a set of nodes to another\nset of nodes, and like cluster creation it is accomplished using the\nredis-trib utility.</p><p>To start a resharding just type:</p><p>You only need to specify a single node, redis-trib will find the other nodes\nautomatically.</p><p>Currently redis-trib is only able to reshard with the administrator support,\nyou can’t just say move 5% of slots from this node to the other one (but\nthis is pretty trivial to implement). So it starts with questions. The first\nis how much a big resharding do you want to do:</p><p>We can try to reshard 1000 hash slots, that should already contain a non\ntrivial amount of keys if the example is still running without the sleep\ncall.</p><p>Then redis-trib needs to know what is the target of the resharding, that is,\nthe node that will receive the hash slots.\nI’ll use the first master node, that is, 127.0.0.1:7000, but I need\nto specify the Node ID of the instance. This was already printed in a\nlist by redis-trib, but I can always find the ID of a node with the following\ncommand if I need:</p><p>Ok so my target node is 97a3a64667477371c4479320d683e4c8db5858b1.</p><p>Now you’ll get asked from what nodes you want to take those keys.\nI’ll just type <code>all</code> in order to take a bit of hash slots from all the\nother master nodes.</p><p>After the final confirmation you’ll see a message for every slot that\nredis-trib is going to move from a node to another, and a dot will be printed\nfor every actual key moved from one side to the other.</p><p>While the resharding is in progress you should be able to see your\nexample program running unaffected. You can stop and restart it multiple times\nduring the resharding if you want.</p><p>At the end of the resharding, you can test the health of the cluster with\nthe following command:</p><p>All the slots will be covered as usually, but this time the master at\n127.0.0.1:7000 will have more hash slots, something around 6461.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"RESHARDING THE CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-scripting-a-resharding-operation\">Scripting a resharding operation</h2><p>Reshardings can be performed automatically without the need to manually\nenter the parameters in an interactive way. This is possible using a command\nline like the following:</p><p>This allows to build some automatism if you are likely to reshard often,\nhowever currently there is no way for <code>redis-trib</code> to automatically\nrebalance the cluster checking the distribution of keys across the cluster\nnodes and intelligently moving slots as needed. This feature will be added\nin the future.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"SCRIPTING A RESHARDING OPERATION"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-a-more-interesting-example-application\">A more interesting example application</h2><p>The example application we wrote early is not very good.\nIt writes to the cluster in a simple way without even checking if what was\nwritten is the right thing.</p><p>From our point of view the cluster receiving the writes could just always\nwrite the key <code>foo</code> to <code>42</code> to every operation, and we would not notice at\nall.</p><p>So in the <code>redis-rb-cluster</code> repository, there is a more interesting application\nthat is called <code>consistency-test.rb</code>. It uses a set of counters, by default 1000, and sends <code>INCR</code> commands in order to increment the counters.</p><p>However instead of just writing, the application does two additional things:</p><ul>\n<li>When a counter is updated using <code>INCR</code>, the application remembers the write.</li>\n<li>It also reads a random counter before every write, and check if the value is what we expected it to be, comparing it with the value it has in memory.</li>\n</ul><p>What this means is that this application is a simple <strong>consistency checker</strong>,\nand is able to tell you if the cluster lost some write, or if it accepted\na write that we did not receive acknowledgment for. In the first case we’ll\nsee a counter having a value that is smaller than the one we remember, while\nin the second case the value will be greater.</p><p>Running the consistency-test application produces a line of output every\nsecond:</p><p>The line shows the number of <strong>R</strong>eads and <strong>W</strong>rites performed, and the\nnumber of errors (query not accepted because of errors since the system was\nnot available).</p><p>If some inconsistency is found, new lines are added to the output.\nThis is what happens, for example, if I reset a counter manually while\nthe program is running:</p><p>When I set the counter to 0 the real value was 114, so the program reports\n114 lost writes (<code>INCR</code> commands that are not remembered by the cluster).</p><p>This program is much more interesting as a test case, so we’ll use it\nto test the Redis Cluster failover.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"A MORE INTERESTING EXAMPLE APPLICATION"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-testing-the-failover\">Testing the failover</h2><p>Note: during this test, you should take a tab open with the consistency test\napplication running.</p><p>In order to trigger the failover, the simplest thing we can do (that is also\nthe semantically simplest failure that can occur in a distributed system)\nis to crash a single process, in our case a single master.</p><p>We can identify a cluster and crash it with the following command:</p><p>Ok, so 7000, 7001, and 7002 are masters. Let’s crash node 7002 with the\n<strong>DEBUG SEGFAULT</strong> command:</p><p>Now we can look at the output of the consistency test to see what it reported.</p><p>As you can see during the failover the system was not able to accept 578 reads and 577 writes, however no inconsistency was created in the database. This may\nsound unexpected as in the first part of this tutorial we stated that Redis\nCluster can lose writes during the failover because it uses asynchronous\nreplication. What we did not say is that this is not very likely to happen\nbecause Redis sends the reply to the client, and the commands to replicate\nto the slaves, about at the same time, so there is a very small window to\nlose data. However the fact that it is hard to trigger does not mean that it\nis impossible, so this does not change the consistency guarantees provided\nby Redis cluster.</p><p>We can now check what is the cluster setup after the failover (note that\nin the meantime I restarted the crashed instance so that it rejoins the\ncluster as a slave):</p><p>Now the masters are running on ports 7000, 7001 and 7005. What was previously\na master, that is the Redis instance running on port 7002, is now a slave of\n7005.</p><p>The output of the <code>CLUSTER NODES</code> command may look intimidating, but it is actually pretty simple, and is composed of the following tokens:</p><ul>\n<li>Node ID</li>\n<li>ip:port</li>\n<li>flags: master, slave, myself, fail, …</li>\n<li>if it is a slave, the Node ID of the master</li>\n<li>Time of the last pending PING still waiting for a reply.</li>\n<li>Time of the last PONG received.</li>\n<li>Configuration epoch for this node (see the Cluster specification).</li>\n<li>Status of the link to this node.</li>\n<li>Slots served…</li>\n</ul>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"TESTING THE FAILOVER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-manual-failover\">Manual failover</h2><p>Sometimes it is useful to force a failover without actually causing any problem\non a master. For example in order to upgrade the Redis process of one of the\nmaster nodes it is a good idea to failover it in order to turn it into a slave\nwith minimal impact on availability.</p><p>Manual failovers are supported by Redis Cluster using the <code>CLUSTER FAILOVER</code>\ncommand, that must be executed in one of the <strong>slaves</strong> of the master you want\nto failover.</p><p>Manual failovers are special and are safer compared to failovers resulting from\nactual master failures, since they occur in a way that avoid data loss in the\nprocess, by switching clients from the original master to the new master only\nwhen the system is sure that the new master processed all the replication stream\nfrom the old one.</p><p>This is what you see in the slave log when you perform a manual failover:</p><p>Basically clients connected to the master we are failing over are stopped.\nAt the same time the master sends its replication offset to the slave, that\nwaits to reach the offset on its side. When the replication offset is reached,\nthe failover starts, and the old master is informed about the configuration\nswitch. When the clients are unblocked on the old master, they are redirected\nto the new master.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"MANUAL FAILOVER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-adding-a-new-node\">Adding a new node</h2><p>Adding a new node is basically the process of adding an empty node and then\nmoving some data into it, in case it is a new master, or telling it to\nsetup as a replica of a known node, in case it is a slave.</p><p>We’ll show both, starting with the addition of a new master instance.</p><p>In both cases the first step to perform is <strong>adding an empty node</strong>.</p><p>This is as simple as to start a new node in port 7006 (we already used\nfrom 7000 to 7005 for our existing 6 nodes) with the same configuration\nused for the other nodes, except for the port number, so what you should\ndo in order to conform with the setup we used for the previous nodes:</p><ul>\n<li>Create a new tab in your terminal application.</li>\n<li>Enter the <code>cluster-test</code> directory.</li>\n<li>Create a directory named <code>7006</code>.</li>\n<li>Create a redis.conf file inside, similar to the one used for the other nodes but using 7006 as port number.</li>\n<li>Finally start the server with <code>../redis-server ./redis.conf</code></li>\n</ul><p>At this point the server should be running.</p><p>Now we can use <strong>redis-trib</strong> as usually in order to add the node to\nthe existing cluster.</p><p>As you can see I used the <strong>add-node</strong> command specifying the address of the\nnew node as first argument, and the address of a random existing node in the\ncluster as second argument.</p><p>In practical terms redis-trib here did very little to help us, it just\nsent a <code>CLUSTER MEET</code> message to the node, something that is also possible\nto accomplish manually. However redis-trib also checks the state of the\ncluster before to operate, so it is a good idea to perform cluster operations\nalways via redis-trib even when you know how the internals work.</p><p>Now we can connect to the new node to see if it really joined the cluster:</p><p>Note that since this node is already connected to the cluster it is already\nable to redirect client queries correctly and is generally speaking part of\nthe cluster. However it has two peculiarities compared to the other masters:</p><ul>\n<li>It holds no data as it has no assigned hash slots.</li>\n<li>Because it is a master without assigned slots, it does not participate in the election process when a slave wants to become a master.</li>\n</ul><p>Now it is possible to assign hash slots to this node using the resharding\nfeature of <code>redis-trib</code>. It is basically useless to show this as we already\ndid in a previous section, there is no difference, it is just a resharding\nhaving as a target the empty node.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"ADDING A NEW NODE"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-adding-a-new-node-as-a-replica\">Adding a new node as a replica</h2><p>Adding a new Replica can be performed in two ways. The obvious one is to\nuse redis-trib again, but with the —slave option, like this:</p><p>Note that the command line here is exactly like the one we used to add\na new master, so we are not specifying to which master we want to add\nthe replica. In this case what happens is that redis-trib will add the new\nnode as replica of a random master among the masters with less replicas.</p><p>However you can specify exactly what master you want to target with your\nnew replica with the following command line:</p><p>This way we assign the new replica to a specific master.</p><p>A more manual way to add a replica to a specific master is to add the new\nnode as an empty master, and then turn it into a replica using the\n<code>CLUSTER REPLICATE</code> command. This also works if the node was added as a slave\nbut you want to move it as a replica of a different master.</p><p>For example in order to add a replica for the node 127.0.0.1:7005 that is\ncurrently serving hash slots in the range 11423-16383, that has a Node ID\n3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e, all I need to do is to connect\nwith the new node (already added as empty master) and send the command:</p><p>That’s it. Now we have a new replica for this set of hash slots, and all\nthe other nodes in the cluster already know (after a few seconds needed to\nupdate their config). We can verify with the following command:</p><p>The node 3c3a0c… now has two slaves, running on ports 7002 (the existing one) and 7006 (the new one).</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"ADDING A NEW NODE AS A REPLICA"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-removing-a-node\">Removing a node</h2><p>To remove a slave node just use the <code>del-node</code> command of redis-trib:</p><p>The first argument is just a random node in the cluster, the second argument\nis the ID of the node you want to remove.</p><p>You can remove a master node in the same way as well, <strong>however in order to\nremove a master node it must be empty</strong>. If the master is not empty you need\nto reshard data away from it to all the other master nodes before.</p><p>An alternative to remove a master node is to perform a manual failover of it\nover one of its slaves and remove the node after it turned into a slave of the\nnew master. Obviously this does not help when you want to reduce the actual\nnumber of masters in your cluster, in that case, a resharding is needed.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REMOVING A NODE"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-replicas-migration\">Replicas migration</h2><p>In Redis Cluster it is possible to reconfigure a slave to replicate with a\ndifferent master at any time just using the following command:</p><p>However there is a special scenario where you want replicas to move from one\nmaster to another one automatically, without the help of the system administrator.\nThe automatic reconfiguration of replicas is called <em>replicas migration</em> and is\nable to improve the reliability of a Redis Cluster.</p><p>Note: you can read the details of replicas migration in the <a href=\"/topics/cluster-spec\">Redis Cluster Specification</a>, here we’ll only provide some information about the\ngeneral idea and what you should do in order to benefit from it.</p><p>The reason why you may want to let your cluster replicas to move from one master\nto another under certain condition, is that usually the Redis Cluster is as\nresistant to failures as the number of replicas attached to a given master.</p><p>For example a cluster where every master has a single replica can’t continue\noperations if the master and its replica fail at the same time, simply because\nthere is no other instance to have a copy of the hash slots the master was\nserving. However while netsplits are likely to isolate a number of nodes\nat the same time, many other kind of failures, like hardware or software failures\nlocal to a single node, are a very notable class of failures that are unlikely\nto happen at the same time, so it is possible that in your cluster where\nevery master has a slave, the slave is killed at 4am, and the master is killed\nat 6am. This still will result in a cluster that can no longer operate.</p><p>To improve reliability of the system we have the option to add additional\nreplicas to every master, but this is expensive. Replica migration allows to\nadd more slaves to just a few masters. So you have 10 masters with 1 slave\neach, for a total of 20 instances. However you add, for example, 3 instances\nmore as slaves of some of your masters, so certain masters will have more\nthan a single slave.</p><p>With replicas migration what happens is that if a master is left without\nslaves, a replica from a master that has multiple slaves will migrate to\nthe <em>orphaned</em> master. So after your slave goes down at 4am as in the example\nwe made above, another slave will take its place, and when the master\nwill fail as well at 5am, there is still a slave that can be elected so that\nthe cluster can continue to operate.</p><p>So what you should know about replicas migration in short?</p><ul>\n<li>The cluster will try to migrate a replica from the master that has the greatest number of replicas in a given moment.</li>\n<li>To benefit from replica migration you have just to add a few more replicas to a single master in your cluster, it does not matter what master.</li>\n<li>There is a configuration parameter that controls the replica migration feature that is called <code>cluster-migration-barrier</code>: you can read more about it in the example <code>redis.conf</code> file provided with Redis Cluster.</li>\n</ul>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REPLICAS MIGRATION"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-upgrading-nodes-in-a-redis-cluster\">Upgrading nodes in a Redis Cluster</h2><p>Upgrading slave nodes is easy since you just need to stop the node and restart\nit with an updated version of Redis. If there are clients scaling reads using\nslave nodes, they should be able to reconnect to a different slave if a given\none is not available.</p><p>Upgrading masters is a bit more complex, and the suggested procedure is:</p><p>Following this procedure you should upgrade one node after the other until\nall the nodes are upgraded.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"UPGRADING NODES IN A REDIS CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-migrating-to-redis-cluster\">Migrating to Redis Cluster</h2><p>Users willing to migrate to Redis Cluster may have just a single master, or\nmay already using a preexisting sharding setup, where keys\nare split among N nodes, using some in-house algorithm or a sharding algorithm\nimplemented by their client library or Redis proxy.</p><p>In both cases it is possible to migrate to Redis Cluster easily, however\nwhat is the most important detail is if multiple-keys operations are used\nby the application, and how. There are three different cases:</p><p>The third case is not handled by Redis Cluster: the application requires to\nbe modified in order to don’t use multi keys operations or only use them in\nthe context of the same hash tag.</p><p>Case 1 and 2 are covered, so we’ll focus on those two cases, that are handled\nin the same way, so no distinction will be made in the documentation.</p><p>Assuming you have your preexisting data set split into N masters, where\nN=1 if you have no preexisting sharding, the following steps are needed\nin order to migrate your data set to Redis Cluster:</p><p>There is an alternative way to import data from external instances to a Redis\nCluster, which is to use the <code>redis-trib import</code> command.</p><p>The command moves all the keys of a running instance (deleting the keys from\nthe source instance) to the specified pre-existing Redis Cluster. However\nnote that if you use a Redis 2.8 instance as source instance the operation\nmay be slow since 2.8 does not implement migrate connection caching, so you\nmay want to restart your source instance with a Redis 3.x version before\nto perform such operation.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"MIGRATING TO REDIS CLUSTER"},{"content":"<h1 id=\"redis-configuration\">Redis configuration</h1><p>Redis is able to start without a configuration file using a built-in default\nconfiguration, however this setup is only recommended for testing and\ndevelopment purposes.</p><p>The proper way to configure Redis is by providing a Redis configuration file,\nusually called <code>redis.conf</code>.</p><p>The <code>redis.conf</code> file contains a number of directives that have a very simple\nformat:</p><p>This is an example of configuration directive:</p><p>It is possible to provide strings containing spaces as arguments using\nquotes, as in the following example:</p><p>The list of configuration directives, and their meaning and intended usage\nis available in the self documented example redis.conf shipped into the\nRedis distribution.</p><ul>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/antirez/redis/3.0/redis.conf\">redis.conf for Redis 3.0</a></li>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/antirez/redis/2.8/redis.conf\">redis.conf for Redis 2.8</a></li>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/antirez/redis/2.6/redis.conf\">redis.conf for Redis 2.6</a>.</li>\n<li>The self documented <a href=\"https://raw.githubusercontent.com/antirez/redis/2.4/redis.conf\">redis.conf for Redis 2.4</a>.</li>\n</ul>","link":"./alpha/topics/config.html","spaLink":"#/alpha/topics/config","title":"REDIS CONFIGURATION"},{"content":"<h2 id=\"redis-configuration-passing-arguments-via-the-command-line\">Passing arguments via the command line</h2><p>Since Redis 2.6 it is possible to also pass Redis configuration parameters\nusing the command line directly. This is very useful for testing purposes.\nThe following is an example that starts a new Redis instance using port 6380\nas a slave of the instance running at 127.0.0.1 port 6379.</p><p>The format of the arguments passed via the command line is exactly the same\nas the one used in the redis.conf file, with the exception that the keyword\nis prefixed with <code>--</code>.</p><p>Note that internally this generates an in-memory temporary config file\n(possibly concatenating the config file passed by the user if any) where\narguments are translated into the format of redis.conf.</p>","link":"./alpha/topics/config.html","spaLink":"#/alpha/topics/config","title":"PASSING ARGUMENTS VIA THE COMMAND LINE"},{"content":"<h2 id=\"redis-configuration-changing-redis-configuration-while-the-server-is-running\">Changing Redis configuration while the server is running</h2><p>It is possible to reconfigure Redis on the fly without stopping and restarting\nthe service, or querying the current configuration programmatically using the\nspecial commands <a href=\"/commands/config-set\">CONFIG SET</a> and\n<a href=\"/commands/config-get\">CONFIG GET</a></p><p>Not all the configuration directives are supported in this way, but most\nare supported as expected. Please refer to the\n<a href=\"/commands/config-set\">CONFIG SET</a> and <a href=\"/commands/config-get\">CONFIG GET</a>\npages for more information.</p><p>Note that modifying the configuration on the fly <strong>has no effects on the\nredis.conf file</strong> so at the next restart of Redis the old configuration will\nbe used instead.</p><p>Make sure to also modify the <code>redis.conf</code> file accordingly to the configuration\nyou set using <a href=\"/commands/config-set\">CONFIG SET</a>. You can do it manually, or starting with Redis 2.8, you can just use <a href=\"/commands/config-rewrite\">CONFIG REWRITE</a>, which will automatically scan your <code>redis.conf</code> file and update the fields which don’t match the current configuration value. Fields non existing but set to the default value are not added. Comments inside your configuration file are retained.</p>","link":"./alpha/topics/config.html","spaLink":"#/alpha/topics/config","title":"CHANGING REDIS CONFIGURATION WHILE THE SERVER IS RUNNING"},{"content":"<h2 id=\"redis-configuration-configuring-redis-as-a-cache\">Configuring Redis as a cache</h2><p>If you plan to use Redis just as a cache where every key will have an\nexpire set, you may consider using the following configuration instead\n(assuming a max memory limit of 2 megabytes as an example):</p><p>In this configuration there is no need for the application to set a\ntime to live for keys using the <code>EXPIRE</code> command (or equivalent) since\nall the keys will be evicted using an approximated LRU algorithm as long\nas we hit the 2 megabyte memory limit.</p><p>Basically in this configuration Redis acts in a similar way to memcached.\nWe have more extensive documentation about <a href=\"/topics/lru-cache\">using Redis as an LRU cache</a>.</p>","link":"./alpha/topics/config.html","spaLink":"#/alpha/topics/config","title":"CONFIGURING REDIS AS A CACHE"},{"content":"<h1 id=\"an-introduction-to-redis-data-types-and-abstractions\">An introduction to Redis data types and abstractions</h1><p>Redis is not a <em>plain</em> key-value store, actually it is a <em>data structures server</em>, supporting different kind of values. What this means is that, while in\ntraditional key-value stores you associated string keys to string values, in\nRedis the value is not limited to a simple string, but can also hold more complex\ndata structures. The following is the list of all the data structures supported\nby Redis, which will be covered separately in this tutorial:</p><ul>\n<li>Binary-safe strings.</li>\n<li>Lists: collections of string elements sorted according to the order of insertion. They are basically <em>linked lists</em>.</li>\n<li>Sets: collections of unique, unsorted string elements.</li>\n<li>Sorted sets, similar to Sets but where every string element is associated to a\nfloating number value, called <em>score</em>. The elements are always taken sorted\nby their score, so unlike Sets it is possible to retrieve a range of elements\n(for example you may ask: give me the top 10, or the bottom 10).</li>\n<li>Hashes, which are maps composed of fields associated with values. Both the\nfield and the value are strings. This is very similar to Ruby or Python\nhashes.</li>\n<li>Bit arrays (or simply bitmaps): it is possible, using special commands, to\nhandle String values like an array of bits: you can set and clear individual\nbits, count all the bits set to 1, find the first set or unset bit, and so\nforth.</li>\n<li>HyperLogLogs: this is a probabilistic data structure which is used in order\nto estimate the cardinality of a set. Don’t be scared, it is simpler than\nit seems… See later in the HyperLogLog section of this tutorial.</li>\n</ul><p>It’s not always trivial to grasp how these data types work and what to use in\norder to solve a given problem from the <a href=\"/commands\">command reference</a>, so this\ndocument is a crash course to Redis data types and their most common patterns.</p><p>For all the examples we’ll use the <code>redis-cli</code> utility, a simple but\nhandy command-line utility, to issue commands against the Redis server.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"AN INTRODUCTION TO REDIS DATA TYPES AND ABSTRACTIONS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-keys\">Redis keys</h2><p>Redis keys are binary safe, this means that you can use any binary sequence as a\nkey, from a string like “foo” to the content of a JPEG file.\nThe empty string is also a valid key.</p><p>A few other rules about keys:</p><ul>\n<li>Very long keys are not a good idea. For instance a key of 1024 bytes is a bad\nidea not only memory-wise, but also because the lookup of the key in the\ndataset may require several costly key-comparisons. Even when the task at hand\nis to match the existence of a large value, hashing it (for example\nwith SHA1) is a better idea, especially from the perspective of memory\nand bandwidth.</li>\n<li>Very short keys are often not a good idea. There is little point in writing\n“u1000flw” as a key if you can instead write “user:1000:followers”.  The latter\nis more readable and the added space is minor compared to the space used by\nthe key object itself and the value object. While short keys will obviously\nconsume a bit less memory, your job is to find the right balance.</li>\n<li>Try to stick with a schema. For instance “object-type:id” is a good\nidea, as in “user:1000”. Dots or dashes are often used for multi-word\nfields, as in “comment:1234:reply.to” or “comment:1234:reply-to”.</li>\n<li>The maximum allowed key size is 512 MB.</li>\n</ul><p><a name=\"strings\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS KEYS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-strings\">Redis Strings</h2><p>The Redis String type is the simplest type of value you can associate with\na Redis key. It is the only data type in Memcached, so it is also very natural\nfor newcomers to use it in Redis.</p><p>Since Redis keys are strings, when we use the string type as a value too,\nwe are mapping a string to another string. The string data type is useful\nfor a number of use cases, like caching HTML fragments or pages.</p><p>Let’s play a bit with the string type, using <code>redis-cli</code> (all the examples\nwill be performed via <code>redis-cli</code> in this tutorial).</p><p>As you can see using the <code>SET</code> and the <code>GET</code> commands are the way we set\nand retrieve a string value. Note that <code>SET</code> will replace any existing value\nalready stored into the key, in the case that the key already exists, even if\nthe key is associated with a non-string value. So <code>SET</code> performs an assignment.</p><p>Values can be strings (including binary data) of every kind, for instance you\ncan store a jpeg image inside a key. A value can’t be bigger than 512 MB.</p><p>The <code>SET</code> command has interesting options, that are provided as additional\narguments. For example, I may ask <code>SET</code> to fail if the key already exists,\nor the opposite, that it only succeed if the key already exists:</p><p>Even if strings are the basic values of Redis, there are interesting operations\nyou can perform with them. For instance, one is atomic increment:</p><p>The <a href=\"/commands/incr\">INCR</a> command parses the string value as an integer,\nincrements it by one, and finally sets the obtained value as the new value.\nThere are other similar commands like <a href=\"/commands/incrby\">INCRBY</a>,\n<a href=\"/commands/decr\">DECR</a> and <a href=\"/commands/decrby\">DECRBY</a>. Internally it’s\nalways the same command, acting in a slightly different way.</p><p>What does it mean that INCR is atomic?\nThat even multiple clients issuing INCR against\nthe same key will never enter into a race condition. For instance, it will never\nhappen that client 1 reads “10”, client 2 reads “10” at the same time, both\nincrement to 11, and set the new value to 11. The final value will always be\n12 and the read-increment-set operation is performed while all the other\nclients are not executing a command at the same time.</p><p>There are a number of commands for operating on strings. For example\nthe <code>GETSET</code> command sets a key to a new value, returning the old value as the\nresult. You can use this command, for example, if you have a\nsystem that increments a Redis key using <code>INCR</code>\nevery time your web site receives a new visitor. You may want to collect this\ninformation once every hour, without losing a single increment.\nYou can <code>GETSET</code> the key, assigning it the new value of “0” and reading the\nold value back.</p><p>The ability to set or retrieve the value of multiple keys in a single\ncommand is also useful for reduced latency. For this reason there are\nthe <code>MSET</code> and <code>MGET</code> commands:</p><p>When <code>MGET</code> is used, Redis returns an array of values.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS STRINGS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-altering-and-querying-the-key-space\">Altering and querying the key space</h2><p>There are commands that are not defined on particular types, but are useful\nin order to interact with the space of keys, and thus, can be used with\nkeys of any type.</p><p>For example the <code>EXISTS</code> command returns 1 or 0 to signal if a given key\nexists or not in the database, while the <code>DEL</code> command deletes a key\nand associated value, whatever the value is.</p><p>From the examples you can also see how <code>DEL</code> itself returns 1 or 0 depending on whether\nthe key was removed (it existed) or not (there was no such key with that\nname).</p><p>There are many key space related commands, but the above two are the\nessential ones together with the <code>TYPE</code> command, which returns the kind\nof value stored at the specified key:</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"ALTERING AND QUERYING THE KEY SPACE"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-expires-keys-with-limited-time-to-live\">Redis expires: keys with limited time to live</h2><p>Before continuing with more complex data structures, we need to discuss\nanother feature which works regardless of the value type, and is\ncalled <strong>Redis expires</strong>. Basically you can set a timeout for a key, which\nis a limited time to live. When the time to live elapses, the key is\nautomatically destroyed, exactly as if the user called the <code>DEL</code> command\nwith the key.</p><p>A few quick info about Redis expires:</p><ul>\n<li>They can be set both using seconds or milliseconds precision.</li>\n<li>However the expire time resolution is always 1 millisecond.</li>\n<li>Information about expires are replicated and persisted on disk, the time virtually passes when your Redis server remains stopped (this means that Redis saves the date at which a key will expire).</li>\n</ul><p>Setting an expire is trivial:</p><p>The key vanished between the two <code>GET</code> calls, since the second call was\ndelayed more than 5 seconds. In the example above we used <code>EXPIRE</code> in\norder to set the expire (it can also be used in order to set a different\nexpire to a key already having one, like <code>PERSIST</code> can be used in order\nto remove the expire and make the key persistent forever). However we\ncan also create keys with expires using other Redis commands. For example\nusing <code>SET</code> options:</p><p>The example above sets a key with the string value <code>100</code>, having an expire\nof ten seconds. Later the <code>TTL</code> command is called in order to check the\nremaining time to live for the key.</p><p>In order to set and check expires in milliseconds, check the <code>PEXPIRE</code> and\nthe <code>PTTL</code> commands, and the full list of <code>SET</code> options.</p><p><a name=\"lists\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS EXPIRES: KEYS WITH LIMITED TIME TO LIVE"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-lists\">Redis Lists</h2><p>To explain the List data type it’s better to start with a little bit of theory,\nas the term <em>List</em> is often used in an improper way by information technology\nfolks. For instance “Python Lists” are not what the name may suggest (Linked\nLists), but rather Arrays (the same data type is called Array in\nRuby actually).</p><p>From a very general point of view a List is just a sequence of ordered\nelements: 10,20,1,2,3 is a list. But the properties of a List implemented using\nan Array are very different from the properties of a List implemented using a\n<em>Linked List</em>.</p><p>Redis lists are implemented via Linked Lists. This means that even if you have\nmillions of elements inside a list, the operation of adding a new element in\nthe head or in the tail of the list is performed <em>in constant time</em>. The speed of adding a\nnew element with the <code>LPUSH</code> command to the head of a list with ten\nelements is the same as adding an element to the head of list with 10\nmillion elements.</p><p>What’s the downside? Accessing an element <em>by index</em> is very fast in lists\nimplemented with an Array (constant time indexed access) and not so fast in\nlists implemented by linked lists (where the operation requires an amount of\nwork proportional to the index of the accessed element).</p><p>Redis Lists are implemented with linked lists because for a database system it\nis crucial to be able to add elements to a very long list in a very fast way.\nAnother strong advantage, as you’ll see in a moment, is that Redis Lists can be\ntaken at constant length in constant time.</p><p>When fast access to the middle of a large collection of elements is important,\nthere is a different data structure that can be used, called sorted sets.\nSorted sets will be covered later in this tutorial.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-first-steps-with-redis-lists\">First steps with Redis Lists</h2><p>The <code>LPUSH</code> command adds a new element into a list, on the\nleft (at the head), while the <code>RPUSH</code> command adds a new\nelement into a list ,on the right (at the tail). Finally the\n<code>LRANGE</code> command extracts ranges of elements from lists:</p><p>Note that <a href=\"/commands/lrange\">LRANGE</a> takes two indexes, the first and the last\nelement of the range to return. Both the indexes can be negative, telling Redis\nto start counting from the end: so -1 is the last element, -2 is the\npenultimate element of the list, and so forth.</p><p>As you can see <code>RPUSH</code> appended the elements on the right of the list, while\nthe final <code>LPUSH</code> appended the element on the left.</p><p>Both commands are <em>variadic commands</em>, meaning that you are free to push\nmultiple elements into a list in a single call:</p><p>An important operation defined on Redis lists is the ability to <em>pop elements</em>.\nPopping elements is the operation of both retrieving the element from the list,\nand eliminating it from the list, at the same time. You can pop elements\nfrom left and right, similarly to how you can push elements in both sides\nof the list:</p><p>We added three elements and popped three elements, so at the end of this\nsequence of commands the list is empty and there are no more elements to\npop. If we try to pop yet another element, this is the result we get:</p><p>Redis returned a NULL value to signal that there are no elements into the\nlist.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"FIRST STEPS WITH REDIS LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-common-use-cases-for-lists\">Common use cases for lists</h2><p>Lists are useful for a number of tasks, two very representative use cases\nare the following:</p><ul>\n<li>Remember the latest updates posted by users into a social network.</li>\n<li>Communication between processes, using a consumer-producer pattern where the producer pushes items into a list, and a consumer (usually a <em>worker</em>) consumes those items and executed actions. Redis has special list commands to make this use case both more reliable and efficient.</li>\n</ul><p>For example both the popular Ruby libraries <a href=\"https://github.com/resque/resque\">resque</a> and\n<a href=\"https://github.com/mperham/sidekiq\">sidekiq</a> use Redis lists under the hood in order to\nimplement background jobs.</p><p>The popular Twitter social network <a href=\"http://www.infoq.com/presentations/Real-Time-Delivery-Twitter\">takes the latest tweets</a>\nposted by users into Redis lists.</p><p>To describe a common use case step by step, imagine your home page shows the latest\nphotos published in a photo sharing social network and you want to speedup access.</p><ul>\n<li>Every time a user posts a new photo, we add its ID into a list with <code>LPUSH</code>.</li>\n<li>When users visit the home page, we use <code>LRANGE 0 9</code> in order to get the latest 10 posted items.</li>\n</ul>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"COMMON USE CASES FOR LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-capped-lists\">Capped lists</h2><p>In many use cases we just want to use lists to store the <em>latest items</em>,\nwhatever they are: social network updates, logs, or anything else.</p><p>Redis allows us to use lists as a capped collection, only remembering the latest\nN items and discarding all the oldest items using the <code>LTRIM</code> command.</p><p>The <code>LTRIM</code> command is similar to <code>LRANGE</code>, but <strong>instead of displaying the\nspecified range of elements</strong> it sets this range as the new list value. All\nthe elements outside the given range are removed.</p><p>An example will make it more clear:</p><p>The above <code>LTRIM</code> command tells Redis to take just list elements from index\n0 to 2, everything else will be discarded. This allows for a very simple but\nuseful pattern: doing a List push operation + a List trim operation together\nin order to add a new element and discard elements exceeding a limit:</p><p>The above combination adds a new element and takes only the 1000\nnewest elements into the list. With <code>LRANGE</code> you can access the top items\nwithout any need to remember very old data.</p><p>Note: while <code>LRANGE</code> is technically an O(N) command, accessing small ranges\ntowards the head or the tail of the list is a constant time operation.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"CAPPED LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-blocking-operations-on-lists\">Blocking operations on lists</h2><p>Lists have a special feature that make them suitable to implement queues,\nand in general as a building block for inter process communication systems:\nblocking operations.</p><p>Imagine you want to push items into a list with one process, and use\na different process in order to actually do some kind of work with those\nitems. This is the usual producer / consumer setup, and can be implemented\nin the following simple way:</p><ul>\n<li>To push items into the list, producers call <code>LPUSH</code>.</li>\n<li>To extract / process items from the list, consumers call <code>RPOP</code>.</li>\n</ul><p>However it is possible that sometimes the list is empty and there is nothing\nto process, so <code>RPOP</code> just returns NULL. In this case a consumer is forced to wait\nsome time and retry again with <code>RPOP</code>. This is called <em>polling</em>, and is not\na good idea in this context because it has several drawbacks:</p><p>So Redis implements commands called <code>BRPOP</code> and <code>BLPOP</code> which are versions\nof <code>RPOP</code> and <code>LPOP</code> able to block if the list is empty: they’ll return to\nthe caller only when a new element is added to the list, or when a user-specified\ntimeout is reached.</p><p>This is an example of a <code>BRPOP</code> call we could use in the worker:</p><p>It means: “wait for elements in the list <code>tasks</code>, but return if after 5 seconds\nno element is available”.</p><p>Note that you can use 0 as timeout to wait for elements forever, and you can\nalso specify multiple lists and not just one, in order to wait on multiple\nlists at the same time, and get notified when the first list receives an\nelement.</p><p>A few things to note about <code>BRPOP</code>:</p><p>There are more things you should know about lists and blocking ops. We\nsuggest that you read more on the following:</p><ul>\n<li>It is possible to build safer queues or rotating queues using <code>RPOPLPUSH</code>.</li>\n<li>There is also a blocking variant of the command, called <code>BRPOPLPUSH</code>.</li>\n</ul>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"BLOCKING OPERATIONS ON LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-automatic-creation-and-removal-of-keys\">Automatic creation and removal of keys</h2><p>So far in our examples we never had to create empty lists before pushing\nelements, or removing empty lists when they no longer have elements inside.\nIt is Redis’ responsibility to delete keys when lists are left empty, or to create\nan empty list if the key does not exist and we are trying to add elements\nto it, for example, with <code>LPUSH</code>.</p><p>This is not specific to lists, it applies to all the Redis data types\ncomposed of multiple elements — Sets, Sorted Sets and Hashes.</p><p>Basically we can summarize the behavior with three rules:</p><p>Examples of rule 1:</p><p>However we can’t perform operations against the wrong type of the key exists:</p><p>Example of rule 2:</p><p>The key no longer exists after all the elements are popped.</p><p>Example of rule 3:</p><p><a name=\"hashes\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"AUTOMATIC CREATION AND REMOVAL OF KEYS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-hashes\">Redis Hashes</h2><p>Redis hashes look exactly how one might expect a “hash” to look, with field-value pairs:</p><p>While hashes are handy to represent <em>objects</em>, actually the number of fields you can\nput inside a hash has no practical limits (other than available memory), so you can use\nhashes in many different ways inside your application.</p><p>The command <code>HMSET</code> sets multiple fields of the hash, while <code>HGET</code> retrieves\na single field. <code>HMGET</code> is similar to <code>HGET</code> but returns an array of values:</p><p>There are commands that are able to perform operations on individual fields\nas well, like <code>HINCRBY</code>:</p><p>You can find the <a href=\"http://redis.io/commands#hash\">full list of hash commands in the documentation</a>.</p><p>It is worth noting that small hashes (i.e., a few elements with small values) are\nencoded in special way in memory that make them very memory efficient.</p><p><a name=\"sets\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS HASHES"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-sets\">Redis Sets</h2><p>Redis Sets are unordered collections of strings. The\n<code>SADD</code> command adds new elements to a set. It’s also possible\nto do a number of other operations against sets like testing if a given element\nalready exists, performing the intersection, union or difference between\nmultiple sets, and so forth.</p><p>Here I’ve added three elements to my set and told Redis to return all the\nelements. As you can see they are not sorted — Redis is free to return the\nelements in any order at every call, since there is no contract with the\nuser about element ordering.</p><p>Redis has commands to test for membership. For example, checking if an element exists:</p><p>“3” is a member of the set, while “30” is not.</p><p>Sets are good for expressing relations between objects.\nFor instance we can easily use sets in order to implement tags.</p><p>A simple way to model this problem is to have a set for every object we\nwant to tag. The set contains the IDs of the tags associated with the object.</p><p>One illustration is tagging news articles.\nIf article ID 1000 is tagged with tags 1, 2, 5 and 77, a set\ncan associate these tag IDs with the news item:</p><p>We may also want to have the inverse relation as well: the list\nof all the news tagged with a given tag:</p><p>To get all the tags for a given object is trivial:</p><p>Note: in the example we assume you have another data structure, for example\na Redis hash, which maps tag IDs to tag names.</p><p>There are other non trivial operations that are still easy to implement\nusing the right Redis commands. For instance we may want a list of all the\nobjects with the tags 1, 2, 10, and 27 together. We can do this using\nthe <code>SINTER</code> command, which performs the intersection between different\nsets. We can use:</p><p>In addition to intersection you can also perform\nunions, difference, extract a random element, and so forth.</p><p>The command to extract an element is called <code>SPOP</code>, and is handy to model\ncertain problems. For example in order to implement a web-based poker game,\nyou may want to represent your deck with a set. Imagine we use a one-char\nprefix for (C)lubs, (D)iamonds, (H)earts, (S)pades:</p><p>Now we want to provide each player with 5 cards. The <code>SPOP</code> command\nremoves a random element, returning it to the client, so it is the\nperfect operation in this case.</p><p>However if we call it against our deck directly, in the next play of the\ngame we’ll need to populate the deck of cards again, which may not be\nideal. So to start, we can make a copy of the set stored in the <code>deck</code> key\ninto the <code>game:1:deck</code> key.</p><p>This is accomplished using <code>SUNIONSTORE</code>, which normally performs the\nunion between multiple sets, and stores the result into another set.\nHowever, since the union of a single set is itself, I can copy my deck\nwith:</p><p>Now I’m ready to provide the first player with five cards:</p><p>One pair of jacks, not great…</p><p>This is a good time to introduce the set command that provides the number\nof elements inside a set. This is often called the <em>cardinality of a set</em>\nin the context of set theory, so the Redis command is called <code>SCARD</code>.</p><p>The math works: 52 - 5 = 47.</p><p>When you need to just get random elements without removing them from the\nset, there is the <code>SRANDMEMBER</code> command suitable for the task. It also features\nthe ability to return both repeating and non-repeating elements.</p><p><a name=\"sorted-sets\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS SETS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-sorted-sets\">Redis Sorted sets</h2><p>Sorted sets are a data type which is similar to a mix between a Set and\na Hash. Like sets, sorted sets are composed of unique, non-repeating\nstring elements, so in some sense a sorted set is a set as well.</p><p>However while elements inside sets are not ordered, every element in\na sorted set is associated with a floating point value, called <em>the score</em>\n(this is why the type is also similar to a hash, since every element\nis mapped to a value).</p><p>Moreover, elements in a sorted sets are <em>taken in order</em> (so they are not\nordered on request, order is a peculiarity of the data structure used to\nrepresent sorted sets). They are ordered according to the following rule:</p><ul>\n<li>If A and B are two elements with a different score, then A &gt; B if A.score is &gt; B.score.</li>\n<li>If A and B have exactly the same score, then A &gt; B if the A string is lexicographically greater than the B string. A and B strings can’t be equal since sorted sets only have unique elements.</li>\n</ul><p>Let’s start with a simple example, adding a few selected hackers names as\nsorted set elements, with their year of birth as “score”.</p><p>As you can see <code>ZADD</code> is similar to <code>SADD</code>, but takes one additional argument\n(placed before the element to be added) which is the score.\n<code>ZADD</code> is also variadic, so you are free to specify multiple score-value\npairs, even if this is not used in the example above.</p><p>With sorted sets it is trivial to return a list of hackers sorted by their\nbirth year because actually <em>they are already sorted</em>.</p><p>Implementation note: Sorted sets are implemented via a\ndual-ported data structure containing both a skip list and a hash table, so\nevery time we add an element Redis performs an O(log(N)) operation. That’s\ngood, but when we ask for sorted elements Redis does not have to do any work at\nall, it’s already all sorted:</p><p>Note: 0 and -1 means from element index 0 to the last element (-1 works\nhere just as it does in the case of the <code>LRANGE</code> command).</p><p>What if I want to order them the opposite way, youngest to oldest?\nUse <a href=\"/commands/zrevrange\">ZREVRANGE</a> instead of <a href=\"/commands/zrange\">ZRANGE</a>:</p><p>It is possible to return scores as well, using the <code>WITHSCORES</code> argument:</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS SORTED SETS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-operating-on-ranges\">Operating on ranges</h2><p>Sorted sets are more powerful than this. They can operate on ranges.\nLet’s get all the individuals that were born up to 1950 inclusive. We\nuse the <code>ZRANGEBYSCORE</code> command to do it:</p><p>We asked Redis to return all the elements with a score between negative\ninfinity and 1950 (both extremes are included).</p><p>It’s also possible to remove ranges of elements. Let’s remove all\nthe hackers born between 1940 and 1960 from the sorted set:</p><p><code>ZREMRANGEBYSCORE</code> is perhaps not the best command name,\nbut it can be very useful, and returns the number of removed elements.</p><p>Another extremely useful operation defined for sorted set elements\nis the get-rank operation. It is possible to ask what is the\nposition of an element in the set of the ordered elements.</p><p>The <code>ZREVRANK</code> command is also available in order to get the rank, considering\nthe elements sorted a descending way.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"OPERATING ON RANGES"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-lexicographical-scores\">Lexicographical scores</h2><p>With recent versions of Redis 2.8, a new feature was introduced that allows\ngetting ranges lexicographically, assuming elements in a sorted set are all\ninserted with the same identical score (elements are compared with the C\n<code>memcmp</code> function, so it is guaranteed that there is no collation, and every\nRedis instance will reply with the same output).</p><p>The main commands to operate with lexicographical ranges are <code>ZRANGEBYLEX</code>,\n<code>ZREVRANGEBYLEX</code>, <code>ZREMRANGEBYLEX</code> and <code>ZLEXCOUNT</code>.</p><p>For example, let’s add again our list of famous hackers, but this time\nuse a score of zero for all the elements:</p><p>Because of the sorted sets ordering rules, they are already sorted\nlexicographically:</p><p>Using <code>ZRANGEBYLEX</code> we can ask for lexicographical ranges:</p><p>Ranges can be inclusive or exclusive (depending on the first character),\nalso string infinite and minus infinite are specified respectively with\nthe <code>+</code> and <code>-</code> strings. See the documentation for more information.</p><p>This feature is important because it allows us to use sorted sets as a generic\nindex. For example, if you want to index elements by a 128-bit unsigned\ninteger argument, all you need to do is to add elements into a sorted\nset with the same score (for example 0) but with an 8 byte prefix\nconsisting of <strong>the 128 bit number in big endian</strong>. Since numbers in big\nendian, when ordered lexicographically (in raw bytes order) are actually\nordered numerically as well, you can ask for ranges in the 128 bit space,\nand get the element’s value discarding the prefix.</p><p>If you want to see the feature in the context of a more serious demo,\ncheck the <a href=\"http://autocomplete.redis.io\">Redis autocomplete demo</a>.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"LEXICOGRAPHICAL SCORES"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-updating-the-score-leader-boards\">Updating the score: leader boards</h2><p>Just a final note about sorted sets before switching to the next topic.\nSorted sets’ scores can be updated at any time. Just calling <code>ZADD</code> against\nan element already included in the sorted set will update its score\n(and position) with O(log(N)) time complexity.  As such, sorted sets are suitable\nwhen there are tons of updates.</p><p>Because of this characteristic a common use case is leader boards.\nThe typical application is a Facebook game where you combine the ability to\ntake users sorted by their high score, plus the get-rank operation, in order\nto show the top-N users, and the user rank in the leader board (e.g., “you are\nthe #4932 best score here”).</p><p><a name=\"bitmaps\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"UPDATING THE SCORE: LEADER BOARDS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-bitmaps\">Bitmaps</h2><p>Bitmaps are not an actual data type, but a set of bit-oriented operations\ndefined on the String type. Since strings are binary safe blobs and their\nmaximum length is 512 MB, they are suitable to set up to 2^32 different\nbits.</p><p>Bit operations are divided into two groups: constant-time single bit\noperations, like setting a bit to 1 or 0, or getting its value, and\noperations on groups of bits, for example counting the number of set\nbits in a given range of bits (e.g., population counting).</p><p>One of the biggest advantages of bitmaps is that they often provide\nextreme space savings when storing information. For example in a system\nwhere different users are represented by incremental user IDs, it is possible\nto remember a single bit information (for example, knowing whether\na user wants to receive a newsletter) of 4 billion of users using just 512 MB of memory.</p><p>Bits are set and retrieved using the <code>SETBIT</code> and <code>GETBIT</code> commands:</p><p>The <code>SETBIT</code> command takes as its first argument the bit number, and as its second\nargument the value to set the bit to, which is 1 or 0. The command\nautomatically enlarges the string if the addressed bit is outside the\ncurrent string length.</p><p><code>GETBIT</code> just returns the value of the bit at the specified index.\nOut of range bits (addressing a bit that is outside the length of the string\nstored into the target key) are always considered to be zero.</p><p>There are three commands operating on group of bits:</p><p>Both <code>BITPOS</code> and <code>BITCOUNT</code> are able to operate with byte ranges of the\nstring, instead of running for the whole length of the string. The following\nis a trivial example of <code>BITCOUNT</code> call:</p><p>Common user cases for bitmaps are:</p><ul>\n<li>Real time analytics of all kinds.</li>\n<li>Storing space efficient but high performance boolean information associated with object IDs.</li>\n</ul><p>For example imagine you want to know the longest streak of daily visits of\nyour web site users. You start counting days starting from zero, that is the\nday you made your web site public, and set a bit with <code>SETBIT</code> every time\nthe user visits the web site. As a bit index you simply take the current unix\ntime, subtract the initial offset, and divide by 3600*24.</p><p>This way for each user you have a small string containing the visit\ninformation for each day. With <code>BITCOUNT</code> it is possible to easily get\nthe number of days a given user visited the web site, while with\na few <code>BITPOS</code> calls, or simply fetching and analyzing the bitmap client-side,\nit is possible to easily compute the longest streak.</p><p>Bitmaps are trivial to split into multiple keys, for example for\nthe sake of sharding the data set and because in general it is better to\navoid working with huge keys. To split a bitmap across different keys\ninstead of setting all the bits into a key, a trivial strategy is just\nto store M bits per key and obtain the key name with <code>bit-number/M</code> and\nthe Nth bit to address inside the key with <code>bit-number MOD M</code>.</p><p><a name=\"hyperloglogs\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"BITMAPS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-hyperloglogs\">HyperLogLogs</h2><p>A HyperLogLog is a probabilistic data structure used in order to count\nunique things (technically this is referred to estimating the cardinality\nof a set). Usually counting unique items requires using an amount of memory\nproportional to the number of items you want to count, because you need\nto remember the elements you have already seen in the past in order to avoid\ncounting them multiple times. However there is a set of algorithms that trade\nmemory for precision: you end with an estimated measure with a standard error,\nin the case of the Redis implementation, which is less than 1%.  The\nmagic of this algorithm is that you no longer need to use an amount of memory\nproportional to the number of items counted, and instead can use a\nconstant amount of memory! 12k bytes in the worst case, or a lot less if your\nHyperLogLog (We’ll just call them HLL from now) has seen very few elements.</p><p>HLLs in Redis, while technically a different data structure, is encoded\nas a Redis string, so you can call <code>GET</code> to serialize a HLL, and <code>SET</code>\nto deserialize it back to the server.</p><p>Conceptually the HLL API is like using Sets to do the same task. You would\n<code>SADD</code> every observed element into a set, and would use <code>SCARD</code> to check the\nnumber of elements inside the set, which are unique since <code>SADD</code> will not\nre-add an existing element.</p><p>While you don’t really <em>add items</em> into an HLL, because the data structure\nonly contains a state that does not include actual elements, the API is the\nsame:</p><ul>\n<li>Every time you see a new element, you add it to the count with <code>PFADD</code>.</li>\n<li><p>Every time you want to retrieve the current approximation of the unique elements <em>added</em> with <code>PFADD</code> so far, you use the <code>PFCOUNT</code>.</p>\n<pre><code class=\"prettyprint prettyprinted\" style=\"\"><span class=\"pln\">  </span><span class=\"pun\">&gt;</span><span class=\"pln\"> pfadd hll a b c d\n  </span><span class=\"pun\">(</span><span class=\"pln\">integer</span><span class=\"pun\">)</span><span class=\"pln\"> </span><span class=\"lit\">1</span><span class=\"pln\">\n  </span><span class=\"pun\">&gt;</span><span class=\"pln\"> pfcount hll\n  </span><span class=\"pun\">(</span><span class=\"pln\">integer</span><span class=\"pun\">)</span><span class=\"pln\"> </span><span class=\"lit\">4</span></code></pre>\n</li>\n</ul><p>Every time you want to retrieve the current approximation of the unique elements <em>added</em> with <code>PFADD</code> so far, you use the <code>PFCOUNT</code>.</p><p>An example of use case for this data structure is counting unique queries\nperformed by users in a search form every day.</p><p>Redis is also able to perform the union of HLLs, please check the\n<a href=\"/commands#hyperloglog\">full documentation</a> for more information.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"HYPERLOGLOGS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-other-notable-features\">Other notable features</h2><p>There are other important things in the Redis API that can’t be explored\nin the context of this document, but are worth your attention:</p><ul>\n<li>It is possible to <a href=\"/commands/scan\">iterate the key space of a large collection incrementally</a>.</li>\n<li>It is possible to run <a href=\"/commands/eval\">Lua scripts server side</a> to win latency and bandwidth.</li>\n<li>Redis is also a <a href=\"/topics/pubsub\">Pub-Sub server</a>.</li>\n</ul>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"OTHER NOTABLE FEATURES"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-learn-more\">Learn more</h2><p>This tutorial is in no way complete and has covered just the basics of the API.\nRead the <a href=\"/commands\">command reference</a> to discover a lot more.</p><p>Thanks for reading, and have fun hacking with Redis!</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"LEARN MORE"},{"content":"<h1 id=\"data-types\">Data types</h1><p><a name=\"strings\"></a></p>","link":"./alpha/topics/data-types.html","spaLink":"#/alpha/topics/data-types","title":"DATA TYPES"},{"content":"<h2 id=\"data-types-strings\">Strings</h2><p>Strings are the most basic kind of Redis value. Redis Strings are binary safe, this means that a Redis string can contain any kind of data, for instance a\nJPEG image or a serialized Ruby object.</p><p>A String value can be at max 512 Megabytes in length.</p><p>You can do a number of interesting things using strings in Redis, for instance you can:</p><ul>\n<li>Use Strings as atomic counters using commands in the INCR family: <a href=\"/commands/incr\">INCR</a>, <a href=\"/commands/decr\">DECR</a>, <a href=\"/commands/incrby\">INCRBY</a>.</li>\n<li>Append to strings with the <a href=\"/commands/append\">APPEND</a> command.</li>\n<li>Use Strings as a random access vectors with <a href=\"/commands/getrange\">GETRANGE</a> and <a href=\"/commands/setrange\">SETRANGE</a>.</li>\n<li>Encode a lot of data in little space, or create a Redis backed Bloom Filter using <a href=\"/commands/getbit\">GETBIT</a> and <a href=\"/commands/setbit\">SETBIT</a>.</li>\n</ul><p>Check all the <a href=\"/commands/#string\">available string commands</a> for more information, or read the <a href=\"/topics/data-types-intro\">introduction to Redis data types</a>.</p><p><a name=\"lists\"></a></p>","link":"./alpha/topics/data-types.html","spaLink":"#/alpha/topics/data-types","title":"STRINGS"},{"content":"<h2 id=\"data-types-lists\">Lists</h2><p>Redis Lists are simply lists of strings, sorted by insertion order.\nIt is possible to add elements to a Redis List pushing new elements on the head  (on the left) or on the tail (on the right) of the list.</p><p>The <a href=\"/commands/lpush\">LPUSH</a> command inserts a new element on the head, while\n<a href=\"/commands/rpush\">RPUSH</a> inserts a new element on the tail. A new list is created\nwhen one of this operations is performed against an empty key.\nSimilarly the key is removed from the key space if a list operation will\nempty the list. These are very handy semantics since all the list commands will\nbehave exactly like they were called with an empty list if called with a\nnon-existing key as argument.</p><p>Some example of list operations and resulting lists:</p><p>The max length of a list is 2^32 - 1 elements (4294967295, more than 4 billion of elements per list).</p><p>The main features of Redis Lists from the point of view of time complexity are\nthe support for constant time insertion and deletion of elements near the\nhead and tail, even with many millions of inserted items.\nAccessing elements is very fast near the extremes of the list but\nis slow if you try accessing the middle of a very big list, as it is\nan O(N) operation.</p><p>You can do many interesting things with Redis Lists, for instance you can:</p><ul>\n<li>Model a timeline in a social network, using <a href=\"/commands/lpush\">LPUSH</a> in order to add new elements in the user time line, and using <a href=\"/commands/lrange\">LRANGE</a> in order to retrieve a few of recently inserted items.</li>\n<li>You can use <a href=\"/commands/lpush\">LPUSH</a> together with <a href=\"/commands/ltrim\">LTRIM</a> to create a list that never exceeds a given number of elements, but just remembers the latest N elements.</li>\n<li>Lists can be used as a message passing primitive, See for instance the well known <a href=\"https://github.com/defunkt/resque\">Resque</a> Ruby library for creating background jobs.</li>\n<li>You can do a lot more with lists, this data type supports a number of commands, including blocking commands like <a href=\"/commands/blpop\">BLPOP</a>.</li>\n</ul><p>Please check all the <a href=\"/commands#list\">available commands operating on lists</a> for more information, or read the <a href=\"/topics/data-types-intro\">introduction to Redis data types</a>.</p><p><a name=\"sets\"></a></p>","link":"./alpha/topics/data-types.html","spaLink":"#/alpha/topics/data-types","title":"LISTS"},{"content":"<h2 id=\"data-types-sets\">Sets</h2><p>Redis Sets are an unordered collection of Strings. It is possible to add,\nremove, and test for existence of members in O(1) (constant time regardless\nof the number of elements contained inside the Set).</p><p>Redis Sets have the desirable property of not allowing repeated members. Adding the same element multiple times will result in a set having a single copy of this element. Practically speaking this means that adding a member does not require a <em>check if exists then add</em> operation.</p><p>A very interesting thing about Redis Sets is that they support a number of\nserver side commands to compute sets starting from existing sets, so you\ncan do unions, intersections, differences of sets in very short time.</p><p>The max number of members in a set is 2^32 - 1 (4294967295, more than 4 billion   of members per set).</p><p>You can do many interesting things using Redis Sets, for instance you can:</p><ul>\n<li>You can track unique things using Redis Sets. Want to know all the unique IP addresses visiting a given blog post? Simply use <a href=\"/commands/sadd\">SADD</a> every time you process a page view. You are sure repeated IPs will not be inserted.</li>\n<li>Redis Sets are good to represent relations. You can create a tagging system with Redis using a Set to represent every tag. Then you can add all the IDs of all the objects having a given tag into a Set representing this particular tag, using the <a href=\"/commands/sadd\">SADD</a> command. Do you want all the IDs of all the Objects having a three different tags at the same time? Just use <a href=\"/commands/sinter\">SINTER</a>.</li>\n<li>You can use Sets to extract elements at random using the <a href=\"/commands/spop\">SPOP</a> or <a href=\"/commands/srandmember\">SRANDMEMBER</a> commands.</li>\n</ul><p>As usual, check the <a href=\"/commands#set\">full list of Set commands</a> for more information, or read the <a href=\"/topics/data-types-intro\">introduction to Redis data types</a>.</p><p><a name=\"hashes\"></a></p>","link":"./alpha/topics/data-types.html","spaLink":"#/alpha/topics/data-types","title":"SETS"},{"content":"<h2 id=\"data-types-hashes\">Hashes</h2><p>Redis Hashes are maps between string fields and string values, so they are the perfect data type to represent objects (e.g. A User with a number of fields like name, surname, age, and so forth):</p><p>A hash with a few fields (where few means up to one hundred or so) is stored in a way\nthat takes very little space, so you can store millions of objects in a small\nRedis instance.</p><p>While Hashes are used mainly to represent objects, they are capable of storing many elements, so you can use Hashes for many other tasks as well.</p><p>Every hash can store up to 2^32 - 1 field-value pairs (more than 4 billion).</p><p>Check the <a href=\"/commands#hash\">full list of Hash commands</a> for more information, or read the <a href=\"/topics/data-types-intro\">introduction to Redis data types</a>.</p><p><a name=\"sorted-sets\"></a></p>","link":"./alpha/topics/data-types.html","spaLink":"#/alpha/topics/data-types","title":"HASHES"},{"content":"<h2 id=\"data-types-sorted-sets\">Sorted sets</h2><p>Redis Sorted Sets are, similarly to Redis Sets, non repeating collections of\nStrings. The difference is that every member of a Sorted Set is associated\nwith score, that is used in order to take the sorted set ordered, from the\nsmallest to the greatest score.  While members are unique, scores may be\nrepeated.</p><p>With sorted sets you can add, remove, or update elements in a very fast way\n(in a time proportional to the logarithm of the number of elements). Since\nelements are <em>taken in order</em> and not ordered afterwards, you can also get\nranges by score or by rank (position) in a very fast way.\nAccessing the middle of a sorted set is also very fast, so you can use\nSorted Sets as a smart list of non repeating elements where you can quickly access\neverything you need: elements in order, fast existence test, fast access\nto elements in the middle!</p><p>In short with sorted sets you can do a lot of tasks with great performance\nthat are really hard to model in other kind of databases.</p><p>With Sorted Sets you can:</p><ul>\n<li>Take a leader board in a massive online game, where every time a new score\nis submitted you update it using <a href=\"/commands/zadd\">ZADD</a>. You can easily\ntake the top users using <a href=\"/commands/zrange\">ZRANGE</a>, you can also, given an\nuser name, return its rank in the listing using <a href=\"/commands/zrank\">ZRANK</a>.\nUsing ZRANK and ZRANGE together you can show users with a score similar to\na given user. All very <em>quickly</em>.</li>\n<li>Sorted Sets are often used in order to index data that is stored inside Redis.\nFor instance if you have many hashes representing users, you can use a sorted set with elements having the age of the user as the score and the ID of the user as the value. So using <a href=\"/commands/zrangebyscore\">ZRANGEBYSCORE</a> it will be trivial and fast to retrieve all the users with a given interval of ages.</li>\n</ul><p>Sorted Sets are probably the most advanced Redis data types, so take some time to check the <a href=\"/commands#sorted_set\">full list of Sorted Set commands</a> to discover what you can do with Redis! Also you may want to read the <a href=\"/topics/data-types-intro\">introduction to Redis data types</a>.</p>","link":"./alpha/topics/data-types.html","spaLink":"#/alpha/topics/data-types","title":"SORTED SETS"},{"content":"<h2 id=\"data-types-bitmaps-and-hyperloglogs\">Bitmaps and HyperLogLogs</h2><p>Redis also supports Bitmaps and HyperLogLogs which are actually data types\nbased on the String base type, but having their own semantics.</p><p>Please refer to the <a href=\"/topics/data-types-intro\">introduction to Redis data types</a> for information about those types.</p>","link":"./alpha/topics/data-types.html","spaLink":"#/alpha/topics/data-types","title":"BITMAPS AND HYPERLOGLOGS"},{"content":"<h1 id=\"redis-debugging-guide\">Redis debugging guide</h1><p>Redis is developed with a great stress on stability: we do our best with\nevery release to make sure you’ll experience a very stable product and no\ncrashes. However even with our best efforts it is impossible to avoid all\nthe critical bugs with 100% of success.</p><p>When Redis crashes it produces a detailed report of what happened, however\nsometimes looking at the crash report is not enough, nor it is possible for\nthe Redis core team to reproduce the issue independently: in this scenario we\nneed help from the user that is able to reproduce the issue.</p><p>This little guide shows how to use GDB to provide all the information the\nRedis developers will need to track the bug more easily.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"REDIS DEBUGGING GUIDE"},{"content":"<h2 id=\"redis-debugging-guide-what-is-gdb\">What is GDB?</h2><p>GDB is the Gnu Debugger: a program that is able to inspect the internal state\nof another program. Usually tracking and fixing a bug is an exercise in\ngathering more information about the state of the program at the moment the\nbug happens, so GDB is an extremely useful tool.</p><p>GDB can be used in two ways:</p><ul>\n<li>It can attach to a running program and inspect the state of it at runtime.</li>\n<li>It can inspect the state of a program that already terminated using what is called a <em>core file</em>, that is, the image of the memory at the time the program was running.</li>\n</ul><p>From the point of view of investigating Redis bugs we need to use both this\nGDB modes: the user able to reproduce the bug attaches GDB to his running Redis instance, and when the crash happens, he creates the <code>core</code> file that the in turn the developer will use to inspect the Redis internals at the time of the crash.</p><p>This way the developer can perform all the inspections in his computer without the help of the user, and the user is free to restart Redis in the production environment.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"WHAT IS GDB?"},{"content":"<h2 id=\"redis-debugging-guide-compiling-redis-without-optimizations\">Compiling Redis without optimizations</h2><p>By default Redis is compiled with the <code>-O2</code> switch, this means that compiler\noptimizations are enabled. This makes the Redis executable faster, but at the\nsame time it makes Redis (like any other program) harder to inspect using GDB.</p><p>It is better to attach GDB to Redis compiled without optimizations using the\n<code>make noopt</code> command to compile it (instead of just using the plain <code>make</code>\ncommand). However if you have an already running Redis in production there is\nno need to recompile and restart it if this is going to create problems on\nyour side. Even if by a lesser extent GDB still works against executables\ncompiled with optimizations.</p><p>It is great if you make sure to recompile Redis with <code>make noopt</code> after the\nfirst crash, so that the next time it will be simpler to track the issue.</p><p>You should not be concerned with the loss of performances compiling Redis\nwithout optimizations, it is very unlikely that this will cause problems in\nyour environment since it is usually just a matter of a small percentage\nbecause Redis is not very CPU-bound (it does a lot of I/O to serve queries).</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"COMPILING REDIS WITHOUT OPTIMIZATIONS"},{"content":"<h2 id=\"redis-debugging-guide-attaching-gdb-to-a-running-process\">Attaching GDB to a running process</h2><p>If you have an already running Redis server, you can attach GDB to it, so that\nif Redis will crash it will be possible to both inspect the internals and\ngenerate a <code>core dump</code> file.</p><p>After you attach GDB to the Redis process it will continue running as usually without any loss of performance, so this is not a dangerous procedure.</p><p>In order to attach GDB the first thing you need is the <em>process ID</em> of the running Redis instance (the <em>pid</em> of the process). You can easily obtain it using <code>redis-cli</code>:</p><p>In the above example the process ID is <strong>58414</strong>.</p><ul>\n<li>Login into your Redis server.</li>\n<li>(Optional but recommended) Start <strong>screen</strong> or <strong>tmux</strong> or any other program that will make sure that your GDB session will not be closed if your ssh connection will timeout. If you don’t know what screen is do yourself a favor and <a href=\"http://www.linuxjournal.com/article/6340\">Read this article</a></li>\n<li><p>Attach GDB to the running Redis server typing:</p>\n<p>  gdb <code>&lt;path-to-redis-executable&gt;</code> <code>&lt;pid&gt;</code></p>\n<p>  For example: gdb /usr/local/bin/redis-server 58414</p>\n</li>\n</ul><p>Attach GDB to the running Redis server typing:</p><p>  gdb <code>&lt;path-to-redis-executable&gt;</code> <code>&lt;pid&gt;</code></p><p>  For example: gdb /usr/local/bin/redis-server 58414</p><p>GDB will start and will attach to the running server printing something like the following:</p><ul>\n<li><p>At this point GDB is attached but <strong>your Redis instance is blocked by GDB</strong>. In order to let the Redis instance continue the execution just type <strong>continue</strong> at the GDB prompt, and press enter.</p>\n<pre><code class=\"prettyprint prettyprinted\" style=\"\"><span class=\"pln\">  </span><span class=\"pun\">(</span><span class=\"pln\">gdb</span><span class=\"pun\">)</span><span class=\"pln\"> </span><span class=\"kwd\">continue</span><span class=\"pln\">\n  </span><span class=\"typ\">Continuing</span><span class=\"pun\">.</span></code></pre>\n</li>\n<li><p>Done! Now your Redis instance has GDB attached. You can wait for… the next crash :)</p>\n</li>\n<li>Now it’s time to detach your screen / tmux session, if you are running GDB using it, pressing the usual <strong>Ctrl-a a</strong> key combination.</li>\n</ul><p>At this point GDB is attached but <strong>your Redis instance is blocked by GDB</strong>. In order to let the Redis instance continue the execution just type <strong>continue</strong> at the GDB prompt, and press enter.</p><p>Done! Now your Redis instance has GDB attached. You can wait for… the next crash :)</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"ATTACHING GDB TO A RUNNING PROCESS"},{"content":"<h2 id=\"redis-debugging-guide-after-the-crash\">After the crash</h2><p>Redis has a command to simulate a segmentation fault (in other words a bad\ncrash) using the <code>DEBUG SEGFAULT</code> command (don’t use it against a real production instance of course ;). So I’ll use this command to crash my instance to show what happens in the GDB side:</p><p>As you can see GDB detected that Redis crashed, and was able to show me\neven the file name and line number causing the crash. This is already much\nbetter than the Redis crash report back trace (containing just function\nnames and binary offsets).</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"AFTER THE CRASH"},{"content":"<h2 id=\"redis-debugging-guide-obtaining-the-stack-trace\">Obtaining the stack trace</h2><p>The first thing to do is to obtain a full stack trace with GDB. This is as\nsimple as using the <strong>bt</strong> command: (that is a short for backtrace):</p><p>This shows the backtrace, but we also want to dump the processor registers using the <strong>info registers</strong> command:</p><p>Please <strong>make sure to include</strong> both this outputs in your bug report.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"OBTAINING THE STACK TRACE"},{"content":"<h2 id=\"redis-debugging-guide-obtaining-the-core-file\">Obtaining the core file</h2><p>The next step is to generate the core dump, that is the image of the memory of the running Redis process. This is performed using the <code>gcore</code> command:</p><p>Now you have the core dump to send to the Redis developer, but <strong>it is important to understand</strong> that this happens to contain all the data that was inside the Redis instance at the time of the crash: Redis developers will make sure to don’t share the content with any other, and will delete the file as soon as it is no longer used for debugging purposes, but you are warned that sending the core file you are sending your data.</p><p>If there are sensible stuff in the data set we suggest sending the dump directly to Salvatore Sanfilippo (that is the guy writing this doc) at the email address <strong>antirez at gmail dot com</strong>.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"OBTAINING THE CORE FILE"},{"content":"<h2 id=\"redis-debugging-guide-what-to-send-to-developers\">What to send to developers</h2><p>Finally you can send everything to the Redis core team:</p><ul>\n<li>The Redis executable you are using.</li>\n<li>The stack trace produced by the <strong>bt</strong> command, and the registers dump.</li>\n<li>The core file you generated with gdb.</li>\n<li>Information about the operating system and GCC version, and Redis version you are using.</li>\n</ul>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"WHAT TO SEND TO DEVELOPERS"},{"content":"<h2 id=\"redis-debugging-guide-thank-you\">Thank you</h2><p>Your help is extremely important! Many issues can only be tracked this way, thanks! It is also possible that helping Redis debugging you’ll be among the winners of the next <a href=\"http://antirez.com/post/redis-moka-awards-2011.html\">Redis Moka Award</a>.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"THANK YOU"},{"content":"<h1 id=\"distributed-locks-with-redis\">Distributed locks with Redis</h1><p>Distributed locks are a very useful primitive in many environments where\ndifferent processes must operate with shared resources in a mutually\nexclusive way.</p><p>There are a number of libraries and blog posts describing how to implement\na DLM (Distributed Lock Manager) with Redis, but every library uses a different\napproach, and many use a simple approach with lower guarantees compared to\nwhat can be achieved with slightly more complex designs.</p><p>This page is an attempt to provide a more canonical algorithm to implement\ndistributed locks with Redis. We propose an algorithm, called <strong>Redlock</strong>,\nwhich implements a DLM which we believe to be safer than the vanilla single\ninstance approach. We hope that the community will analyze it, provide\nfeedback, and use it as a starting point for the implementations or more\ncomplex or alternative designs.</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"DISTRIBUTED LOCKS WITH REDIS"},{"content":"<h2 id=\"distributed-locks-with-redis-implementations\">Implementations</h2><p>Before describing the algorithm, here are a few links to implementations\nalready available that can be used for reference.</p><ul>\n<li><a href=\"https://github.com/antirez/redlock-rb\">Redlock-rb</a> (Ruby implementation). There is also a <a href=\"https://github.com/leandromoreira/redlock-rb\">fork of Redlock-rb</a> that adds a gem for easy distribution and perhaps more.</li>\n<li><a href=\"https://github.com/SPSCommerce/redlock-py\">Redlock-py</a> (Python implementation).</li>\n<li><a href=\"https://github.com/ronnylt/redlock-php\">Redlock-php</a> (PHP implementation).</li>\n<li><a href=\"https://github.com/malkusch/lock#phpredismutex\">PHPRedisMutex</a> (further PHP implementation)</li>\n<li><a href=\"https://github.com/hjr265/redsync.go\">Redsync.go</a> (Go implementation).</li>\n<li><a href=\"https://github.com/mrniko/redisson\">Redisson</a> (Java implementation).</li>\n<li><a href=\"https://github.com/sbertrang/redis-distlock\">Redis::DistLock</a> (Perl implementation).</li>\n<li><a href=\"https://github.com/jacket-code/redlock-cpp\">Redlock-cpp</a> (C++ implementation).</li>\n<li><a href=\"https://github.com/kidfashion/redlock-cs\">Redlock-cs</a> (C#/.NET implementation).</li>\n<li><a href=\"https://github.com/samcook/RedLock.net\">RedLock.net</a> (C#/.NET implementation). Includes async and lock extension support.</li>\n<li><a href=\"https://github.com/psibernetic/scarletlock\">ScarletLock</a> (C# .NET implementation with configurable datastore)</li>\n<li><a href=\"https://github.com/mike-marcacci/node-redlock\">node-redlock</a> (NodeJS implementation). Includes support for lock extension.</li>\n</ul>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"IMPLEMENTATIONS"},{"content":"<h2 id=\"distributed-locks-with-redis-safety-and-liveness-guarantees\">Safety and Liveness guarantees</h2><p>We are going to model our design with just three properties that, from our point of view, are the minimum guarantees needed to use distributed locks in an effective way.</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"SAFETY AND LIVENESS GUARANTEES"},{"content":"<h2 id=\"distributed-locks-with-redis-why-failover-based-implementations-are-not-enough\">Why failover-based implementations are not enough</h2><p>To understand what we want to improve, let’s analyze the current state of affairs with most Redis-based distributed lock libraries.</p><p>The simplest way to use Redis to lock a resource is to create a key in an instance. The key is usually created with a limited time to live, using the Redis expires feature, so that eventually it will get released (property 2 in our list). When the client needs to release the resource, it deletes the key.</p><p>Superficially this works well, but there is a problem: this is a single point of failure in our architecture. What happens if the Redis master goes down?\nWell, let’s add a slave! And use it if the master is unavailable. This is unfortunately not viable. By doing so we can’t implement our safety property of mutual exclusion, because Redis replication is asynchronous.</p><p>There is an obvious race condition with this model:</p><p>Sometimes it is perfectly fine that under special circumstances, like during a failure, multiple clients can hold the lock at the same time.\nIf this is the case, you can use your replication based solution. Otherwise we suggest to implement the solution described in this document.</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"WHY FAILOVER-BASED IMPLEMENTATIONS ARE NOT ENOUGH"},{"content":"<h2 id=\"distributed-locks-with-redis-correct-implementation-with-a-single-instance\">Correct implementation with a single instance</h2><p>Before trying to overcome the limitation of the single instance setup described above, let’s check how to do it correctly in this simple case, since this is actually a viable solution in applications where a race condition from time to time is acceptable, and because locking into a single instance is the foundation we’ll use for the distributed algorithm described here.</p><p>To acquire the lock, the way to go is the following:</p><p>The command will set the key only if it does not already exist (NX option), with an expire of 30000 milliseconds (PX option).\nThe key is set to a value “my_random_value”. This value must be unique across all clients and all lock requests.</p><p>Basically the random value is used in order to release the lock in a safe way, with a script that tells Redis: remove the key only if it exists and the value stored at the key is exactly the one I expect to be. This is accomplished by the following Lua script:</p><p>This is important in order to avoid removing a lock that was created by another client. For example a client may acquire the lock, get blocked in some operation for longer than the lock validity time (the time at which the key will expire), and later remove the lock, that was already acquired by some other client.\nUsing just DEL is not safe as a client may remove the lock of another client. With the above script instead every lock is “signed” with a random string, so the lock will be removed only if it is still the one that was set by the client trying to remove it.</p><p>What should this random string be? I assume it’s 20 bytes from /dev/urandom, but you can find cheaper ways to make it unique enough for your tasks.\nFor example a safe pick is to seed RC4 with /dev/urandom, and generate a pseudo random stream from that.\nA simpler solution is to use a combination of unix time with microseconds resolution, concatenating it with a client ID, it is not as safe, but probably up to the task in most environments.</p><p>The time we use as the key time to live, is called the “lock validity time”. It is both the auto release time, and the time the client has in order to perform the operation required before another client may be able to acquire the lock again, without technically violating the mutual exclusion guarantee, which is only limited to a given window of time from the moment the lock is acquired.</p><p>So now we have a good way to acquire and release the lock. The system, reasoning about a non-distributed system composed of a single, always available, instance, is safe. Let’s extend the concept to a distributed system where we don’t have such guarantees.</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"CORRECT IMPLEMENTATION WITH A SINGLE INSTANCE"},{"content":"<h2 id=\"distributed-locks-with-redis-the-redlock-algorithm\">The Redlock algorithm</h2><p>In the distributed version of the algorithm we assume we have N Redis masters. Those nodes are totally independent, so we don’t use replication or any other implicit coordination system. We already described how to acquire and release the lock safely in a single instance. We take for granted that the algorithm will use this method to acquire and release the lock in a single instance. In our examples we set N=5, which is a reasonable value, so we need to run 5 Redis masters on different computers or virtual machines in order to ensure that they’ll fail in a mostly independent way.</p><p>In order to acquire the lock, the client performs the following operations:</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"THE REDLOCK ALGORITHM"},{"content":"<h2 id=\"distributed-locks-with-redis-is-the-algorithm-asynchronous\">Is the algorithm asynchronous?</h2><p>The algorithm relies on the assumption that while there is no synchronized clock across the processes, still the local time in every process flows approximately at the same rate, with an error which is small compared to the auto-release time of the lock. This assumption closely resembles a real-world computer: every computer has a local clock and we can usually rely on different computers to have a clock drift which is small.</p><p>At this point we need to better specify our mutual exclusion rule: it is guaranteed only as long as the client holding the lock will terminate its work within the lock validity time (as obtained in step 3), minus some time (just a few milliseconds in order to compensate for clock drift between processes).</p><p>For more information about similar systems requiring a bound <em>clock drift</em>, this paper is an interesting reference: <a href=\"http://dl.acm.org/citation.cfm?id=74870\">Leases: an efficient fault-tolerant mechanism for distributed file cache consistency</a>.</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"IS THE ALGORITHM ASYNCHRONOUS?"},{"content":"<h2 id=\"distributed-locks-with-redis-retry-on-failure\">Retry on failure</h2><p>When a client is unable to acquire the lock, it should try again after a random delay in order to try to desynchronize multiple clients trying to acquire the lock for the same resource at the same time (this may result in a split brain condition where nobody wins). Also the faster a client tries to acquire the lock in the majority of Redis instances, the smaller the window for a split brain condition (and the need for a retry), so ideally the client should try to send the SET commands to the N instances at the same time using multiplexing.</p><p>It is worth stressing how important it is for clients that fail to acquire the majority of locks, to release the (partially) acquired locks ASAP, so that there is no need to wait for key expiry in order for the lock to be acquired again (however if a network partition happens and the client is no longer able to communicate with the Redis instances, there is an availability penalty to pay as it waits for key expiration).</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"RETRY ON FAILURE"},{"content":"<h2 id=\"distributed-locks-with-redis-releasing-the-lock\">Releasing the lock</h2><p>Releasing the lock is simple and involves just releasing the lock in all instances, whether or not the client believes it was able to successfully lock a given instance.</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"RELEASING THE LOCK"},{"content":"<h2 id=\"distributed-locks-with-redis-safety-arguments\">Safety arguments</h2><p>Is the algorithm safe? We can try to understand what happens in different scenarios.</p><p>To start let’s assume that a client is able to acquire the lock in the majority of instances. All the instances will contain a key with the same time to live. However, the key was set at different times, so the keys will also expire at different times. But if the first key was set at worst at time T1 (the time we sample before contacting the first server) and the last key was set at worst at time T2 (the time we obtained the reply from the last server), we are sure that the first key to expire in the set will exist for at least <code>MIN_VALIDITY=TTL-(T2-T1)-CLOCK_DRIFT</code>. All the other keys will expire later, so we are sure that the keys will be simultaneously set for at least this time.</p><p>During the time that the majority of keys are set, another client will not be able to acquire the lock, since N/2+1 SET NX operations can’t succeed if N/2+1 keys already exist. So if a lock was acquired, it is not possible to re-acquire it at the same time (violating the mutual exclusion property).</p><p>However we want to also make sure that multiple clients trying to acquire the lock at the same time can’t simultaneously succeed.</p><p>If a client locked the majority of instances using a time near, or greater, than the lock maximum validity time (the TTL we use for SET basically), it will consider the lock invalid and will unlock the instances, so we only need to consider the case where a client was able to lock the majority of instances in a time which is less than the validity time. In this case for the argument already expressed above, for <code>MIN_VALIDITY</code> no client should be able to re-acquire the lock. So multiple clients will be able to lock N/2+1 instances at the same time (with “time” being the end of Step 2) only when the time to lock the majority was greater than the TTL time, making the lock invalid.</p><p>Are you able to provide a formal proof of safety, point to existing algorithms that are similar, or find a bug? That would be greatly appreciated.</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"SAFETY ARGUMENTS"},{"content":"<h2 id=\"distributed-locks-with-redis-liveness-arguments\">Liveness arguments</h2><p>The system liveness is based on three main features:</p><p>However, we pay an availability penalty equal to <code>TTL</code> time on network partitions, so if there are continuous partitions, we can pay this penalty indefinitely.\nThis happens every time a client acquires a lock and gets partitioned away before being able to remove the lock.</p><p>Basically if there are infinite continuous network partitions, the system may become not available for an infinite amount of time.</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"LIVENESS ARGUMENTS"},{"content":"<h2 id=\"distributed-locks-with-redis-performance-crash-recovery-and-fsync\">Performance, crash-recovery and fsync</h2><p>Many users using Redis as a lock server need high performance in terms of both latency to acquire and release a lock, and number of acquire / release operations that it is possible to perform per second. In order to meet this requirement, the strategy to talk with the N Redis servers to reduce latency is definitely multiplexing (or poor man’s multiplexing, which is, putting the socket in non-blocking mode, send all the commands, and read all the commands later, assuming that the RTT between the client and each instance is similar).</p><p>However there is another consideration to do about persistence if we want to target a crash-recovery system model.</p><p>Basically to see the problem here, let’s assume we configure Redis without persistence at all. A client acquires the lock in 3 of 5 instances. One of the instances where the client was able to acquire the lock is restarted, at this point there are again 3 instances that we can lock for the same resource, and another client can lock it again, violating the safety property of exclusivity of lock.</p><p>If we enable AOF persistence, things will improve quite a bit. For example we can upgrade a server by sending SHUTDOWN and restarting it. Because Redis expires are semantically implemented so that virtually the time still elapses when the server is off, all our requirements are fine.\nHowever everything is fine as long as it is a clean shutdown. What about a power outage? If Redis is configured, as by default, to fsync on disk every second, it is possible that after a restart our key is missing. In theory, if we want to guarantee the lock safety in the face of any kind of instance restart, we need to enable fsync=always in the persistence setting. This in turn will totally ruin performances to the same level of CP systems that are traditionally used to implement distributed locks in a safe way.</p><p>However things are better than what they look like at a first glance. Basically\nthe algorithm safety is retained as long as when an instance restarts after a\ncrash, it no longer participates to any <strong>currently active</strong> lock, so that the\nset of currently active locks when the instance restarts, were all obtained\nby locking instances other than the one which is rejoining the system.</p><p>To guarantee this we just need to make an instance, after a crash, unavailable\nfor at least a bit more than the max <code>TTL</code> we use, which is, the time needed\nfor all the keys about the locks that existed when the instance crashed, to\nbecome invalid and be automatically released.</p><p>Using <em>delayed restarts</em> it is basically possible to achieve safety even\nwithout any kind of Redis persistence available, however note that this may\ntranslate into an availability penalty. For example if a majority of instances\ncrash, the system will become globally unavailable for <code>TTL</code> (here globally means\nthat no resource at all will be lockable during this time).</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"PERFORMANCE, CRASH-RECOVERY AND FSYNC"},{"content":"<h2 id=\"distributed-locks-with-redis-making-the-algorithm-more-reliable-extending-the-lock\">Making the algorithm more reliable: Extending the lock</h2><p>If the work performed by clients is composed of small steps, it is possible to\nuse smaller lock validity times by default, and extend the algorithm implementing\na lock extension mechanism. Basically the client, if in the middle of the\ncomputation while the lock validity is approaching a low value, may extend the\nlock by sending a Lua script to all the instances that extends the TTL of the key\nif the key exists and its value is still the random value the client assigned\nwhen the lock was acquired.</p><p>The client should only consider the lock re-acquired if it was able to extend\nthe lock into the majority of instances, and within the validity time\n(basically the algorithm to use is very similar to the one used when acquiring\nthe lock).</p><p>However this does not technically change the algorithm, so the maximum number\nof lock reacquisition attempts should be limited, otherwise one of the liveness\nproperties is violated.</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"MAKING THE ALGORITHM MORE RELIABLE: EXTENDING THE LOCK"},{"content":"<h2 id=\"distributed-locks-with-redis-want-to-help\">Want to help?</h2><p>If you are into distributed systems, it would be great to have your opinion / analysis. Also reference implementations in other languages could be great.</p><p>Thanks in advance!</p>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"WANT TO HELP?"},{"content":"<h2 id=\"distributed-locks-with-redis-analysis-of-redlock\">Analysis of Redlock</h2>","link":"./alpha/topics/distlock.html","spaLink":"#/alpha/topics/distlock","title":"ANALYSIS OF REDLOCK"},{"content":"<h1 id=\"redis-encryption\">Redis Encryption</h1><p>The idea of adding SSL support to Redis was proposed many times, however\ncurrently we believe that given the small percentage of users requiring\nSSL support, and the fact that each scenario tends to be different, to use\na different “tunneling” strategy can be better. We may change the idea in the\nfuture, but currently a good solution that may be suitable for many use cases\nis to use the following project:</p><ul>\n<li><a href=\"http://www.tarsnap.com/spiped.html\">Spiped</a> is a utility for creating symmetrically encrypted and authenticated pipes between socket addresses, so that one may connect to one address (e.g., a UNIX socket on localhost) and transparently have a connection established to another address (e.g., a UNIX socket on a different system).</li>\n</ul><p>The software is written in a similar spirit to Redis itself, it is a self-contained 4000 lines of C code utility that does a single thing well.</p>","link":"./alpha/topics/encryption.html","spaLink":"#/alpha/topics/encryption","title":"REDIS ENCRYPTION"},{"content":"<h1 id=\"faq\">FAQ</h1>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"FAQ"},{"content":"<h2 id=\"faq-why-redis-is-different-compared-to-other-key-value-stores\">Why Redis is different compared to other key-value stores?</h2><p>There are two main reasons.</p><ul>\n<li>Redis is a different evolution path in the key-value DBs where values can contain more complex data types, with atomic operations defined on those data types. Redis data types are closely related to fundamental data structures and are exposed to the programmer as such, without additional abstraction layers.</li>\n<li>Redis is an in-memory but persistent on disk database, so it represents a different trade off where very high write and read speed is achieved with the limitation of data sets that can’t be larger than memory. Another advantage of\nin memory databases is that the memory representation of complex data structures\nis much simpler to manipulate compared to the same data structure on disk, so\nRedis can do a lot, with little internal complexity. At the same time the\ntwo on-disk storage formats (RDB and AOF) don’t need to be suitable for random\naccess, so they are compact and always generated in an append-only fashion\n(Even the AOF log rotation is an append-only operation, since the new version\nis generated from the copy of data in memory).</li>\n</ul>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHY REDIS IS DIFFERENT COMPARED TO OTHER KEY-VALUE STORES?"},{"content":"<h2 id=\"faq-whats-the-redis-memory-footprint\">What’s the Redis memory footprint?</h2><p>To give you a few examples (all obtained using 64-bit instances):</p><ul>\n<li>An empty instance uses ~ 1MB of memory.</li>\n<li>1 Million small Keys -&gt; String Value pairs use ~ 100MB of memory.</li>\n<li>1 Million Keys -&gt; Hash value, representing an object with 5 fields, use ~ 200 MB of memory.</li>\n</ul><p>To test your use case is trivial using the <code>redis-benchmark</code> utility to generate random data sets and check with the <code>INFO memory</code> command the space used.</p><p>64-bit systems will use considerably more memory than 32-bit systems to store the same keys, especially if the keys and values are small. This is because pointers take 8 bytes in 64-bit systems. But of course the advantage is that you can\nhave a lot of memory in 64-bit systems, so in order to run large Redis servers a 64-bit system is more or less required. The alternative is sharding.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHAT’S THE REDIS MEMORY FOOTPRINT?"},{"content":"<h2 id=\"faq-i-like-rediss-high-level-operations-and-features-but-i-dont-like-that-it-takes-everything-in-memory-and-i-cant-have-a-dataset-larger-the-memory-plans-to-change-this\">I like Redis’s high level operations and features, but I don’t like that it takes everything in memory and I can’t have a dataset larger the memory. Plans to change this?</h2><p>In the past the Redis developers experimented with Virtual Memory and other systems in order to allow larger than RAM datasets, but after all we are very happy if we can do one thing well: data served from memory, disk used for storage. So for now there are no plans to create an on disk backend for Redis. Most of what\nRedis is, after all, is a direct result of its current design.</p><p>If your real problem is not the total RAM needed, but the fact that you need\nto split your data set into multiple Redis instances, please read the\n<a href=\"/topics/partitioning\">Partitioning page</a> in this documentation for more info.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"I LIKE REDIS’S HIGH LEVEL OPERATIONS AND FEATURES, BUT I DON’T LIKE THAT IT TAKES EVERYTHING IN MEMORY AND I CAN’T HAVE A DATASET LARGER THE MEMORY. PLANS TO CHANGE THIS?"},{"content":"<h2 id=\"faq-is-using-redis-together-with-an-on-disk-database-a-good-idea\">Is using Redis together with an on-disk database a good idea?</h2><p>Yes, a common design pattern involves taking very write-heavy small data\nin Redis (and data you need the Redis data structures to model your problem\nin an efficient way), and big <em>blobs</em> of data into an SQL or eventually\nconsistent on-disk database.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"IS USING REDIS TOGETHER WITH AN ON-DISK DATABASE A GOOD IDEA?"},{"content":"<h2 id=\"faq-is-there-something-i-can-do-to-lower-the-redis-memory-usage\">Is there something I can do to lower the Redis memory usage?</h2><p>If you can, use Redis 32 bit instances. Also make good use of small hashes,\nlists, sorted sets, and sets of integers, since Redis is able to represent\nthose data types in the special case of a few elements in a much more compact\nway. There is more info in the <a href=\"/topics/memory-optimization\">Memory Optimization page</a>.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"IS THERE SOMETHING I CAN DO TO LOWER THE REDIS MEMORY USAGE?"},{"content":"<h2 id=\"faq-what-happens-if-redis-runs-out-of-memory\">What happens if Redis runs out of memory?</h2><p>Redis will either be killed by the Linux kernel OOM killer,\ncrash with an error, or will start to slow down.\nWith modern operating systems malloc() returning NULL is not common, usually\nthe server will start swapping, and Redis performance will degrade, so\nyou’ll probably notice there is something wrong.</p><p>The INFO command will report the amount of memory Redis is using so you can\nwrite scripts that monitor your Redis servers checking for critical conditions.</p><p>Redis has built-in protections allowing the user to set a max limit to memory\nusage, using the <code>maxmemory</code> option in the config file to put a limit\nto the memory Redis can use. If this limit is reached Redis will start to reply\nwith an error to write commands (but will continue to accept read-only\ncommands), or you can configure it to evict keys when the max memory limit\nis reached in the case you are using Redis for caching.</p><p>We have documentation if you plan to use <a href=\"/topics/lru-cache\">Redis as an LRU cache</a>.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHAT HAPPENS IF REDIS RUNS OUT OF MEMORY?"},{"content":"<h2 id=\"faq-background-saving-is-failing-with-a-fork-error-under-linux-even-if-ive-a-lot-of-free-ram\">Background saving is failing with a fork() error under Linux even if I’ve a lot of free RAM!</h2><p>Short answer: <code>echo 1 &gt; /proc/sys/vm/overcommit_memory</code> :)</p><p>And now the long one:</p><p>Redis background saving schema relies on the copy-on-write semantic of fork in\nmodern operating systems: Redis forks (creates a child process) that is an\nexact copy of the parent. The child process dumps the DB on disk and finally\nexits. In theory the child should use as much memory as the parent being a\ncopy, but actually thanks to the copy-on-write semantic implemented by most\nmodern operating systems the parent and child process will <em>share</em> the common\nmemory pages. A page will be duplicated only when it changes in the child or in\nthe parent. Since in theory all the pages may change while the child process is\nsaving, Linux can’t tell in advance how much memory the child will take, so if\nthe <code>overcommit_memory</code> setting is set to zero fork will fail unless there is\nas much free RAM as required to really duplicate all the parent memory pages,\nwith the result that if you have a Redis dataset of 3 GB and just 2 GB of free\nmemory it will fail.</p><p>Setting <code>overcommit_memory</code> to 1 says Linux to relax and perform the fork in a\nmore optimistic allocation fashion, and this is indeed what you want for Redis.</p><p>A good source to understand how Linux Virtual Memory work and other\nalternatives for <code>overcommit_memory</code> and <code>overcommit_ratio</code> is this classic\nfrom Red Hat Magazine, <a href=\"http://www.redhat.com/magazine/001nov04/features/vm/\">“Understanding Virtual Memory”</a>.\nBeware, this article had <code>1</code> and <code>2</code> configuration values for <code>overcommit_memory</code>\nreversed: refer to the <a href=\"http://man7.org/linux/man-pages/man5/proc.5.html\">proc(5)</a> man page for the right meaning of the\navailable values.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"BACKGROUND SAVING IS FAILING WITH A FORK() ERROR UNDER LINUX EVEN IF I’VE A LOT OF FREE RAM!"},{"content":"<h2 id=\"faq-are-redis-on-disk-snapshots-atomic\">Are Redis on-disk-snapshots atomic?</h2><p>Yes, redis background saving process is always forked when the server is\noutside of the execution of a command, so every command reported to be atomic\nin RAM is also atomic from the point of view of the disk snapshot.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"ARE REDIS ON-DISK-SNAPSHOTS ATOMIC?"},{"content":"<h2 id=\"faq-redis-is-single-threaded-how-can-i-exploit-multiple-cpu-cores\">Redis is single threaded. How can I exploit multiple CPU / cores?</h2><p>It’s very unlikely that CPU becomes your bottleneck with Redis, as usually Redis is either memory or network bound. For instance, using pipelining Redis running\non an average Linux system can deliver even 500k requests per second, so\nif your application mainly uses O(N) or O(log(N)) commands, it is hardly\ngoing to use too much CPU.</p><p>However, to maximize CPU usage you can start multiple instances of Redis in\nthe same box and treat them as different servers. At some point a single\nbox may not be enough anyway, so if you want to use multiple CPUs you can\nstart thinking of some way to shard earlier.</p><p>You can find more information about using multiple Redis instances in the <a href=\"/topics/partitioning\">Partitioning page</a>.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"REDIS IS SINGLE THREADED. HOW CAN I EXPLOIT MULTIPLE CPU / CORES?"},{"content":"<h2 id=\"faq-what-is-the-maximum-number-of-keys-a-single-redis-instance-can-hold-and-what-the-max-number-of-elements-in-a-hash-list-set-sorted-set\">What is the maximum number of keys a single Redis instance can hold? and what the max number of elements in a Hash, List, Set, Sorted Set?</h2><p>Redis can handle up to 2^32 keys, and was tested in practice to\nhandle at least 250 million of keys per instance.</p><p>Every hash, list, set, and sorted set, can hold 2^32 elements.</p><p>In other words your limit is likely the available memory in your system.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHAT IS THE MAXIMUM NUMBER OF KEYS A SINGLE REDIS INSTANCE CAN HOLD? AND WHAT THE MAX NUMBER OF ELEMENTS IN A HASH, LIST, SET, SORTED SET?"},{"content":"<h2 id=\"faq-my-slave-claims-to-have-a-different-number-of-keys-compared-to-its-master-why\">My slave claims to have a different number of keys compared to its master, why?</h2><p>If you use keys with limited time to live (Redis expires) this is normal behavior. This is what happens:</p><ul>\n<li>The master generates an RDB file on the first synchronization with the slave.</li>\n<li>The RDB file will not include keys already expired in the master, but that are still in memory.</li>\n<li>However these keys are still in the memory of the Redis master, even if logically expired. They’ll not be considered as existing, but the memory will be reclaimed later, both incrementally and explicitly on access. However while these keys are not logical part of the dataset, they are advertised in <code>INFO</code> output and by the <code>DBSIZE</code> command.</li>\n<li>When the slave reads the RDB file generated by the master, this set of keys will not be loaded.</li>\n</ul><p>As a result of this, it is common for users with many keys with an expire set to see less keys in the slaves, because of this artifact, but there is no actual logical difference in the instances content.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"MY SLAVE CLAIMS TO HAVE A DIFFERENT NUMBER OF KEYS COMPARED TO ITS MASTER, WHY?"},{"content":"<h2 id=\"faq-what-redis-means-actually\">What Redis means actually?</h2><p>It means REmote DIctionary Server.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHAT REDIS MEANS ACTUALLY?"},{"content":"<h2 id=\"faq-why-did-you-start-the-redis-project\">Why did you start the Redis project?</h2><p>Originally Redis was started in order to scale <a href=\"http://lloogg.com\">LLOOGG</a>. But after I got the basic server working I liked the idea to share the work with other people, and Redis was turned into an open source project.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHY DID YOU START THE REDIS PROJECT?"}]