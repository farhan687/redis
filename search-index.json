[{"content":"<h2 id=\"-pattern-time-series\">Pattern: Time series</h2><p>The <code>APPEND</code> command can be used to create a very compact representation of a\nlist of fixed-size samples, usually referred as <em>time series</em>.\nEvery time a new sample arrives we can store it using the command</p><p>Accessing individual elements in the time series is not hard:</p><ul>\n<li><code>STRLEN</code> can be used in order to obtain the number of samples.</li>\n<li><code>GETRANGE</code> allows for random access of elements.\nIf our time series have associated time information we can easily implement\na binary search to get range combining <code>GETRANGE</code> with the Lua scripting\nengine available in Redis 2.6.</li>\n<li><code>SETRANGE</code> can be used to overwrite an existing time series.</li>\n</ul><p>The limitation of this pattern is that we are forced into an append-only mode\nof operation, there is no way to cut the time series to a given size easily\nbecause Redis currently lacks a command able to trim string objects.\nHowever the space efficiency of time series stored in this way is remarkable.</p><p>Hint: it is possible to switch to a different key based on the current Unix\ntime, in this way it is possible to have just a relatively small amount of\nsamples per key, to avoid dealing with very big keys, and to make this pattern\nmore friendly to be distributed across many Redis instances.</p><p>An example sampling the temperature of a sensor using fixed-size strings (using\na binary format is better in real implementations).</p>","link":"./alpha/commands/append.html","spaLink":"#/alpha/commands/append","title":"PATTERN: TIME SERIES"},{"content":"<h2 id=\"-example\">Example</h2><p>The following command removes the association for slots 5000 and\n5001 from the node receiving the command:</p>","link":"./alpha/commands/cluster-delslots.html","spaLink":"#/alpha/commands/cluster-delslots","title":"EXAMPLE"},{"content":"<h2 id=\"-usage-in-redis-cluster\">Usage in Redis Cluster</h2><p>This command only works in cluster mode and may be useful for\ndebugging and in order to manually orchestrate a cluster configuration\nwhen a new cluster is created. It is currently not used by <code>redis-trib</code>,\nand mainly exists for API completeness.</p><p>@return</p><p>@simple-string-reply: <code>OK</code> if the command was successful. Otherwise\nan error is returned.</p>","link":"./alpha/commands/cluster-delslots.html","spaLink":"#/alpha/commands/cluster-delslots","title":"USAGE IN REDIS CLUSTER"},{"content":"<h2 id=\"-pattern-real-time-metrics-using-bitmaps\">Pattern: real-time metrics using bitmaps</h2><p>Bitmaps are a very space-efficient representation of certain kinds of\ninformation.\nOne example is a Web application that needs the history of user visits, so that\nfor instance it is possible to determine what users are good targets of beta\nfeatures.</p><p>Using the <code>SETBIT</code> command this is trivial to accomplish, identifying every day\nwith a small progressive integer.\nFor instance day 0 is the first day the application was put online, day 1 the\nnext day, and so forth.</p><p>Every time a user performs a page view, the application can register that in\nthe current day the user visited the web site using the <code>SETBIT</code> command setting\nthe bit corresponding to the current day.</p><p>Later it will be trivial to know the number of single days the user visited the\nweb site simply calling the <code>BITCOUNT</code> command against the bitmap.</p><p>A similar pattern where user IDs are used instead of days is described\nin the article called “<a href=\"http://blog.getspool.com/2011/11/29/fast-easy-realtime-metrics-using-redis-bitmaps\">Fast easy realtime metrics using Redis\nbitmaps</a>“.</p>","link":"./alpha/commands/bitcount.html","spaLink":"#/alpha/commands/bitcount","title":"PATTERN: REAL-TIME METRICS USING BITMAPS"},{"content":"<h2 id=\"-performance-considerations\">Performance considerations</h2><p>In the above example of counting days, even after 10 years the application is\nonline we still have just <code>365*10</code> bits of data per user, that is just 456 bytes\nper user.\nWith this amount of data <code>BITCOUNT</code> is still as fast as any other O(1) Redis\ncommand like <code>GET</code> or <code>INCR</code>.</p><p>When the bitmap is big, there are two alternatives:</p><ul>\n<li>Taking a separated key that is incremented every time the bitmap is modified.\nThis can be very efficient and atomic using a small Redis Lua script.</li>\n<li>Running the bitmap incrementally using the <code>BITCOUNT</code> <em>start</em> and <em>end</em>\noptional parameters, accumulating the results client-side, and optionally\ncaching the result into a key.</li>\n</ul>","link":"./alpha/commands/bitcount.html","spaLink":"#/alpha/commands/bitcount","title":"PERFORMANCE CONSIDERATIONS"},{"content":"<h2 id=\"-details-on-why-the-ban-list-is-needed\">Details on why the ban-list is needed</h2><p>In the following example we’ll show why the command must not just remove\na given node from the nodes table, but also prevent it for being re-inserted\nagain for some time.</p><p>Let’s assume we have four nodes, A, B, C and D. In order to\nend with just a three nodes cluster A, B, C we may follow these steps:</p><p>As you can see in this way removing a node is fragile, we need to send\n<code>CLUSTER FORGET</code> commands to all the nodes ASAP hoping there are no\ngossip sections processing in the meantime. Because of this problem the\ncommand implements a ban-list with an expire time for each entry.</p><p>So what the command really does is:</p><p>This way we have a 60 second window to inform all the nodes in the cluster that\nwe want to remove a node.</p>","link":"./alpha/commands/cluster-forget.html","spaLink":"#/alpha/commands/cluster-forget","title":"DETAILS ON WHY THE BAN-LIST IS NEEDED"},{"content":"<h2 id=\"-special-conditions-not-allowing-the-command-execution\">Special conditions not allowing the command execution</h2><p>The command does not succeed and returns an error in the following cases:</p><p>@return</p><p>@simple-string-reply: <code>OK</code> if the command was executed successfully, otherwise an error is returned.</p>","link":"./alpha/commands/cluster-forget.html","spaLink":"#/alpha/commands/cluster-forget","title":"SPECIAL CONDITIONS NOT ALLOWING THE COMMAND EXECUTION"},{"content":"<h2 id=\"-pattern-reliable-queue\">Pattern: Reliable queue</h2><p>Please see the pattern description in the <code>RPOPLPUSH</code> documentation.</p>","link":"./alpha/commands/brpoplpush.html","spaLink":"#/alpha/commands/brpoplpush","title":"PATTERN: RELIABLE QUEUE"},{"content":"<h2 id=\"-pattern-circular-list\">Pattern: Circular list</h2><p>Please see the pattern description in the <code>RPOPLPUSH</code> documentation.</p>","link":"./alpha/commands/brpoplpush.html","spaLink":"#/alpha/commands/brpoplpush","title":"PATTERN: CIRCULAR LIST"},{"content":"<h2 id=\"-serialization-format\">Serialization format</h2><p>The output of the command is just a space-separated CSV string, where\neach line represents a node in the cluster. The following is an example\nof output:</p><p>Each line is composed of the following fields:</p><p>The meaning of each filed is the following:</p><p>Meaning of the flags (field number 3):</p><ul>\n<li><code>myself</code>: The node you are contacting.</li>\n<li><code>master</code>: Node is a master.</li>\n<li><code>slave</code>: Node is a slave.</li>\n<li><code>fail?</code>: Node is in <code>PFAIL</code> state. Not reachable for the node you are contacting, but still logically reachable (not in <code>FAIL</code> state).</li>\n<li><code>fail</code>: Node is in <code>FAIL</code> state. It was not reachable for multiple nodes that promoted the <code>PFAIL</code> state to <code>FAIL</code>.</li>\n<li><code>handshake</code>: Untrusted node, we are handshaking.</li>\n<li><code>noaddr</code>: No address known for this node.</li>\n<li><code>noflags</code>: No flags at all.</li>\n</ul>","link":"./alpha/commands/cluster-nodes.html","spaLink":"#/alpha/commands/cluster-nodes","title":"SERIALIZATION FORMAT"},{"content":"<h2 id=\"-notes-on-published-config-epochs\">Notes on published config epochs</h2><p>Slaves broadcast their master’s config epochs (in order to get an <code>UPDATE</code>\nmessage if they are found to be stale), so the real config epoch of the\nslave (which is meaningless more or less, since they don’t serve hash slots)\ncan be only obtained checking the node flagged as <code>myself</code>, which is the entry\nof the node we are asking to generate <code>CLUSTER NODES</code> output. The other slaves\nepochs reflect what they publish in heartbeat packets, which is, the\nconfiguration epoch of the masters they are currently replicating.</p>","link":"./alpha/commands/cluster-nodes.html","spaLink":"#/alpha/commands/cluster-nodes","title":"NOTES ON PUBLISHED CONFIG EPOCHS"},{"content":"<h2 id=\"-special-slot-entries\">Special slot entries</h2><p>Normally hash slots associated to a given node are in one of the following formats,\nas already explained above:</p><p>However node hash slots can be in a special state, used in order to communicate errors after a node restart (mismatch between the keys in the AOF/RDB file, and the node hash slots configuration), or when there is a resharding operation in progress. This two states are <strong>importing</strong> and <strong>migrating</strong>.</p><p>The meaning of the two states is explained in the Redis Specification, however the gist of the two states is the following:</p><ul>\n<li><strong>Importing</strong> slots are yet not part of the nodes hash slot, there is a migration in progress. The node will accept queries about these slots only if the <code>ASK</code> command is used.</li>\n<li><strong>Migrating</strong> slots are assigned to the node, but are being migrated to some other node. The node will accept queries if all the keys in the command exist already, otherwise it will emit what is called an <strong>ASK redirection</strong>, to force new keys creation directly in the importing node.</li>\n</ul><p>Importing and migrating slots are emitted in the <code>CLUSTER NODES</code> output as follows:</p><ul>\n<li><strong>Importing slot:</strong> <code>[slot_number-&lt;-importing_from_node_id]</code></li>\n<li><strong>Migrating slot:</strong> <code>[slot_number-&gt;-migrating_to_node_id]</code></li>\n</ul><p>The following are a few examples of importing and migrating slots:</p><ul>\n<li><code>[93-&lt;-292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f]</code></li>\n<li><code>[1002-&lt;-67ed2db8d677e59ec4a4cefb06858cf2a1a89fa1]</code></li>\n<li><code>[77-&gt;-e7d1eecce10fd6bb5eb35b9f99a514335d9ba9ca]</code></li>\n<li><code>[16311-&gt;-292f8b365bb7edb5e285caf0b7e6ddc7265d2f4f]</code></li>\n</ul><p>Note that the format does not have any space, so <code>CLUSTER NODES</code> output format is plain CSV with space as separator even when this special slots are emitted. However a complete parser for the format should be able to handle them.</p><p>Note that:</p><p>@return</p><p>@bulk-string-reply: The serialized cluster configuration.</p>","link":"./alpha/commands/cluster-nodes.html","spaLink":"#/alpha/commands/cluster-nodes","title":"SPECIAL SLOT ENTRIES"},{"content":"<h2 id=\"-example\">Example</h2><p>For example the following command assigns slots 1 2 3 to the node receiving\nthe command:</p><p>However trying to execute it again results into an error since the slots\nare already assigned:</p>","link":"./alpha/commands/cluster-addslots.html","spaLink":"#/alpha/commands/cluster-addslots","title":"EXAMPLE"},{"content":"<h2 id=\"-usage-in-redis-cluster\">Usage in Redis Cluster</h2><p>This command only works in cluster mode and is useful in the following\nRedis Cluster operations:</p>","link":"./alpha/commands/cluster-addslots.html","spaLink":"#/alpha/commands/cluster-addslots","title":"USAGE IN REDIS CLUSTER"},{"content":"<h2 id=\"-information-about-slots-propagation-and-warnings\">Information about slots propagation and warnings</h2><p>Note that once a node assigns a set of slots to itself, it will start\npropagating this information in heartbeat packet headers. However the\nother nodes will accept the information only if they have the slot as\nnot already bound with another node, or if the configuration epoch of the\nnode advertising the new hash slot, is greater than the node currently listed\nin the table.</p><p>This means that this command should be used with care only by applications\norchestrating Redis Cluster, like <code>redis-trib</code>, and the command if used\nout of the right context can leave the cluster in a wrong state or cause\ndata loss.</p><p>@return</p><p>@simple-string-reply: <code>OK</code> if the command was successful. Otherwise an error is returned.</p>","link":"./alpha/commands/cluster-addslots.html","spaLink":"#/alpha/commands/cluster-addslots","title":"INFORMATION ABOUT SLOTS PROPAGATION AND WARNINGS"},{"content":"<h2 id=\"-example\">Example</h2><p>Note that the command implements the full hashing algorithm, including support for <strong>hash tags</strong>, that is the special property of Redis Cluster key hashing algorithm, of hashing just what is between <code>{</code> and <code>}</code> if such a pattern is found inside the key name, in order to force multiple keys to be handled by the same node.</p><p>@return</p><p>@integer-reply: The hash slot number.</p>","link":"./alpha/commands/cluster-keyslot.html","spaLink":"#/alpha/commands/cluster-keyslot","title":"EXAMPLE"},{"content":"<h2 id=\"-client-kill-and-redis-sentinel\">CLIENT KILL and Redis Sentinel</h2><p>Recent versions of Redis Sentinel (Redis 2.8.12 or greater) use CLIENT KILL\nin order to kill clients when an instance is reconfigured, in order to\nforce clients to perform the handshake with one Sentinel again and update\nits configuration.</p>","link":"./alpha/commands/client-kill.html","spaLink":"#/alpha/commands/client-kill","title":"CLIENT KILL AND REDIS SENTINEL"},{"content":"<h2 id=\"-notes\">Notes</h2><p>Due to the single-threaded nature of Redis, it is not possible to\nkill a client connection while it is executing a command. From\nthe client point of view, the connection can never be closed\nin the middle of the execution of a command. However, the client\nwill notice the connection has been closed only when the\nnext command is sent (and results in network error).</p><p>@return</p><p>When called with the three arguments format:</p><p>@simple-string-reply: <code>OK</code> if the connection exists and has been closed</p><p>When called with the filter / value format:</p><p>@integer-reply: the number of clients killed.</p>","link":"./alpha/commands/client-kill.html","spaLink":"#/alpha/commands/client-kill","title":"NOTES"},{"content":"<h2 id=\"-notes\">Notes</h2><p>New fields are regularly added for debugging purpose. Some could be removed\nin the future. A version safe Redis client using this command should parse\nthe output accordingly (i.e. handling gracefully missing fields, skipping\nunknown fields).</p>","link":"./alpha/commands/client-list.html","spaLink":"#/alpha/commands/client-list","title":"NOTES"},{"content":"<h2 id=\"-cluster-setslot-slot-migrating-destination-node-id\">CLUSTER SETSLOT <code>&lt;slot&gt;</code> MIGRATING <code>&lt;destination-node-id&gt;</code></h2><p>This subcommand sets a slot to <em>migrating</em> state. In order to set a slot\nin this state, the node receiving the command must be the hash slot owner,\notherwise an error is returned.</p><p>When a slot is set in migrating state, the node changes behavior in the\nfollowing way:</p>","link":"./alpha/commands/cluster-setslot.html","spaLink":"#/alpha/commands/cluster-setslot","title":"CLUSTER SETSLOT <SLOT> MIGRATING <DESTINATION-NODE-ID>"},{"content":"<h2 id=\"-cluster-setslot-slot-importing-source-node-id\">CLUSTER SETSLOT <code>&lt;slot&gt;</code> IMPORTING <code>&lt;source-node-id&gt;</code></h2><p>This subcommand is the reverse of <code>MIGRATING</code>, and prepares the destination\nnode to import keys from the specified source node. The command only works if\nthe node is not already owner of the specified hash slot.</p><p>When a slot is set in importing state, the node changes behavior in the following way:</p><p>In this way when a node in migrating state generates an <code>ASK</code> redirection, the client contacts the target node, sends <code>ASKING</code>, and immediately after sends the command. This way commands about non-existing keys in the old node or keys already migrated to the target node are executed in the target node, so that:</p>","link":"./alpha/commands/cluster-setslot.html","spaLink":"#/alpha/commands/cluster-setslot","title":"CLUSTER SETSLOT <SLOT> IMPORTING <SOURCE-NODE-ID>"},{"content":"<h2 id=\"-cluster-setslot-slot-stable\">CLUSTER SETSLOT <code>&lt;slot&gt;</code> STABLE</h2><p>This subcommand just clears migrating / importing state from the slot. It is\nmainly used to fix a cluster stuck in a wrong state by <code>redis-trib fix</code>.\nNormally the two states are cleared automatically at the end of the migration\nusing the <code>SETSLOT ... NODE ...</code> subcommand as explained in the next section.</p>","link":"./alpha/commands/cluster-setslot.html","spaLink":"#/alpha/commands/cluster-setslot","title":"CLUSTER SETSLOT <SLOT> STABLE"},{"content":"<h2 id=\"-cluster-setslot-slot-node-node-id\">CLUSTER SETSLOT <code>&lt;slot&gt;</code> NODE <code>&lt;node-id&gt;</code></h2><p>The <code>NODE</code> subcommand is the one with the most complex semantics. It\nassociates the hash slot with the specified node, however the command works\nonly in specific situations and has different side effects depending on the\nslot state. The following is the set of pre-conditions and side effects of the\ncommand:</p><p>It is important to note that step 3 is the only time when a Redis Cluster node will create a new config epoch without agreement from other nodes. This only happens when a manual configuration is operated. However it is impossible that this creates a non-transient setup where two nodes have the same config epoch, since Redis Cluster uses a config epoch collision resolution algorithm.</p><p>@return</p><p>@simple-string-reply: All the subcommands return <code>OK</code> if the command was successful. Otherwise an error is returned.</p>","link":"./alpha/commands/cluster-setslot.html","spaLink":"#/alpha/commands/cluster-setslot","title":"CLUSTER SETSLOT <SLOT> NODE <NODE-ID>"},{"content":"<h2 id=\"-redis-cluster-live-resharding-explained\">Redis Cluster live resharding explained</h2><p>The <code>CLUSTER SETSLOT</code> command is an important piece used by Redis Cluster in order to migrate all the keys contained in one hash slot from one node to another. This is how the migration is orchestrated, with the help of other commands as well. We’ll call the node that has the current ownership of the hash slot the <code>source</code> node, and the node where we want to migrate the <code>destination</code> node.</p><p>Notes:</p><ul>\n<li>The order of step 1 and 2 is important. We want the destination node to be ready to accept <code>ASK</code> redirections when the source node is configured to redirect.</li>\n<li>Step 4 does not technically need to use <code>SETSLOT</code> in the nodes not involved in the resharding, since the configuration will eventually propagate itself, however it is a good idea to do so in order to stop nodes from pointing to the wrong node for the hash slot moved as soon as possible, resulting in less redirections to find the right node.</li>\n</ul>","link":"./alpha/commands/cluster-setslot.html","spaLink":"#/alpha/commands/cluster-setslot","title":"REDIS CLUSTER LIVE RESHARDING EXPLAINED"},{"content":"<h2 id=\"-non-blocking-behavior\">Non-blocking behavior</h2><p>When <code>BLPOP</code> is called, if at least one of the specified keys contains a\nnon-empty list, an element is popped from the head of the list and returned to\nthe caller together with the <code>key</code> it was popped from.</p><p>Keys are checked in the order that they are given.\nLet’s say that the key <code>list1</code> doesn’t exist and <code>list2</code> and <code>list3</code> hold\nnon-empty lists.\nConsider the following command:</p><p><code>BLPOP</code> guarantees to return an element from the list stored at <code>list2</code> (since\nit is the first non empty list when checking <code>list1</code>, <code>list2</code> and <code>list3</code> in\nthat order).</p>","link":"./alpha/commands/blpop.html","spaLink":"#/alpha/commands/blpop","title":"NON-BLOCKING BEHAVIOR"},{"content":"<h2 id=\"-blocking-behavior\">Blocking behavior</h2><p>If none of the specified keys exist, <code>BLPOP</code> blocks the connection until another\nclient performs an <code>LPUSH</code> or <code>RPUSH</code> operation against one of the keys.</p><p>Once new data is present on one of the lists, the client returns with the name\nof the key unblocking it and the popped value.</p><p>When <code>BLPOP</code> causes a client to block and a non-zero timeout is specified,\nthe client will unblock returning a <code>nil</code> multi-bulk value when the specified\ntimeout has expired without a push operation against at least one of the\nspecified keys.</p><p><strong>The timeout argument is interpreted as an integer value specifying the maximum number of seconds to block</strong>. A timeout of zero can be used to block indefinitely.</p>","link":"./alpha/commands/blpop.html","spaLink":"#/alpha/commands/blpop","title":"BLOCKING BEHAVIOR"},{"content":"<h2 id=\"-what-key-is-served-first-what-client-what-element-priority-ordering-details\">What key is served first? What client? What element? Priority ordering details.</h2><ul>\n<li>If the client tries to blocks for multiple keys, but at least one key contains elements, the returned key / element pair is the first key from left to right that has one or more elements. In this case the client is not blocked. So for instance <code>BLPOP key1 key2 key3 key4 0</code>, assuming that both <code>key2</code> and <code>key4</code> are non-empty, will always return an element from <code>key2</code>.</li>\n<li>If multiple clients are blocked for the same key, the first client to be served is the one that was waiting for more time (the first that blocked for the key). Once a client is unblocked it does not retain any priority, when it blocks again with the next call to <code>BLPOP</code> it will be served accordingly to the number of clients already blocked for the same key, that will all be served before it (from the first to the last that blocked).</li>\n<li>When a client is blocking for multiple keys at the same time, and elements are available at the same time in multiple keys (because of a transaction or a Lua script added elements to multiple lists), the client will be unblocked using the first key that received a push operation (assuming it has enough elements to serve our client, as there may be other clients as well waiting for this key). Basically after the execution of every command Redis will run a list of all the keys that received data AND that have at least a client blocked. The list is ordered by new element arrival time, from the first key that received data to the last. For every key processed, Redis will serve all the clients waiting for that key in a FIFO fashion, as long as there are elements in this key. When the key is empty or there are no longer clients waiting for this key, the next key that received new data in the previous command / transaction / script is processed, and so forth.</li>\n</ul>","link":"./alpha/commands/blpop.html","spaLink":"#/alpha/commands/blpop","title":"WHAT KEY IS SERVED FIRST? WHAT CLIENT? WHAT ELEMENT? PRIORITY ORDERING DETAILS."},{"content":"<h2 id=\"-behavior-of-blpop-when-multiple-elements-are-pushed-inside-a-list\">Behavior of <code>!BLPOP</code> when multiple elements are pushed inside a list.</h2><p>There are times when a list can receive multiple elements in the context of the same conceptual command:</p><ul>\n<li>Variadic push operations such as <code>LPUSH mylist a b c</code>.</li>\n<li>After an <code>EXEC</code> of a <code>MULTI</code> block with multiple push operations against the same list.</li>\n<li>Executing a Lua Script with Redis 2.6 or newer.</li>\n</ul><p>When multiple elements are pushed inside a list where there are clients blocking, the behavior is different for Redis 2.4 and Redis 2.6 or newer.</p><p>For Redis 2.6 what happens is that the command performing multiple pushes is executed, and <em>only after</em> the execution of the command the blocked clients are served. Consider this sequence of commands.</p><p>If the above condition happens using a Redis 2.6 server or greater, Client <strong>A</strong> will be served with the <code>c</code> element, because after the <code>LPUSH</code> command the list contains <code>c,b,a</code>, so taking an element from the left means to return <code>c</code>.</p><p>Instead Redis 2.4 works in a different way: clients are served <em>in the context</em> of the push operation, so as long as <code>LPUSH foo a b c</code> starts pushing the first element to the list, it will be delivered to the Client <strong>A</strong>, that will receive <code>a</code> (the first element pushed).</p><p>The behavior of Redis 2.4 creates a lot of problems when replicating or persisting data into the AOF file, so the much more generic and semantically simpler behavior was introduced into Redis 2.6 to prevent problems.</p><p>Note that for the same reason a Lua script or a <code>MULTI/EXEC</code> block may push elements into a list and afterward <strong>delete the list</strong>. In this case the blocked clients will not be served at all and will continue to be blocked as long as no data is present on the list after the execution of a single command, transaction, or script.</p>","link":"./alpha/commands/blpop.html","spaLink":"#/alpha/commands/blpop","title":"BEHAVIOR OF !BLPOP WHEN MULTIPLE ELEMENTS ARE PUSHED INSIDE A LIST."},{"content":"<h2 id=\"-blpop-inside-a-multi-exec-transaction\"><code>!BLPOP</code> inside a <code>!MULTI</code> / <code>!EXEC</code> transaction</h2><p><code>BLPOP</code> can be used with pipelining (sending multiple commands and\nreading the replies in batch), however this setup makes sense almost solely\nwhen it is the last command of the pipeline.</p><p>Using <code>BLPOP</code> inside a <code>MULTI</code> / <code>EXEC</code> block does not make a lot of sense\nas it would require blocking the entire server in order to execute the block\natomically, which in turn does not allow other clients to perform a push\noperation. For this reason the behavior of <code>BLPOP</code> inside <code>MULTI</code> / <code>EXEC</code> when the list is empty is to return a <code>nil</code> multi-bulk reply, which is the same\nthing that happens when the timeout is reached.</p><p>If you like science fiction, think of time flowing at infinite speed inside a\n<code>MULTI</code> / <code>EXEC</code> block…</p><p>@return</p><p>@array-reply: specifically:</p><ul>\n<li>A <code>nil</code> multi-bulk when no element could be popped and the timeout expired.</li>\n<li>A two-element multi-bulk with the first element being the name of the key\nwhere an element was popped and the second element being the value of the\npopped element.</li>\n</ul><p>@examples</p>","link":"./alpha/commands/blpop.html","spaLink":"#/alpha/commands/blpop","title":"!BLPOP INSIDE A !MULTI / !EXEC TRANSACTION"},{"content":"<h2 id=\"-reliable-queues\">Reliable queues</h2><p>When <code>BLPOP</code> returns an element to the client, it also removes the element from the list. This means that the element only exists in the context of the client: if the client crashes while processing the returned element, it is lost forever.</p><p>This can be a problem with some application where we want a more reliable messaging system. When this is the case, please check the <code>BRPOPLPUSH</code> command, that is a variant of <code>BLPOP</code> that adds the returned element to a target list before returning it to the client.</p>","link":"./alpha/commands/blpop.html","spaLink":"#/alpha/commands/blpop","title":"RELIABLE QUEUES"},{"content":"<h2 id=\"-pattern-event-notification\">Pattern: Event notification</h2><p>Using blocking list operations it is possible to mount different blocking\nprimitives.\nFor instance for some application you may need to block waiting for elements\ninto a Redis Set, so that as far as a new element is added to the Set, it is\npossible to retrieve it without resort to polling.\nThis would require a blocking version of <code>SPOP</code> that is not available, but using\nblocking list operations we can easily accomplish this task.</p><p>The consumer will do:</p><p>While in the producer side we’ll use simply:</p>","link":"./alpha/commands/blpop.html","spaLink":"#/alpha/commands/blpop","title":"PATTERN: EVENT NOTIFICATION"},{"content":"<h2 id=\"-nested-result-array\">Nested Result Array</h2><p>Each top-level result contains six nested results.  Each nested result is:</p><ul>\n<li>command name</li>\n<li>command arity specification</li>\n<li>nested @array-reply of command flags</li>\n<li>position of first key in argument list</li>\n<li>position of last key in argument list</li>\n<li>step count for locating repeating keys</li>\n</ul>","link":"./alpha/commands/command.html","spaLink":"#/alpha/commands/command","title":"NESTED RESULT ARRAY"},{"content":"<h3 id=\"-nested-result-array-command-name\">Command Name</h3><p>Command name is the command returned as a lowercase string.</p>","link":"./alpha/commands/command.html","spaLink":"#/alpha/commands/command","title":"Command Name"},{"content":"<h3 id=\"-nested-result-array-command-arity\">Command Arity</h3><p>Command arity follows a simple pattern:</p><ul>\n<li>positive if command has fixed number of required arguments.</li>\n<li>negative if command has minimum number of required arguments, but may have more.</li>\n</ul><p>Command arity <em>includes</em> counting the command name itself.</p><p>Examples:</p><ul>\n<li><code>GET</code> arity is 2 since the command only accepts one\nargument and always has the format <code>GET _key_</code>.</li>\n<li><code>MGET</code> arity is -2 since the command accepts at a minimum\none argument, but up to an unlimited number: <code>MGET _key1_ [key2] [key3] ...</code>.</li>\n</ul><p>Also note with <code>MGET</code>, the -1 value for “last key position” means the list\nof keys may have unlimited length.</p>","link":"./alpha/commands/command.html","spaLink":"#/alpha/commands/command","title":"Command Arity"},{"content":"<h3 id=\"-nested-result-array-flags\">Flags</h3><p>Command flags is @array-reply containing one or more status replies:</p><ul>\n<li><em>write</em> - command may result in modifications</li>\n<li><em>readonly</em> - command will never modify keys</li>\n<li><em>denyoom</em> - reject command if currently OOM</li>\n<li><em>admin</em> - server admin command</li>\n<li><em>pubsub</em> - pubsub-related command</li>\n<li><em>noscript</em> - deny this command from scripts</li>\n<li><em>random</em> - command has random results, dangerous for scripts</li>\n<li><em>sort_for_script</em> - if called from script, sort output</li>\n<li><em>loading</em> - allow command while database is loading</li>\n<li><em>stale</em> - allow command while replica has stale data</li>\n<li><em>skip_monitor</em> - do not show this command in MONITOR</li>\n<li><em>asking</em> - cluster related - accept even if importing</li>\n<li><em>fast</em> - command operates in constant or log(N) time.  Used for latency monitoring.</li>\n<li><em>movablekeys</em> - keys have no pre-determined position.  You must discover keys yourself.</li>\n</ul>","link":"./alpha/commands/command.html","spaLink":"#/alpha/commands/command","title":"Flags"},{"content":"<h3 id=\"-nested-result-array-movable-keys\">Movable Keys</h3><p>Some Redis commands have no predetermined key locations.  For those commands,\nflag <code>movablekeys</code> is added to the command flags @array-reply.  Your Redis\nCluster client needs to parse commands marked <code>movabkeleys</code> to locate all relevant key positions.</p><p>Complete list of commands currently requiring key location parsing:</p><ul>\n<li><code>SORT</code> - optional <code>STORE</code> key, optional <code>BY</code> weights, optional <code>GET</code> keys</li>\n<li><code>ZUNIONSTORE</code> - keys stop when <code>WEIGHT</code> or <code>AGGREGATE</code> starts</li>\n<li><code>ZINTERSTORE</code> - keys stop when <code>WEIGHT</code> or <code>AGGREGATE</code> starts</li>\n<li><code>EVAL</code> - keys stop after <code>numkeys</code> count arguments</li>\n<li><code>EVALSHA</code> - keys stop after <code>numkeys</code> count arguments</li>\n</ul><p>Also see <code>COMMAND GETKEYS</code> for getting your Redis server tell you where keys\nare in any given command.</p>","link":"./alpha/commands/command.html","spaLink":"#/alpha/commands/command","title":"Movable Keys"},{"content":"<h3 id=\"-nested-result-array-first-key-in-argument-list\">First Key in Argument List</h3><p>For most commands the first key is position 1.  Position 0 is\nalways the command name itself.</p>","link":"./alpha/commands/command.html","spaLink":"#/alpha/commands/command","title":"First Key in Argument List"},{"content":"<h3 id=\"-nested-result-array-last-key-in-argument-list\">Last Key in Argument List</h3><p>Redis commands usually accept one key, two keys, or an unlimited number of keys.</p><p>If a command accepts one key, the first key and last key positions is 1.</p><p>If a command accepts two keys (e.g. <code>BRPOPLPUSH</code>, <code>SMOVE</code>, <code>RENAME</code>, …) then the\nlast key position is the location of the last key in the argument list.</p><p>If a command accepts an unlimited number of keys, the last key position is -1.</p>","link":"./alpha/commands/command.html","spaLink":"#/alpha/commands/command","title":"Last Key in Argument List"},{"content":"<h3 id=\"-nested-result-array-step-count\">Step Count</h3><p>Key step count allows us to find key positions in commands\nlike <code>MSET</code> where the format is <code>MSET _key1_ _val1_ [key2] [val2] [key3] [val3]...</code>.</p><p>In the case of <code>MSET</code>, keys are every other position so the step value is 2.  Compare\nwith <code>MGET</code> above where the step value is just 1.</p><p>@return</p><p>@array-reply: nested list of command details.  Commands are returned\nin random order.</p><p>@examples</p>","link":"./alpha/commands/command.html","spaLink":"#/alpha/commands/command","title":"Step Count"},{"content":"<h2 id=\"-force-option-manual-failover-when-the-master-is-down\">FORCE option: manual failover when the master is down</h2><p>The command behavior can be modified by two options: <strong>FORCE</strong> and <strong>TAKEOVER</strong>.</p><p>If the <strong>FORCE</strong> option is given, the slave does not perform any handshake\nwith the master, that may be not reachable, but instead just starts a\nfailover ASAP starting from point 4. This is useful when we want to start\na manual failover while the master is no longer reachable.</p><p>However using <strong>FORCE</strong> we still need the majority of masters to be available\nin order to authorize the failover and generate a new configuration epoch\nfor the slave that is going to become master.</p>","link":"./alpha/commands/cluster-failover.html","spaLink":"#/alpha/commands/cluster-failover","title":"FORCE OPTION: MANUAL FAILOVER WHEN THE MASTER IS DOWN"},{"content":"<h2 id=\"-takeover-option-manual-failover-without-cluster-consensus\">TAKEOVER option: manual failover without cluster consensus</h2><p>There are situations where this is not enough, and we want a slave to failover\nwithout any agreement with the rest of the cluster. A real world use case\nfor this is to mass promote slaves in a different data center to masters\nin order to perform a data center switch, while all the masters are down\nor partitioned away.</p><p>The <strong>TAKEOVER</strong> option implies everything <strong>FORCE</strong> implies, but also does\nnot uses any cluster authorization in order to failover. A slave receiving\n<code>CLUSTER FAILOVER TAKEOVER</code> will instead:</p><p>Note that <strong>TAKEOVER violates the last-failover-wins principle</strong> of Redis Cluster, since the configuration epoch generated by the slave violates the normal generation of configuration epochs in several ways:</p><p>Because of this the <strong>TAKEOVER</strong> option should be used with care.</p>","link":"./alpha/commands/cluster-failover.html","spaLink":"#/alpha/commands/cluster-failover","title":"TAKEOVER OPTION: MANUAL FAILOVER WITHOUT CLUSTER CONSENSUS"},{"content":"<h2 id=\"-implementation-details-and-notes\">Implementation details and notes</h2><p><code>CLUSTER FAILOVER</code>, unless the <strong>TAKEOVER</strong> option is specified,  does not\nexecute a failover synchronously, it only <em>schedules</em> a manual failover,\nbypassing the failure detection stage, so to check if the failover actually\nhappened, <code>CLUSTER NODES</code> or other means should be used in order to verify\nthat the state of the cluster changes after some time the command was sent.</p><p>@return</p><p>@simple-string-reply: <code>OK</code> if the command was accepted and a manual failover is going to be attempted. An error if the operation cannot be executed, for example if we are talking with a node which is already a master.</p>","link":"./alpha/commands/cluster-failover.html","spaLink":"#/alpha/commands/cluster-failover","title":"IMPLEMENTATION DETAILS AND NOTES"},{"content":"<h2 id=\"-nested-result-array\">Nested Result Array</h2><p>Each nested result is:</p><ul>\n<li>Start slot range</li>\n<li>End slot range</li>\n<li>Master for slot range represented as nested IP/Port array </li>\n<li>First replica of master for slot range</li>\n<li>Second replica</li>\n<li>…continues until all replicas for this master are returned.</li>\n</ul><p>Each result includes all active replicas of the master instance\nfor the listed slot range.  Failed replicas are not returned.</p><p>The third nested reply is guaranteed to be the IP/Port pair of\nthe master instance for the slot range.\nAll IP/Port pairs after the third nested reply are replicas\nof the master.</p><p>If a cluster instance has non-contiguous slots (e.g. 1-400,900,1800-6000) then\nmaster and replica IP/Port results will be duplicated for each top-level\nslot range reply.</p><p><strong>Warning:</strong> Newer versions of Redis Cluster will output, for each Redis instance, not just the IP and port, but also the node ID as third element of the array. In future versions there could be more elements describing the node better. In general a client implementation should just rely on the fact that certain parameters are at fixed positions as specified, but more parameters may follow and should be ignored. Similarly a client library should try if possible to cope with the fact that older versions may just have the IP and port parameter.</p><p>@return</p><p>@array-reply: nested list of slot ranges with IP/Port mappings.</p>","link":"./alpha/commands/cluster-slots.html","spaLink":"#/alpha/commands/cluster-slots","title":"NESTED RESULT ARRAY"},{"content":"<h3 id=\"-nested-result-array-sample-output-old-version\">Sample Output (old version)</h3>","link":"./alpha/commands/cluster-slots.html","spaLink":"#/alpha/commands/cluster-slots","title":"Sample Output (old version)"},{"content":"<h3 id=\"-nested-result-array-sample-output-new-version-includes-ids\">Sample Output (new version, includes IDs)</h3>","link":"./alpha/commands/cluster-slots.html","spaLink":"#/alpha/commands/cluster-slots","title":"Sample Output (new version, includes IDs)"},{"content":"<h2 id=\"-background\">Background</h2><p><code>EXPIREAT</code> was introduced in order to convert relative timeouts to absolute\ntimeouts for the AOF persistence mode.\nOf course, it can be used directly to specify that a given key should expire at\na given time in the future.</p><p>@return</p><p>@integer-reply, specifically:</p><ul>\n<li><code>1</code> if the timeout was set.</li>\n<li><code>0</code> if <code>key</code> does not exist or the timeout could not be set (see: <code>EXPIRE</code>).</li>\n</ul><p>@examples</p>","link":"./alpha/commands/expireat.html","spaLink":"#/alpha/commands/expireat","title":"BACKGROUND"},{"content":"<h2 id=\"-use-case\">Use case</h2><p>As already specified this command is mostly not needed if not for debugging. However there are actual use cases, which is, when there is to query for the same areas multiple times, or with a different granularity or area shape compared to what Redis <code>GEORADIUS</code> is able to provide, the client may implement using this command part of the logic on the client side. Score ranges representing given areas can be cached client side and used to retrieve elements directly using <code>ZRANGEBYSCORE</code>.</p><p>@return</p><p>@array-reply, specifically:</p><p>The command returns an array of give elements in the following order:</p><ul>\n<li>The 52 bit geohash</li>\n<li>min-longitude, min-latitude of the area identified</li>\n<li>max-longitude, max-latitude of the area identified</li>\n<li>center-longitude, center-latitude</li>\n<li>min-score and max-score of the sorted set to retrieve the members inside the area</li>\n</ul><p>@examples</p>","link":"./alpha/commands/geoencode.html","spaLink":"#/alpha/commands/geoencode","title":"USE CASE"},{"content":"<h2 id=\"-implementation-details\">Implementation details</h2><p>The command is always propagated in the replication link and the Append Only\nFile as a <code>HSET</code> operation, so that differences in the underlying floating point\nmath implementation will not be sources of inconsistency.</p>","link":"./alpha/commands/hincrbyfloat.html","spaLink":"#/alpha/commands/hincrbyfloat","title":"IMPLEMENTATION DETAILS"},{"content":"<h2 id=\"-design-pattern\">Design pattern</h2><p><code>GETSET</code> can be used together with <code>INCR</code> for counting with atomic reset.\nFor example: a process may call <code>INCR</code> against the key <code>mycounter</code> every time\nsome event occurs, but from time to time we need to get the value of the counter\nand reset it to zero atomically.\nThis can be done using <code>GETSET mycounter \"0\"</code>:</p><p>@return</p><p>@bulk-string-reply: the old value stored at <code>key</code>, or <code>nil</code> when <code>key</code> did not exist.</p><p>@examples</p>","link":"./alpha/commands/getset.html","spaLink":"#/alpha/commands/getset","title":"DESIGN PATTERN"},{"content":"<h2 id=\"-geohash-string-properties\">Geohash string properties</h2><p>The command returns 11 characters Geohash strings, so no precision is loss\ncompared to the Redis internal 52 bit representation. The returned Geohashes\nhave the following properties:</p><p>@return</p><p>@array-reply, specifically:</p><p>The command returns an array where each element is the Geohash corresponding to\neach member name passed as argument to the command.</p><p>@examples</p>","link":"./alpha/commands/geohash.html","spaLink":"#/alpha/commands/geohash","title":"GEOHASH STRING PROPERTIES"},{"content":"<h2 id=\"-atomic-rewrite-process\">Atomic rewrite process</h2><p>In order to make sure the redis.conf file is always consistent, that is, on errors or crashes you always end with the old file, or the new one, the rewrite is performed with a single <code>write(2)</code> call that has enough content to be at least as big as the old file. Sometimes additional padding in the form of comments is added in order to make sure the resulting file is big enough, and later the file gets truncated to remove the padding at the end.</p><p>@return</p><p>@simple-string-reply: <code>OK</code> when the configuration was rewritten properly.\nOtherwise an error is returned.</p>","link":"./alpha/commands/config-rewrite.html","spaLink":"#/alpha/commands/config-rewrite","title":"ATOMIC REWRITE PROCESS"},{"content":"<h2 id=\"-how-does-it-work\">How does it work?</h2><p>The way the sorted set is populated is using a technique called\n<a href=\"https://en.wikipedia.org/wiki/Geohash\">Geohash</a>. Latitude and Longitude\nbits are interleaved in order to form an unique 52 bit integer. We know\nthat a sorted set double score can represent a 52 bit integer without losing\nprecision.</p><p>This format allows for radius querying by checking the 1+8 areas needed\nto cover the whole radius, and discarding elements outside the radius.\nThe areas are checked by calculating the range of the box covered removing\nenough bits from the less significant part of the sorted set score, and\ncomputing the score range to query in the sorted set for each area.</p>","link":"./alpha/commands/geoadd.html","spaLink":"#/alpha/commands/geoadd","title":"HOW DOES IT WORK?"},{"content":"<h2 id=\"-what-earth-model-does-it-use\">What Earth model does it use?</h2><p>It just assumes that the Earth is a sphere, since the used distance formula\nis the Haversine formula. This formula is only an approximation when applied to the Earth, which is not a perfect sphere. The introduced errors are not an issue when used in the context of social network sites that need to query by radius\nand most other applications. However in the worst case the error may be up to\n0.5%, so you may want to consider other systems for error-critical applications.</p><p>@return</p><p>@integer-reply, specifically:</p><ul>\n<li>The number of elements added to the sorted set, not including elements\nalready existing for which the score was updated.</li>\n</ul><p>@examples</p>","link":"./alpha/commands/geoadd.html","spaLink":"#/alpha/commands/geoadd","title":"WHAT EARTH MODEL DOES IT USE?"},{"content":"<h2 id=\"-refreshing-expires\">Refreshing expires</h2><p>It is possible to call <code>EXPIRE</code> using as argument a key that already has an\nexisting expire set.\nIn this case the time to live of a key is <em>updated</em> to the new value.\nThere are many useful applications for this, an example is documented in the\n<em>Navigation session</em> pattern section below.</p>","link":"./alpha/commands/expire.html","spaLink":"#/alpha/commands/expire","title":"REFRESHING EXPIRES"},{"content":"<h2 id=\"-differences-in-redis-prior-213\">Differences in Redis prior 2.1.3</h2><p>In Redis versions prior <strong>2.1.3</strong> altering a key with an expire set using a\ncommand altering its value had the effect of removing the key entirely.\nThis semantics was needed because of limitations in the replication layer that\nare now fixed.</p><p>@return</p><p>@integer-reply, specifically:</p><ul>\n<li><code>1</code> if the timeout was set.</li>\n<li><code>0</code> if <code>key</code> does not exist or the timeout could not be set.</li>\n</ul><p>@examples</p>","link":"./alpha/commands/expire.html","spaLink":"#/alpha/commands/expire","title":"DIFFERENCES IN REDIS PRIOR 2.1.3"},{"content":"<h2 id=\"-pattern-navigation-session\">Pattern: Navigation session</h2><p>Imagine you have a web service and you are interested in the latest N pages\n<em>recently</em> visited by your users, such that each adjacent page view was not\nperformed more than 60 seconds after the previous.\nConceptually you may think at this set of page views as a <em>Navigation session</em>\nif your user, that may contain interesting information about what kind of\nproducts he or she is looking for currently, so that you can recommend related\nproducts.</p><p>You can easily model this pattern in Redis using the following strategy: every\ntime the user does a page view you call the following commands:</p><p>If the user will be idle more than 60 seconds, the key will be deleted and only\nsubsequent page views that have less than 60 seconds of difference will be\nrecorded.</p><p>This pattern is easily modified to use counters using <code>INCR</code> instead of lists\nusing <code>RPUSH</code>.</p>","link":"./alpha/commands/expire.html","spaLink":"#/alpha/commands/expire","title":"PATTERN: NAVIGATION SESSION"},{"content":"<h1 id=\"appendix-redis-expires\">Appendix: Redis expires</h1>","link":"./alpha/commands/expire.html","spaLink":"#/alpha/commands/expire","title":"APPENDIX: REDIS EXPIRES"},{"content":"<h2 id=\"appendix-redis-expires-keys-with-an-expire\">Keys with an expire</h2><p>Normally Redis keys are created without an associated time to live.\nThe key will simply live forever, unless it is removed by the user in an\nexplicit way, for instance using the <code>DEL</code> command.</p><p>The <code>EXPIRE</code> family of commands is able to associate an expire to a given key,\nat the cost of some additional memory used by the key.\nWhen a key has an expire set, Redis will make sure to remove the key when the\nspecified amount of time elapsed.</p><p>The key time to live can be updated or entirely removed using the <code>EXPIRE</code> and\n<code>PERSIST</code> command (or other strictly related commands).</p>","link":"./alpha/commands/expire.html","spaLink":"#/alpha/commands/expire","title":"KEYS WITH AN EXPIRE"},{"content":"<h2 id=\"appendix-redis-expires-expire-accuracy\">Expire accuracy</h2><p>In Redis 2.4 the expire might not be pin-point accurate, and it could be between\nzero to one seconds out.</p><p>Since Redis 2.6 the expire error is from 0 to 1 milliseconds.</p>","link":"./alpha/commands/expire.html","spaLink":"#/alpha/commands/expire","title":"EXPIRE ACCURACY"},{"content":"<h2 id=\"appendix-redis-expires-expires-and-persistence\">Expires and persistence</h2><p>Keys expiring information is stored as absolute Unix timestamps (in milliseconds\nin case of Redis version 2.6 or greater).\nThis means that the time is flowing even when the Redis instance is not active.</p><p>For expires to work well, the computer time must be taken stable.\nIf you move an RDB file from two computers with a big desync in their clocks,\nfunny things may happen (like all the keys loaded to be expired at loading\ntime).</p><p>Even running instances will always check the computer clock, so for instance if\nyou set a key with a time to live of 1000 seconds, and then set your computer\ntime 2000 seconds in the future, the key will be expired immediately, instead of\nlasting for 1000 seconds.</p>","link":"./alpha/commands/expire.html","spaLink":"#/alpha/commands/expire","title":"EXPIRES AND PERSISTENCE"},{"content":"<h2 id=\"appendix-redis-expires-how-redis-expires-keys\">How Redis expires keys</h2><p>Redis keys are expired in two ways: a passive way, and an active way.</p><p>A key is actively expired simply when some client tries to access it, and the\nkey is found to be timed out.</p><p>Of course this is not enough as there are expired keys that will never be\naccessed again.\nThese keys should be expired anyway, so periodically Redis tests a few keys at\nrandom among keys with an expire set.\nAll the keys that are already expired are deleted from the keyspace.</p><p>Specifically this is what Redis does 10 times per second:</p><p>This is a trivial probabilistic algorithm, basically the assumption is that our\nsample is representative of the whole key space, and we continue to expire until\nthe percentage of keys that are likely to be expired is under 25%</p><p>This means that at any given moment the maximum amount of keys already expired\nthat are using memory is at max equal to max amount of write operations per\nsecond divided by 4.</p>","link":"./alpha/commands/expire.html","spaLink":"#/alpha/commands/expire","title":"HOW REDIS EXPIRES KEYS"},{"content":"<h2 id=\"appendix-redis-expires-how-expires-are-handled-in-the-replication-link-and-aof-file\">How expires are handled in the replication link and AOF file</h2><p>In order to obtain a correct behavior without sacrificing consistency, when a\nkey expires, a <code>DEL</code> operation is synthesized in both the AOF file and gains all\nthe attached slaves.\nThis way the expiration process is centralized in the master instance, and there\nis no chance of consistency errors.</p><p>However while the slaves connected to a master will not expire keys\nindependently (but will wait for the <code>DEL</code> coming from the master), they’ll\nstill take the full state of the expires existing in the dataset, so when a\nslave is elected to a master it will be able to expire the keys independently,\nfully acting as a master.</p>","link":"./alpha/commands/expire.html","spaLink":"#/alpha/commands/expire","title":"HOW EXPIRES ARE HANDLED IN THE REPLICATION LINK AND AOF FILE"},{"content":"<h2 id=\"-introduction-to-eval\">Introduction to EVAL</h2><p><code>EVAL</code> and <code>EVALSHA</code> are used to evaluate scripts using the Lua interpreter\nbuilt into Redis starting from version 2.6.0.</p><p>The first argument of <code>EVAL</code> is a Lua 5.1 script.\nThe script does not need to define a Lua function (and should not).\nIt is just a Lua program that will run in the context of the Redis server.</p><p>The second argument of <code>EVAL</code> is the number of arguments that follows the script\n(starting from the third argument) that represent Redis key names.\nThe arguments can be accessed by Lua using the <code>!KEYS</code> global variable in the\nform of a one-based array (so <code>KEYS[1]</code>, <code>KEYS[2]</code>, …).</p><p>All the additional arguments should not represent key names and can be accessed\nby Lua using the <code>ARGV</code> global variable, very similarly to what happens with\nkeys (so <code>ARGV[1]</code>, <code>ARGV[2]</code>, …).</p><p>The following example should clarify what stated above:</p><p>Note: as you can see Lua arrays are returned as Redis multi bulk replies, that\nis a Redis return type that your client library will likely convert into an\nArray type in your programming language.</p><p>It is possible to call Redis commands from a Lua script using two different Lua\nfunctions:</p><ul>\n<li><code>redis.call()</code></li>\n<li><code>redis.pcall()</code></li>\n</ul><p><code>redis.call()</code> is similar to <code>redis.pcall()</code>, the only difference is that if a\nRedis command call will result in an error, <code>redis.call()</code> will raise a Lua\nerror that in turn will force <code>EVAL</code> to return an error to the command caller,\nwhile <code>redis.pcall</code> will trap the error and return a Lua table representing the\nerror.</p><p>The arguments of the <code>redis.call()</code> and <code>redis.pcall()</code> functions are all\nthe arguments of a well formed Redis command:</p><p>The above script sets the key <code>foo</code> to the string <code>bar</code>.\nHowever it violates the <code>EVAL</code> command semantics as all the keys that the script\nuses should be passed using the <code>!KEYS</code> array:</p><p>All Redis commands must be analyzed before execution to determine which\nkeys the command will operate on.  In order for this to be true for <code>EVAL</code>, keys must be passed explicitly.\nThis is useful in many ways, but especially to make sure Redis Cluster\ncan forward your request to the appropriate cluster node.</p><p>Note this rule is not enforced in order to provide the user with\nopportunities to abuse the Redis single instance configuration, at the cost of\nwriting scripts not compatible with Redis Cluster.</p><p>Lua scripts can return a value that is converted from the Lua type to the Redis\nprotocol using a set of conversion rules.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"INTRODUCTION TO EVAL"},{"content":"<h2 id=\"-conversion-between-lua-and-redis-data-types\">Conversion between Lua and Redis data types</h2><p>Redis return values are converted into Lua data types when Lua calls a Redis\ncommand using call() or pcall().\nSimilarly Lua data types are converted into the Redis protocol when a Lua script\nreturns a value, so that scripts can control what <code>EVAL</code> will return to the\nclient.</p><p>This conversion between data types is designed in a way that if a Redis type is\nconverted into a Lua type, and then the result is converted back into a Redis\ntype, the result is the same as the initial value.</p><p>In other words there is a one-to-one conversion between Lua and Redis types.\nThe following table shows you all the conversions rules:</p><p><strong>Redis to Lua</strong> conversion table.</p><ul>\n<li>Redis integer reply -&gt; Lua number</li>\n<li>Redis bulk reply -&gt; Lua string</li>\n<li>Redis multi bulk reply -&gt; Lua table (may have other Redis data types nested)</li>\n<li>Redis status reply -&gt; Lua table with a single <code>ok</code> field containing the status</li>\n<li>Redis error reply -&gt; Lua table with a single <code>err</code> field containing the error</li>\n<li>Redis Nil bulk reply and Nil multi bulk reply -&gt; Lua false boolean type</li>\n</ul><p><strong>Lua to Redis</strong> conversion table.</p><ul>\n<li>Lua number -&gt; Redis integer reply (the number is converted into an integer)</li>\n<li>Lua string -&gt; Redis bulk reply</li>\n<li>Lua table (array) -&gt; Redis multi bulk reply (truncated to the first nil inside the Lua array if any)</li>\n<li>Lua table with a single <code>ok</code> field -&gt; Redis status reply</li>\n<li>Lua table with a single <code>err</code> field -&gt; Redis error reply</li>\n<li>Lua boolean false -&gt; Redis Nil bulk reply.</li>\n</ul><p>There is an additional Lua-to-Redis conversion rule that has no corresponding\nRedis to Lua conversion rule:</p><ul>\n<li>Lua boolean true -&gt; Redis integer reply with value of 1.</li>\n</ul><p>Also there are two important rules to note:</p><ul>\n<li>Lua has a single numerical type, Lua numbers. There is no distinction between integers and floats. So we always convert Lua numbers into integer replies, removing the decimal part of the number if any. <strong>If you want to return a float from Lua you should return it as a string</strong>, exactly like Redis itself does (see for instance the <code>ZSCORE</code> command).</li>\n<li>There is <a href=\"http://www.lua.org/pil/19.1.html\">no simple way to have nils inside Lua arrays</a>, this is a result of Lua table semantics, so when Redis converts a Lua array into Redis protocol the conversion is stopped if a nil is encountered.</li>\n</ul><p>Here are a few conversion examples:</p><p>The last example shows how it is possible to receive the exact return value of\n<code>redis.call()</code> or <code>redis.pcall()</code> from Lua that would be returned if the command\nwas called directly.</p><p>In the following example we can see how floats and arrays with nils are handled:</p><p>As you can see 3.333 is converted into 3, and the <em>bar</em> string is never returned as there is a nil before.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"CONVERSION BETWEEN LUA AND REDIS DATA TYPES"},{"content":"<h2 id=\"-helper-functions-to-return-redis-types\">Helper functions to return Redis types</h2><p>There are two helper functions to return Redis types from Lua.</p><ul>\n<li><code>redis.error_reply(error_string)</code> returns an error reply. This function simply returns a single field table with the <code>err</code> field set to the specified string for you.</li>\n<li><code>redis.status_reply(status_string)</code> returns a status reply. This function simply returns a single field table with the <code>ok</code> field set to the specified string for you.</li>\n</ul><p>There is no difference between using the helper functions or directly returning the table with the specified format, so the following two forms are equivalent:</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"HELPER FUNCTIONS TO RETURN REDIS TYPES"},{"content":"<h2 id=\"-atomicity-of-scripts\">Atomicity of scripts</h2><p>Redis uses the same Lua interpreter to run all the commands.\nAlso Redis guarantees that a script is executed in an atomic way: no other\nscript or Redis command will be executed while a script is being executed.\nThis semantic is similar to the one of <code>MULTI</code> / <code>EXEC</code>.\nFrom the point of view of all the other clients the effects of a script are\neither still not visible or already completed.</p><p>However this also means that executing slow scripts is not a good idea.\nIt is not hard to create fast scripts, as the script overhead is very low, but\nif you are going to use slow scripts you should be aware that while the script\nis running no other client can execute commands.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"ATOMICITY OF SCRIPTS"},{"content":"<h2 id=\"-error-handling\">Error handling</h2><p>As already stated, calls to <code>redis.call()</code> resulting in a Redis command error\nwill stop the execution of the script and return an error, in a way that\nmakes it obvious that the error was generated by a script:</p><p>Using <code>redis.pcall()</code> no error is raised, but an error object is\nreturned in the format specified above (as a Lua table with an <code>err</code> field).\nThe script can pass the exact error to the user by returning the error object\nreturned by <code>redis.pcall()</code>.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"ERROR HANDLING"},{"content":"<h2 id=\"-bandwidth-and-evalsha\">Bandwidth and EVALSHA</h2><p>The <code>EVAL</code> command forces you to send the script body again and again.\nRedis does not need to recompile the script every time as it uses an internal\ncaching mechanism, however paying the cost of the additional bandwidth may not\nbe optimal in many contexts.</p><p>On the other hand, defining commands using a special command or via <code>redis.conf</code>\nwould be a problem for a few reasons:</p><ul>\n<li><p>Different instances may have different implementations of a command.</p>\n</li>\n<li><p>Deployment is hard if we have to make sure all instances contain a\ngiven command, especially in a distributed environment.</p>\n</li>\n<li><p>Reading application code, the complete semantics might not be clear since the\napplication calls commands defined server side.</p>\n</li>\n</ul><p>Different instances may have different implementations of a command.</p><p>Deployment is hard if we have to make sure all instances contain a\ngiven command, especially in a distributed environment.</p><p>Reading application code, the complete semantics might not be clear since the\napplication calls commands defined server side.</p><p>In order to avoid these problems while avoiding the bandwidth penalty, Redis\nimplements the <code>EVALSHA</code> command.</p><p><code>EVALSHA</code> works exactly like <code>EVAL</code>, but instead of having a script as the first\nargument it has the SHA1 digest of a script.\nThe behavior is the following:</p><ul>\n<li><p>If the server still remembers a script with a matching SHA1 digest, the\nscript is executed.</p>\n</li>\n<li><p>If the server does not remember a script with this SHA1 digest, a special\nerror is returned telling the client to use <code>EVAL</code> instead.</p>\n</li>\n</ul><p>If the server still remembers a script with a matching SHA1 digest, the\nscript is executed.</p><p>If the server does not remember a script with this SHA1 digest, a special\nerror is returned telling the client to use <code>EVAL</code> instead.</p><p>Example:</p><p>The client library implementation can always optimistically send <code>EVALSHA</code> under\nthe hood even when the client actually calls <code>EVAL</code>, in the hope the script was\nalready seen by the server.\nIf the <code>NOSCRIPT</code> error is returned <code>EVAL</code> will be used instead.</p><p>Passing keys and arguments as additional <code>EVAL</code> arguments is also very useful in\nthis context as the script string remains constant and can be efficiently cached\nby Redis.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"BANDWIDTH AND EVALSHA"},{"content":"<h2 id=\"-script-cache-semantics\">Script cache semantics</h2><p>Executed scripts are guaranteed to be in the script cache of a given execution\nof a Redis instance forever. This means that if an <code>EVAL</code> is performed against a Redis instance all the subsequent <code>EVALSHA</code> calls will succeed.</p><p>The reason why scripts can be cached for long time is that it is unlikely for\na well written application to have enough different scripts to cause memory\nproblems. Every script is conceptually like the implementation of a new command, and even a large application will likely have just a few hundred of them.\nEven if the application is modified many times and scripts will change, the\nmemory used is negligible.</p><p>The only way to flush the script cache is by explicitly calling the <code>SCRIPT FLUSH</code> command, which will <em>completely flush</em> the scripts cache removing all the\nscripts executed so far.</p><p>This is usually needed only when the instance is going to be instantiated for\nanother customer or application in a cloud environment.</p><p>Also, as already mentioned, restarting a Redis instance flushes the\nscript cache, which is not persistent. However from the point of view of the\nclient there are only two ways to make sure a Redis instance was not restarted\nbetween two different commands.</p><ul>\n<li>The connection we have with the server is persistent and was never closed so far.</li>\n<li>The client explicitly checks the <code>runid</code> field in the <code>INFO</code> command in order to make sure the server was not restarted and is still the same process.</li>\n</ul><p>Practically speaking, for the client it is much better to simply assume that in the context of a given connection, cached scripts are guaranteed to be there\nunless an administrator explicitly called the <code>SCRIPT FLUSH</code> command.</p><p>The fact that the user can count on Redis not removing scripts is semantically\nuseful in the context of pipelining.</p><p>For instance an application with a persistent connection to Redis can be sure\nthat if a script was sent once it is still in memory, so EVALSHA can be used\nagainst those scripts in a pipeline without the chance of an error being\ngenerated due to an unknown script (we’ll see this problem in detail later).</p><p>A common pattern is to call <code>SCRIPT LOAD</code> to load all the scripts that will\nappear in a pipeline, then use <code>EVALSHA</code> directly inside the pipeline without\nany need to check for errors resulting from the script hash not being\nrecognized.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"SCRIPT CACHE SEMANTICS"},{"content":"<h2 id=\"-the-script-command\">The SCRIPT command</h2><p>Redis offers a SCRIPT command that can be used in order to control the scripting\nsubsystem.\nSCRIPT currently accepts three different commands:</p><ul>\n<li><p><code>SCRIPT FLUSH</code></p>\n<p>This command is the only way to force Redis to flush the scripts cache.\nIt is most useful in a cloud environment where the same instance can be\nreassigned to a different user.\nIt is also useful for testing client libraries’ implementations of the\nscripting feature.</p>\n</li>\n<li><p><code>SCRIPT EXISTS sha1 sha2 ... shaN</code></p>\n<p>Given a list of SHA1 digests as arguments this command returns an array of\n1 or 0, where 1 means the specific SHA1 is recognized as a script already\npresent in the scripting cache, while 0 means that a script with this SHA1\nwas never seen before (or at least never seen after the latest SCRIPT FLUSH\ncommand).</p>\n</li>\n<li><p><code>SCRIPT LOAD script</code></p>\n<p>This command registers the specified script in the Redis script cache.\nThe command is useful in all the contexts where we want to make sure that\n<code>EVALSHA</code> will not fail (for instance during a pipeline or MULTI/EXEC\noperation), without the need to actually execute the script.</p>\n</li>\n<li><p><code>SCRIPT KILL</code></p>\n<p>This command is the only way to interrupt a long-running script that reaches\nthe configured maximum execution time for scripts.\nThe SCRIPT KILL command can only be used with scripts that did not modify\nthe dataset during their execution (since stopping a read-only script does\nnot violate the scripting engine’s guaranteed atomicity).\nSee the next sections for more information about long running scripts.</p>\n</li>\n</ul><p><code>SCRIPT FLUSH</code></p><p>This command is the only way to force Redis to flush the scripts cache.\nIt is most useful in a cloud environment where the same instance can be\nreassigned to a different user.\nIt is also useful for testing client libraries’ implementations of the\nscripting feature.</p><p><code>SCRIPT EXISTS sha1 sha2 ... shaN</code></p><p>Given a list of SHA1 digests as arguments this command returns an array of\n1 or 0, where 1 means the specific SHA1 is recognized as a script already\npresent in the scripting cache, while 0 means that a script with this SHA1\nwas never seen before (or at least never seen after the latest SCRIPT FLUSH\ncommand).</p><p><code>SCRIPT LOAD script</code></p><p>This command registers the specified script in the Redis script cache.\nThe command is useful in all the contexts where we want to make sure that\n<code>EVALSHA</code> will not fail (for instance during a pipeline or MULTI/EXEC\noperation), without the need to actually execute the script.</p><p><code>SCRIPT KILL</code></p><p>This command is the only way to interrupt a long-running script that reaches\nthe configured maximum execution time for scripts.\nThe SCRIPT KILL command can only be used with scripts that did not modify\nthe dataset during their execution (since stopping a read-only script does\nnot violate the scripting engine’s guaranteed atomicity).\nSee the next sections for more information about long running scripts.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"THE SCRIPT COMMAND"},{"content":"<h2 id=\"-scripts-as-pure-functions\">Scripts as pure functions</h2><p>A very important part of scripting is writing scripts that are pure functions.\nScripts executed in a Redis instance are, by default, replicated on slaves\nand into the AOF file by sending the script itself — not the resulting\ncommands.</p><p>The reason is that sending a script to another Redis instance is often much\nfaster than sending the multiple commands the script generates, so if the\nclient is sending many scripts to the master, converting the scripts into\nindividual commands for the slave / AOF would result in too much bandwidth\nfor the replication link or the Append Only File (and also too much CPU since\ndispatching a command received via network is a lot more work for Redis compared\nto dispatching a command invoked by Lua scripts).</p><p>Normally replicating scripts instead of the effects of the scripts makes sense,\nhowever not in all the cases. So starting with Redis 3.2 (currently not stable),\nthe scripting engine is able to, alternatively, replicate the sequence of write\ncommands resulting from the script execution, instead of replication the\nscript itself. See the next section for more information.\nIn this section we’ll assume that scripts are replicated by sending the whole\nscript. Let’s call this replication mode <strong>whole scripts replication</strong>.</p><p>The main drawback with the <em>whole scripts replication</em> approach is that scripts are required to have the following property:</p><ul>\n<li>The script must always evaluates the same Redis <em>write</em> commands with the\nsame arguments given the same input data set.\nOperations performed by the script cannot depend on any hidden (non-explicit)\ninformation or state that may change as script execution proceeds or between\ndifferent executions of the script, nor can it depend on any external input\nfrom I/O devices.</li>\n</ul><p>Things like using the system time, calling Redis random commands like\n<code>RANDOMKEY</code>, or using Lua random number generator, could result into scripts\nthat will not always evaluate in the same way.</p><p>In order to enforce this behavior in scripts Redis does the following:</p><ul>\n<li>Lua does not export commands to access the system time or other external\nstate.</li>\n<li>Redis will block the script with an error if a script calls a Redis\ncommand able to alter the data set <strong>after</strong> a Redis <em>random</em> command like\n<code>RANDOMKEY</code>, <code>SRANDMEMBER</code>, <code>TIME</code>.\nThis means that if a script is read-only and does not modify the data set it\nis free to call those commands.\nNote that a <em>random command</em> does not necessarily mean a command that uses\nrandom numbers: any non-deterministic command is considered a random command\n(the best example in this regard is the <code>TIME</code> command).</li>\n<li>Redis commands that may return elements in random order, like <code>SMEMBERS</code>\n(because Redis Sets are <em>unordered</em>) have a different behavior when called\nfrom Lua, and undergo a silent lexicographical sorting filter before\nreturning data to Lua scripts.\nSo <code>redis.call(\"smembers\",KEYS[1])</code> will always return the Set elements\nin the same order, while the same command invoked from normal clients may\nreturn different results even if the key contains exactly the same elements.</li>\n<li>Lua pseudo random number generation functions <code>math.random</code> and\n<code>math.randomseed</code> are modified in order to always have the same seed every\ntime a new script is executed.\nThis means that calling <code>math.random</code> will always generate the same sequence\nof numbers every time a script is executed if <code>math.randomseed</code> is not used.</li>\n</ul><p>However the user is still able to write commands with random behavior using the\nfollowing simple trick.\nImagine I want to write a Redis script that will populate a list with N random\nintegers.</p><p>I can start with this small Ruby program:</p><p>Every time this script executed the resulting list will have exactly the\nfollowing elements:</p><p>In order to make it a pure function, but still be sure that every invocation\nof the script will result in different random elements, we can simply add an\nadditional argument to the script that will be used in order to seed the Lua\npseudo-random number generator.\nThe new script is as follows:</p><p>What we are doing here is sending the seed of the PRNG as one of the arguments.\nThis way the script output will be the same given the same arguments, but we are\nchanging one of the arguments in every invocation, generating the random seed\nclient-side.\nThe seed will be propagated as one of the arguments both in the replication\nlink and in the Append Only File, guaranteeing that the same changes will be\ngenerated when the AOF is reloaded or when the slave processes the script.</p><p>Note: an important part of this behavior is that the PRNG that Redis implements\nas <code>math.random</code> and <code>math.randomseed</code> is guaranteed to have the same output\nregardless of the architecture of the system running Redis.\n32-bit, 64-bit, big-endian and little-endian systems will all produce the same\noutput.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"SCRIPTS AS PURE FUNCTIONS"},{"content":"<h2 id=\"-replicating-commands-instead-of-scripts\">Replicating commands instead of scripts</h2><p>Starting with Redis 3.2 (not yet stable) it is possible to select an\nalternative replication method. Instead of replication whole scripts, we\ncan just replicate single write commands generated by the script.\nWe call this <strong>script effects replication</strong>.</p><p>In this replication mode, while Lua scripts are executed, Redis collects\nall the commands executed by the Lua scripting engine that actually modify\nthe dataset. When the script execution finishes, the sequence of commands\nthat the script generated are wrapped into a MULTI / EXEC transaction and\nare sent to slaves and AOF.</p><p>This is useful in several ways depending on the use case:</p><ul>\n<li>When the script is slow to compute, but the effects can be summarized by\na few write commands, it is a shame to re-compute the script on the slaves\nor when reloading the AOF. In this case to replicate just the effect of the\nscript is much better.</li>\n<li>When script effects replication is enabled, the controls about non\ndeterministic functions are disabled. You can, for example, use the <code>TIME</code>\nor <code>SRANDMEMBER</code> commands inside your scripts freely at any place.</li>\n<li>The Lua PRNG in this mode is seeded randomly at every call.</li>\n</ul><p>In order to enable script effects replication, you need to issue the\nfollowing Lua command before any write operated by the script:</p><p>The function returns true if the script effects replication was enabled,\notherwise if the function was called after the script already called\nsome write command, it returns false, and normal whole script replication\nis used.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"REPLICATING COMMANDS INSTEAD OF SCRIPTS"},{"content":"<h2 id=\"-selective-replication-of-commands\">Selective replication of commands</h2><p>When script effects replication is selected (see the previous section), it\nis possible to have more control in the way commands are replicated to slaves\nand AOF. This is a very advanced feature since <strong>a misuse can do damage</strong> by\nbreaking the contract that the master, slaves, and AOF, all must contain the\nsame logical content.</p><p>However this is a useful feature since, sometimes, we need to execute certain\ncommands only in the master in order to create, for example, intermediate\nvalues.</p><p>Think at a Lua script where we perform an intersection between two sets.\nPick five random elements, and create a new set with this five random\nelements. Finally we delete the temporary key representing the intersection\nbetween the two original sets. What we want to replicate is only the creation\nof the new set with the five elements. It’s not useful to also replicate the\ncommands creating the temporary key.</p><p>For this reason, Redis 3.2 introduces a new command that only works when\nscript effects replication is enabled, and is able to control the scripting\nreplication engine. The command is called <code>redis.set_repl()</code> and fails raising\nan error if called when script effects replication is disabled.</p><p>The command can be called with four different arguments:</p><p>By default the scripting engine is always set to <code>REPL_ALL</code>. By calling\nthis function the user can switch on/off AOF and or slaves replication, and\nturn them back later at her/his wish.</p><p>A simple example follows:</p><p>After running the above script, the result is that only keys A and C\nwill be created on slaves and AOF.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"SELECTIVE REPLICATION OF COMMANDS"},{"content":"<h2 id=\"-global-variables-protection\">Global variables protection</h2><p>Redis scripts are not allowed to create global variables, in order to avoid\nleaking data into the Lua state.\nIf a script needs to maintain state between calls (a pretty uncommon need) it\nshould use Redis keys instead.</p><p>When global variable access is attempted the script is terminated and EVAL\nreturns with an error:</p><p>Accessing a <em>non existing</em> global variable generates a similar error.</p><p>Using Lua debugging functionality or other approaches like altering the meta\ntable used to implement global protections in order to circumvent globals\nprotection is not hard.\nHowever it is difficult to do it accidentally.\nIf the user messes with the Lua global state, the consistency of AOF and\nreplication is not guaranteed: don’t do it.</p><p>Note for Lua newbies: in order to avoid using global variables in your scripts\nsimply declare every variable you are going to use using the <em>local</em> keyword.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"GLOBAL VARIABLES PROTECTION"},{"content":"<h2 id=\"-using-select-inside-scripts\">Using SELECT inside scripts</h2><p>It is possible to call <code>SELECT</code> inside Lua scripts like with normal clients,\nHowever one subtle aspect of the behavior changes between Redis 2.8.11 and\nRedis 2.8.12. Before the 2.8.12 release the database selected by the Lua\nscript was <em>transferred</em> to the calling script as current database.\nStarting from Redis 2.8.12 the database selected by the Lua script only\naffects the execution of the script itself, but does not modify the database\nselected by the client calling the script.</p><p>The semantic change between patch level releases was needed since the old\nbehavior was inherently incompatible with the Redis replication layer and\nwas the cause of bugs.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"USING SELECT INSIDE SCRIPTS"},{"content":"<h2 id=\"-available-libraries\">Available libraries</h2><p>The Redis Lua interpreter loads the following Lua libraries:</p><ul>\n<li><code>base</code> lib.</li>\n<li><code>table</code> lib.</li>\n<li><code>string</code> lib.</li>\n<li><code>math</code> lib.</li>\n<li><code>struct</code> lib.</li>\n<li><code>cjson</code> lib.</li>\n<li><code>cmsgpack</code> lib.</li>\n<li><code>bitop</code> lib.</li>\n<li><code>redis.sha1hex</code> function.</li>\n<li><code>redis.breakpoint and redis.debug</code> function in the context of the <a href=\"/topics/ldb\">Redis Lua debugger</a>.</li>\n</ul><p>Every Redis instance is <em>guaranteed</em> to have all the above libraries so you can\nbe sure that the environment for your Redis scripts is always the same.</p><p>struct, CJSON and cmsgpack are external libraries, all the other libraries are standard\nLua libraries.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"AVAILABLE LIBRARIES"},{"content":"<h3 id=\"-available-libraries-struct\">struct</h3><p>struct is a library for packing/unpacking structures within Lua.</p><p>Example:</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"struct"},{"content":"<h3 id=\"-available-libraries-cjson\">CJSON</h3><p>The CJSON library provides extremely fast JSON manipulation within Lua.</p><p>Example:</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"CJSON"},{"content":"<h3 id=\"-available-libraries-cmsgpack\">cmsgpack</h3><p>The cmsgpack library provides simple and fast MessagePack manipulation within Lua.</p><p>Example:</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"cmsgpack"},{"content":"<h3 id=\"-available-libraries-bitop\">bitop</h3><p>The Lua Bit Operations Module adds bitwise operations on numbers.\nIt is available for scripting in Redis since version 2.8.18.</p><p>Example:</p><p>It supports several other functions:\n<code>bit.tobit</code>, <code>bit.tohex</code>, <code>bit.bnot</code>, <code>bit.band</code>, <code>bit.bor</code>, <code>bit.bxor</code>,\n<code>bit.lshift</code>, <code>bit.rshift</code>, <code>bit.arshift</code>, <code>bit.rol</code>, <code>bit.ror</code>, <code>bit.bswap</code>.\nAll available functions are documented in the <a href=\"http://bitop.luajit.org/api.html\">Lua BitOp documentation</a></p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"bitop"},{"content":"<h3 id=\"-available-libraries-redissha1hex\"><code>redis.sha1hex</code></h3><p>Perform the SHA1 of the input string.</p><p>Example:</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"redis.sha1hex"},{"content":"<h2 id=\"-emitting-redis-logs-from-scripts\">Emitting Redis logs from scripts</h2><p>It is possible to write to the Redis log file from Lua scripts using the\n<code>redis.log</code> function.</p><p><code>loglevel</code> is one of:</p><ul>\n<li><code>redis.LOG_DEBUG</code></li>\n<li><code>redis.LOG_VERBOSE</code></li>\n<li><code>redis.LOG_NOTICE</code></li>\n<li><code>redis.LOG_WARNING</code></li>\n</ul><p>They correspond directly to the normal Redis log levels.\nOnly logs emitted by scripting using a log level that is equal or greater than\nthe currently configured Redis instance log level will be emitted.</p><p>The <code>message</code> argument is simply a string.\nExample:</p><p>Will generate the following:</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"EMITTING REDIS LOGS FROM SCRIPTS"},{"content":"<h2 id=\"-sandbox-and-maximum-execution-time\">Sandbox and maximum execution time</h2><p>Scripts should never try to access the external system, like the file system or\nany other system call.\nA script should only operate on Redis data and passed arguments.</p><p>Scripts are also subject to a maximum execution time (five seconds by default).\nThis default timeout is huge since a script should usually run in under a\nmillisecond.\nThe limit is mostly to handle accidental infinite loops created during\ndevelopment.</p><p>It is possible to modify the maximum time a script can be executed with\nmillisecond precision, either via <code>redis.conf</code> or using the CONFIG GET / CONFIG\nSET command.\nThe configuration parameter affecting max execution time is called\n<code>lua-time-limit</code>.</p><p>When a script reaches the timeout it is not automatically terminated by Redis\nsince this violates the contract Redis has with the scripting engine to ensure\nthat scripts are atomic.\nInterrupting a script means potentially leaving the dataset with half-written\ndata.\nFor this reasons when a script executes for more than the specified time the\nfollowing happens:</p><ul>\n<li>Redis logs that a script is running too long.</li>\n<li>It starts accepting commands again from other clients, but will reply with a\nBUSY error to all the clients sending normal commands.\nThe only allowed commands in this status are <code>SCRIPT KILL</code> and <code>SHUTDOWN\nNOSAVE</code>.</li>\n<li>It is possible to terminate a script that executes only read-only commands\nusing the <code>SCRIPT KILL</code> command.\nThis does not violate the scripting semantic as no data was yet written to the\ndataset by the script.</li>\n<li>If the script already called write commands the only allowed command becomes\n<code>SHUTDOWN NOSAVE</code> that stops the server without saving the current data set on\ndisk (basically the server is aborted).</li>\n</ul>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"SANDBOX AND MAXIMUM EXECUTION TIME"},{"content":"<h2 id=\"-evalsha-in-the-context-of-pipelining\">EVALSHA in the context of pipelining</h2><p>Care should be taken when executing <code>EVALSHA</code> in the context of a pipelined\nrequest, since even in a pipeline the order of execution of commands must be\nguaranteed.\nIf <code>EVALSHA</code> will return a <code>NOSCRIPT</code> error the command can not be reissued\nlater otherwise the order of execution is violated.</p><p>The client library implementation should take one of the following approaches:</p><ul>\n<li><p>Always use plain <code>EVAL</code> when in the context of a pipeline.</p>\n</li>\n<li><p>Accumulate all the commands to send into the pipeline, then check for <code>EVAL</code>\ncommands and use the <code>SCRIPT EXISTS</code> command to check if all the scripts are\nalready defined.\nIf not, add <code>SCRIPT LOAD</code> commands on top of the pipeline as required, and\nuse <code>EVALSHA</code> for all the <code>EVAL</code> calls.</p>\n</li>\n</ul><p>Always use plain <code>EVAL</code> when in the context of a pipeline.</p><p>Accumulate all the commands to send into the pipeline, then check for <code>EVAL</code>\ncommands and use the <code>SCRIPT EXISTS</code> command to check if all the scripts are\nalready defined.\nIf not, add <code>SCRIPT LOAD</code> commands on top of the pipeline as required, and\nuse <code>EVALSHA</code> for all the <code>EVAL</code> calls.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"EVALSHA IN THE CONTEXT OF PIPELINING"},{"content":"<h2 id=\"-debugging-lua-scripts\">Debugging Lua scripts</h2><p>Starting with Redis 3.2 (currently in beta), Redis has support for native\nLua debugging. The Redis Lua debugger is a remote debugger consisting of\na server, which is Redis itself, and a client, which is by default <code>redis-cli</code>.</p><p>The Lua debugger is described in the <a href=\"/topics/ldb\">Lua scripts debugging</a> section of the Redis documentation.</p>","link":"./alpha/commands/eval.html","spaLink":"#/alpha/commands/eval","title":"DEBUGGING LUA SCRIPTS"},{"content":"<h2 id=\"-consistency-with-range-functions-in-various-programming-languages\">Consistency with range functions in various programming languages</h2><p>Note that if you have a list of numbers from 0 to 100, <code>LRANGE list 0 10</code> will\nreturn 11 elements, that is, the rightmost item is included.\nThis <strong>may or may not</strong> be consistent with behavior of range-related functions\nin your programming language of choice (think Ruby’s <code>Range.new</code>, <code>Array#slice</code>\nor Python’s <code>range()</code> function).</p>","link":"./alpha/commands/lrange.html","spaLink":"#/alpha/commands/lrange","title":"CONSISTENCY WITH RANGE FUNCTIONS IN VARIOUS PROGRAMMING LANGUAGES"},{"content":"<h2 id=\"-out-of-range-indexes\">Out-of-range indexes</h2><p>Out of range indexes will not produce an error.\nIf <code>start</code> is larger than the end of the list, an empty list is returned.\nIf <code>stop</code> is larger than the actual end of the list, Redis will treat it like\nthe last element of the list.</p><p>@return</p><p>@array-reply: list of elements in the specified range.</p><p>@examples</p>","link":"./alpha/commands/lrange.html","spaLink":"#/alpha/commands/lrange","title":"OUT-OF-RANGE INDEXES"},{"content":"<h2 id=\"-cost-of-running-monitor\">Cost of running <code>MONITOR</code></h2><p>Because <code>MONITOR</code> streams back <strong>all</strong> commands, its use comes at a cost.\nThe following (totally unscientific) benchmark numbers illustrate what the cost\nof running <code>MONITOR</code> can be.</p><p>Benchmark result <strong>without</strong> <code>MONITOR</code> running:</p><p>Benchmark result <strong>with</strong> <code>MONITOR</code> running (<code>redis-cli monitor &gt; /dev/null</code>):</p><p>In this particular case, running a single <code>MONITOR</code> client can reduce the\nthroughput by more than 50%.\nRunning more <code>MONITOR</code> clients will reduce throughput even more.</p><p>@return</p><p><strong>Non standard return value</strong>, just dumps the received commands in an infinite\nflow.</p>","link":"./alpha/commands/monitor.html","spaLink":"#/alpha/commands/monitor","title":"COST OF RUNNING MONITOR"},{"content":"<h2 id=\"-implementation-details\">Implementation details</h2><p>The command is always propagated in the replication link and the Append Only\nFile as a <code>SET</code> operation, so that differences in the underlying floating point\nmath implementation will not be sources of inconsistency.</p>","link":"./alpha/commands/incrbyfloat.html","spaLink":"#/alpha/commands/incrbyfloat","title":"IMPLEMENTATION DETAILS"},{"content":"<h2 id=\"-migrating-multiple-keys-with-a-single-command-call\">Migrating multiple keys with a single command call</h2><p>Starting with Redis 3.0.6 <code>MIGRATE</code> supports a new bulk-migration mode that\nuses pipelining in order to migrate multiple keys between instances without\nincurring in the round trip time latency and other overheads that there are\nwhen moving each key with a single <code>MIGRATE</code> call.</p><p>In order to enable this form, the <code>KEYS</code> option is used, and the normal <em>key</em>\nargument is set to an empty string. The actual key names will be provided\nafter the <code>KEYS</code> argument itself, like in the following example:</p><p>When this form is used the <code>NOKEY</code> status code is only returned when none\nof the keys is preset in the instance, otherwise the command is executed, even if\njust a single key exists.</p>","link":"./alpha/commands/migrate.html","spaLink":"#/alpha/commands/migrate","title":"MIGRATING MULTIPLE KEYS WITH A SINGLE COMMAND CALL"},{"content":"<h2 id=\"-options\">Options</h2><ul>\n<li><code>COPY</code> — Do not remove the key from the local instance.</li>\n<li><code>REPLACE</code> — Replace existing key on the remote instance.</li>\n<li><code>KEYS</code> — If the key argument is an empty string, the command will instead migrate all the keys that follow the <code>KEYS</code> option (see the above section for more info).</li>\n</ul><p><code>COPY</code> and <code>REPLACE</code> are available only in 3.0 and above.\n<code>KEYS</code> is available starting with Redis 3.0.6.</p><p>@return</p><p>@simple-string-reply: The command returns OK on success, or <code>NOKEY</code> if no keys were\nfound in the source instance.  </p>","link":"./alpha/commands/migrate.html","spaLink":"#/alpha/commands/migrate","title":"OPTIONS"},{"content":"<h2 id=\"-performances\">Performances</h2><p>When <code>PFCOUNT</code> is called with a single key, performances are excellent even if\nin theory constant times to process a dense HyperLogLog are high. This is\npossible because the <code>PFCOUNT</code> uses caching in order to remember the cardinality\npreviously computed, that rarely changes because most <code>PFADD</code> operations will\nnot update any register. Hundreds of operations per second are possible.</p><p>When <code>PFCOUNT</code> is called with multiple keys, an on-the-fly merge of the\nHyperLogLogs is performed, which is slow, moreover the cardinality of the union\ncan’t be cached, so when used with multiple keys <code>PFCOUNT</code> may take a time in\nthe order of magnitude of the millisecond, and should be not abused.</p><p>The user should take in mind that single-key and multiple-keys executions of\nthis command are semantically different and have different performances.</p>","link":"./alpha/commands/pfcount.html","spaLink":"#/alpha/commands/pfcount","title":"PERFORMANCES"},{"content":"<h2 id=\"-hyperloglog-representation\">HyperLogLog representation</h2><p>Redis HyperLogLogs are represented using a double representation: the <em>sparse</em> representation suitable for HLLs counting a small number of elements (resulting in a small number of registers set to non-zero value), and a <em>dense</em> representation suitable for higher cardinalities. Redis automatically switches from the sparse to the dense representation when needed.</p><p>The sparse representation uses a run-length encoding optimized to store efficiently a big number of registers set to zero. The dense representation is a Redis string of 12288 bytes in order to store 16384 6-bit counters. The need for the double representation comes from the fact that using 12k (which is the dense representation memory requirement) to encode just a few registers for smaller cardinalities is extremely suboptimal.</p><p>Both representations are prefixed with a 16 bytes header, that includes a magic, an encoding / version field, and the cached cardinality estimation computed, stored in little endian format (the most significant bit is 1 if the estimation is invalid since the HyperLogLog was updated since the cardinality was computed).</p><p>The HyperLogLog, being a Redis string, can be retrieved with <code>GET</code> and restored with <code>SET</code>. Calling <code>PFADD</code>, <code>PFCOUNT</code> or <code>PFMERGE</code> commands with a corrupted HyperLogLog is never a problem, it may return random values but does not affect the stability of the server. Most of the times when corrupting a sparse representation, the server recognizes the corruption and returns an error.</p><p>The representation is neutral from the point of view of the processor word size and endianness, so the same representation is used by 32 bit and 64 bit processor, big endian or little endian.</p><p>More details about the Redis HyperLogLog implementation can be found in <a href=\"http://antirez.com/news/75\">this blog post</a>. The source code of the implementation in the <code>hyperloglog.c</code> file is also easy to read and understand, and includes a full specification for the exact encoding used for the sparse and dense representations.</p>","link":"./alpha/commands/pfcount.html","spaLink":"#/alpha/commands/pfcount","title":"HYPERLOGLOG REPRESENTATION"},{"content":"<h2 id=\"-notes\">Notes</h2><p>Please note depending on the version of Redis some of the fields have been\nadded or removed. A robust client application should therefore parse the\nresult of this command by skipping unknown properties, and gracefully handle\nmissing fields.</p><p>Here is the description of fields for Redis &gt;= 2.4.</p><p>Here is the meaning of all fields in the <strong>server</strong> section:</p><ul>\n<li><code>redis_version</code>: Version of the Redis server</li>\n<li><code>redis_git_sha1</code>:  Git SHA1</li>\n<li><code>redis_git_dirty</code>: Git dirty flag</li>\n<li><code>os</code>: Operating system hosting the Redis server</li>\n<li><code>arch_bits</code>: Architecture (32 or 64 bits)</li>\n<li><code>multiplexing_api</code>: event loop mechanism used by Redis</li>\n<li><code>gcc_version</code>: Version of the GCC compiler used to compile the Redis server</li>\n<li><code>process_id</code>: PID of the server process</li>\n<li><code>run_id</code>: Random value identifying the Redis server (to be used by Sentinel and Cluster)</li>\n<li><code>tcp_port</code>: TCP/IP listen port</li>\n<li><code>uptime_in_seconds</code>: Number of seconds since Redis server start</li>\n<li><code>uptime_in_days</code>: Same value expressed in days</li>\n<li><code>lru_clock</code>: Clock incrementing every minute, for LRU management</li>\n</ul><p>Here is the meaning of all fields in the <strong>clients</strong> section:</p><ul>\n<li><code>connected_clients</code>: Number of client connections (excluding connections from slaves)</li>\n<li><code>client_longest_output_list</code>: longest output list among current client connections</li>\n<li><code>client_biggest_input_buf</code>: biggest input buffer among current client connections</li>\n<li><code>blocked_clients</code>: Number of clients pending on a blocking call (BLPOP, BRPOP, BRPOPLPUSH)</li>\n</ul><p>Here is the meaning of all fields in the <strong>memory</strong> section:</p><ul>\n<li><code>used_memory</code>:  total number of bytes allocated by Redis using its\n allocator (either standard <strong>libc</strong>, <strong>jemalloc</strong>, or an alternative allocator such\n as <a href=\"http://code.google.com/p/google-perftools/\"><strong>tcmalloc</strong></a></li>\n<li><code>used_memory_human</code>: Human readable representation of previous value</li>\n<li><code>used_memory_rss</code>: Number of bytes that Redis allocated as seen by the\n operating system (a.k.a resident set size). This is the number reported by tools\n such as <code>top(1)</code> and <code>ps(1)</code></li>\n<li><code>used_memory_peak</code>: Peak memory consumed by Redis (in bytes)</li>\n<li><code>used_memory_peak_human</code>: Human readable representation of previous value</li>\n<li><code>used_memory_lua</code>: Number of bytes used by the Lua engine</li>\n<li><code>mem_fragmentation_ratio</code>: Ratio between <code>used_memory_rss</code> and <code>used_memory</code></li>\n<li><code>mem_allocator</code>: Memory allocator, chosen at compile time</li>\n</ul><p>Ideally, the <code>used_memory_rss</code> value should be only slightly higher than <code>used_memory</code>.\nWhen rss &gt;&gt; used, a large difference means there is memory fragmentation\n(internal or external), which can be evaluated by checking <code>mem_fragmentation_ratio</code>.\nWhen used &gt;&gt; rss, it means part of Redis memory has been swapped off by the operating\nsystem: expect some significant latencies.</p><p>Because Redis does not have control over how its allocations are mapped to\nmemory pages, high <code>used_memory_rss</code> is often the result of a spike in memory\nusage.</p><p>When Redis frees memory, the memory is given back to the allocator, and the\nallocator may or may not give the memory back to the system. There may be\na discrepancy between the <code>used_memory</code> value and memory consumption as\nreported by the operating system. It may be due to the fact memory has been\nused and released by Redis, but not given back to the system. The <code>used_memory_peak</code>\nvalue is generally useful to check this point.</p><p>Here is the meaning of all fields in the <strong>persistence</strong> section:</p><ul>\n<li><code>loading</code>: Flag indicating if the load of a dump file is on-going</li>\n<li><code>rdb_changes_since_last_save</code>: Number of changes since the last dump</li>\n<li><code>rdb_bgsave_in_progress</code>: Flag indicating a RDB save is on-going</li>\n<li><code>rdb_last_save_time</code>: Epoch-based timestamp of last successful RDB save</li>\n<li><code>rdb_last_bgsave_status</code>: Status of the last RDB save operation</li>\n<li><code>rdb_last_bgsave_time_sec</code>: Duration of the last RDB save operation in seconds</li>\n<li><code>rdb_current_bgsave_time_sec</code>: Duration of the on-going RDB save operation if any</li>\n<li><code>aof_enabled</code>: Flag indicating AOF logging is activated</li>\n<li><code>aof_rewrite_in_progress</code>: Flag indicating a AOF rewrite operation is on-going</li>\n<li><code>aof_rewrite_scheduled</code>: Flag indicating an AOF rewrite operation\n will be scheduled once the on-going RDB save is complete.</li>\n<li><code>aof_last_rewrite_time_sec</code>: Duration of the last AOF rewrite operation in seconds</li>\n<li><code>aof_current_rewrite_time_sec</code>: Duration of the on-going AOF rewrite operation if any</li>\n<li><code>aof_last_bgrewrite_status</code>: Status of the last AOF rewrite operation</li>\n</ul><p><code>changes_since_last_save</code> refers to the number of operations that produced\nsome kind of changes in the dataset since the last time either <code>SAVE</code> or\n<code>BGSAVE</code> was called.</p><p>If AOF is activated, these additional fields will be added:</p><ul>\n<li><code>aof_current_size</code>: AOF current file size</li>\n<li><code>aof_base_size</code>: AOF file size on latest startup or rewrite</li>\n<li><code>aof_pending_rewrite</code>: Flag indicating an AOF rewrite operation\n will be scheduled once the on-going RDB save is complete.</li>\n<li><code>aof_buffer_length</code>: Size of the AOF buffer</li>\n<li><code>aof_rewrite_buffer_length</code>: Size of the AOF rewrite buffer</li>\n<li><code>aof_pending_bio_fsync</code>: Number of fsync pending jobs in background I/O queue</li>\n<li><code>aof_delayed_fsync</code>: Delayed fsync counter</li>\n</ul><p>If a load operation is on-going, these additional fields will be added:</p><ul>\n<li><code>loading_start_time</code>: Epoch-based timestamp of the start of the load operation</li>\n<li><code>loading_total_bytes</code>: Total file size</li>\n<li><code>loading_loaded_bytes</code>: Number of bytes already loaded</li>\n<li><code>loading_loaded_perc</code>: Same value expressed as a percentage</li>\n<li><code>loading_eta_seconds</code>: ETA in seconds for the load to be complete</li>\n</ul><p>Here is the meaning of all fields in the <strong>stats</strong> section:</p><ul>\n<li><code>total_connections_received</code>: Total number of connections accepted by the server</li>\n<li><code>total_commands_processed</code>: Total number of commands processed by the server</li>\n<li><code>instantaneous_ops_per_sec</code>: Number of commands processed per second</li>\n<li><code>rejected_connections</code>: Number of connections rejected because of <code>maxclients</code> limit</li>\n<li><code>expired_keys</code>: Total number of key expiration events</li>\n<li><code>evicted_keys</code>: Number of evicted keys due to <code>maxmemory</code> limit</li>\n<li><code>keyspace_hits</code>: Number of successful lookup of keys in the main dictionary</li>\n<li><code>keyspace_misses</code>: Number of failed lookup of keys in the main dictionary</li>\n<li><code>pubsub_channels</code>: Global number of pub/sub channels with client subscriptions</li>\n<li><code>pubsub_patterns</code>: Global number of pub/sub pattern with client subscriptions</li>\n<li><code>latest_fork_usec</code>: Duration of the latest fork operation in microseconds</li>\n</ul><p>Here is the meaning of all fields in the <strong>replication</strong> section:</p><ul>\n<li><code>role</code>: Value is “master” if the instance is slave of no one, or “slave” if the instance is enslaved to a master.\nNote that a slave can be master of another slave (daisy chaining).</li>\n</ul><p>If the instance is a slave, these additional fields are provided:</p><ul>\n<li><code>master_host</code>: Host or IP address of the master</li>\n<li><code>master_port</code>: Master listening TCP port</li>\n<li><code>master_link_status</code>: Status of the link (up/down)</li>\n<li><code>master_last_io_seconds_ago</code>: Number of seconds since the last interaction with master</li>\n<li><code>master_sync_in_progress</code>: Indicate the master is syncing to the slave</li>\n</ul><p>If a SYNC operation is on-going, these additional fields are provided:</p><ul>\n<li><code>master_sync_left_bytes</code>: Number of bytes left before syncing is complete</li>\n<li><code>master_sync_last_io_seconds_ago</code>: Number of seconds since last transfer I/O during a SYNC operation</li>\n</ul><p>If the link between master and slave is down, an additional field is provided:</p><ul>\n<li><code>master_link_down_since_seconds</code>: Number of seconds since the link is down</li>\n</ul><p>The following field is always provided:</p><ul>\n<li><code>connected_slaves</code>: Number of connected slaves</li>\n</ul><p>For each slave, the following line is added:</p><ul>\n<li><code>slaveXXX</code>: id, IP address, port, state</li>\n</ul><p>Here is the meaning of all fields in the <strong>cpu</strong> section:</p><ul>\n<li><code>used_cpu_sys</code>: System CPU consumed by the Redis server</li>\n<li><code>used_cpu_user</code>:User CPU consumed by the Redis server</li>\n<li><code>used_cpu_sys_children</code>: System CPU consumed by the background processes</li>\n<li><code>used_cpu_user_children</code>: User CPU consumed by the background processes</li>\n</ul><p>The <strong>commandstats</strong> section provides statistics based on the command type,\nincluding the number of calls, the total CPU time consumed by these commands,\nand the average CPU consumed per command execution.</p><p>For each command type, the following line is added:</p><ul>\n<li><code>cmdstat_XXX</code>: <code>calls=XXX,usec=XXX,usec_per_call=XXX</code></li>\n</ul><p>The <strong>cluster</strong> section currently only contains a unique field:</p><ul>\n<li><code>cluster_enabled</code>: Indicate Redis cluster is enabled</li>\n</ul><p>The <strong>keyspace</strong> section provides statistics on the main dictionary of each database.\nThe statistics are the number of keys, and the number of keys with an expiration.</p><p>For each database, the following line is added:</p><ul>\n<li><code>dbXXX</code>: <code>keys=XXX,expires=XXX</code></li>\n</ul>","link":"./alpha/commands/info.html","spaLink":"#/alpha/commands/info","title":"NOTES"},{"content":"<h2 id=\"-redis-slow-log-overview\">Redis slow log overview</h2><p>The Redis Slow Log is a system to log queries that exceeded a specified\nexecution time.\nThe execution time does not include I/O operations like talking with the client,\nsending the reply and so forth, but just the time needed to actually execute the\ncommand (this is the only stage of command execution where the thread is blocked\nand can not serve other requests in the meantime).</p><p>You can configure the slow log with two parameters: <em>slowlog-log-slower-than</em>\ntells Redis what is the execution time, in microseconds, to exceed in order for\nthe command to get logged.\nNote that a negative number disables the slow log, while a value of zero forces\nthe logging of every command.\n<em>slowlog-max-len</em> is the length of the slow log.\nThe minimum value is zero.\nWhen a new command is logged and the slow log is already at its maximum length,\nthe oldest one is removed from the queue of logged commands in order to make\nspace.</p><p>The configuration can be done by editing <code>redis.conf</code> or while the server is\nrunning using the <code>CONFIG GET</code> and <code>CONFIG SET</code> commands.</p>","link":"./alpha/commands/slowlog.html","spaLink":"#/alpha/commands/slowlog","title":"REDIS SLOW LOG OVERVIEW"},{"content":"<h2 id=\"-reading-the-slow-log\">Reading the slow log</h2><p>The slow log is accumulated in memory, so no file is written with information\nabout the slow command executions.\nThis makes the slow log remarkably fast at the point that you can enable the\nlogging of all the commands (setting the <em>slowlog-log-slower-than</em> config\nparameter to zero) with minor performance hit.</p><p>To read the slow log the <strong>SLOWLOG GET</strong> command is used, that returns every\nentry in the slow log.\nIt is possible to return only the N most recent entries passing an additional\nargument to the command (for instance <strong>SLOWLOG GET 10</strong>).</p><p>Note that you need a recent version of redis-cli in order to read the slow log\noutput, since it uses some features of the protocol that were not formerly\nimplemented in redis-cli (deeply nested multi bulk replies).</p>","link":"./alpha/commands/slowlog.html","spaLink":"#/alpha/commands/slowlog","title":"READING THE SLOW LOG"},{"content":"<h2 id=\"-output-format\">Output format</h2><p>Every entry is composed of four fields:</p><ul>\n<li>A unique progressive identifier for every slow log entry.</li>\n<li>The unix timestamp at which the logged command was processed.</li>\n<li>The amount of time needed for its execution, in microseconds.</li>\n<li>The array composing the arguments of the command.</li>\n</ul><p>The entry’s unique ID can be used in order to avoid processing slow log entries\nmultiple times (for instance you may have a script sending you an email alert\nfor every new slow log entry).</p><p>The ID is never reset in the course of the Redis server execution, only a server\nrestart will reset it.</p>","link":"./alpha/commands/slowlog.html","spaLink":"#/alpha/commands/slowlog","title":"OUTPUT FORMAT"},{"content":"<h2 id=\"-obtaining-the-current-length-of-the-slow-log\">Obtaining the current length of the slow log</h2><p>It is possible to get just the length of the slow log using the command\n<strong>SLOWLOG LEN</strong>.</p>","link":"./alpha/commands/slowlog.html","spaLink":"#/alpha/commands/slowlog","title":"OBTAINING THE CURRENT LENGTH OF THE SLOW LOG"},{"content":"<h2 id=\"-resetting-the-slow-log\">Resetting the slow log.</h2><p>You can reset the slow log using the <strong>SLOWLOG RESET</strong> command.\nOnce deleted the information is lost forever.</p>","link":"./alpha/commands/slowlog.html","spaLink":"#/alpha/commands/slowlog","title":"RESETTING THE SLOW LOG."},{"content":"<h1 id=\"pubsub-channels-pattern\">PUBSUB CHANNELS [pattern]</h1><p>Lists the currently <em>active channels</em>. An active channel is a Pub/Sub channel\nwith one or more subscribers (not including clients subscribed to patterns).</p><p>If no <code>pattern</code> is specified, all the channels are listed, otherwise if pattern\nis specified only channels matching the specified glob-style pattern are\nlisted.</p><p>@return</p><p>@array-reply: a list of active channels, optionally matching the specified pattern.</p>","link":"./alpha/commands/pubsub.html","spaLink":"#/alpha/commands/pubsub","title":"PUBSUB CHANNELS [PATTERN]"},{"content":"<h1 id=\"pubsub-numsub-channel-1-channel-n\"><code>PUBSUB NUMSUB [channel-1 ... channel-N]</code></h1><p>Returns the number of subscribers (not counting clients subscribed to patterns)\nfor the specified channels.</p><p>@return</p><p>@array-reply: a list of channels and number of subscribers for every channel. The format is channel, count, channel, count, …, so the list is flat.\nThe order in which the channels are listed is the same as the order of the\nchannels specified in the command call.</p><p>Note that it is valid to call this command without channels. In this case it\nwill just return an empty list.</p>","link":"./alpha/commands/pubsub.html","spaLink":"#/alpha/commands/pubsub","title":"PUBSUB NUMSUB [CHANNEL-1 ... CHANNEL-N]"},{"content":"<h1 id=\"pubsub-numpat\"><code>PUBSUB NUMPAT</code></h1><p>Returns the number of subscriptions to patterns (that are performed using the\n<code>PSUBSCRIBE</code> command). Note that this is not just the count of clients subscribed\nto patterns but the total number of patterns all the clients are subscribed to.</p><p>@return</p><p>@integer-reply: the number of patterns all the clients are subscribed to.</p>","link":"./alpha/commands/pubsub.html","spaLink":"#/alpha/commands/pubsub","title":"PUBSUB NUMPAT"},{"content":"<h2 id=\"-pattern-reliable-queue\">Pattern: Reliable queue</h2><p>Redis is often used as a messaging server to implement processing of background\njobs or other kinds of messaging tasks.\nA simple form of queue is often obtained pushing values into a list in the\nproducer side, and waiting for this values in the consumer side using <code>RPOP</code>\n(using polling), or <code>BRPOP</code> if the client is better served by a blocking\noperation.</p><p>However in this context the obtained queue is not <em>reliable</em> as messages can\nbe lost, for example in the case there is a network problem or if the consumer\ncrashes just after the message is received but it is still to process.</p><p><code>RPOPLPUSH</code> (or <code>BRPOPLPUSH</code> for the blocking variant) offers a way to avoid\nthis problem: the consumer fetches the message and at the same time pushes it\ninto a <em>processing</em> list.\nIt will use the <code>LREM</code> command in order to remove the message from the\n<em>processing</em> list once the message has been processed.</p><p>An additional client may monitor the <em>processing</em> list for items that remain\nthere for too much time, and will push those timed out items into the queue\nagain if needed.</p>","link":"./alpha/commands/rpoplpush.html","spaLink":"#/alpha/commands/rpoplpush","title":"PATTERN: RELIABLE QUEUE"},{"content":"<h2 id=\"-pattern-circular-list\">Pattern: Circular list</h2><p>Using <code>RPOPLPUSH</code> with the same source and destination key, a client can visit\nall the elements of an N-elements list, one after the other, in O(N) without\ntransferring the full list from the server to the client using a single <code>LRANGE</code>\noperation.</p><p>The above pattern works even if the following two conditions: <em> There are\nmultiple clients rotating the list: they’ll fetch different elements, until all\nthe elements of the list are visited, and the process restarts.\n</em> Even if other clients are actively pushing new items at the end of the list.</p><p>The above makes it very simple to implement a system where a set of items must\nbe processed by N workers continuously as fast as possible.\nAn example is a monitoring system that must check that a set of web sites are\nreachable, with the smallest delay possible, using a number of parallel workers.</p><p>Note that this implementation of workers is trivially scalable and reliable,\nbecause even if a message is lost the item is still in the queue and will be\nprocessed at the next iteration.</p>","link":"./alpha/commands/rpoplpush.html","spaLink":"#/alpha/commands/rpoplpush","title":"PATTERN: CIRCULAR LIST"},{"content":"<h2 id=\"-patterns\">Patterns</h2><p>Thanks to <code>SETRANGE</code> and the analogous <code>GETRANGE</code> commands, you can use Redis\nstrings as a linear array with O(1) random access.\nThis is a very fast and efficient storage in many real world use cases.</p><p>@return</p><p>@integer-reply: the length of the string after it was modified by the command.</p><p>@examples</p><p>Basic usage:</p><p>Example of zero padding:</p>","link":"./alpha/commands/setrange.html","spaLink":"#/alpha/commands/setrange","title":"PATTERNS"},{"content":"<h2 id=\"-save-and-nosave-modifiers\">SAVE and NOSAVE modifiers</h2><p>It is possible to specify an optional modifier to alter the behavior of the\ncommand.\nSpecifically:</p><ul>\n<li><strong>SHUTDOWN SAVE</strong> will force a DB saving operation even if no save points are\nconfigured.</li>\n<li><strong>SHUTDOWN NOSAVE</strong> will prevent a DB saving operation even if one or more\nsave points are configured.\n(You can think at this variant as an hypothetical <strong>ABORT</strong> command that just\nstops the server).</li>\n</ul><p>@return</p><p>@simple-string-reply on error.\nOn success nothing is returned since the server quits and the connection is\nclosed.</p>","link":"./alpha/commands/shutdown.html","spaLink":"#/alpha/commands/shutdown","title":"SAVE AND NOSAVE MODIFIERS"},{"content":"<h2 id=\"-output-format\">Output format</h2><p>The command returns an array of elements. The first element is the role of\nthe instance, as one of the following three strings:</p><ul>\n<li>“master”</li>\n<li>“slave”</li>\n<li>“sentinel”</li>\n</ul><p>The additional elements of the array depends on the role.</p>","link":"./alpha/commands/role.html","spaLink":"#/alpha/commands/role","title":"OUTPUT FORMAT"},{"content":"<h2 id=\"-master-output\">Master output</h2><p>An example of output when <code>ROLE</code> is called in a master instance:</p><p>The master output is composed of the following parts:</p>","link":"./alpha/commands/role.html","spaLink":"#/alpha/commands/role","title":"MASTER OUTPUT"},{"content":"<h2 id=\"-slave-output\">Slave output</h2><p>An example of output when <code>ROLE</code> is called in a slave instance:</p><p>The slave output is composed of the following parts:</p>","link":"./alpha/commands/role.html","spaLink":"#/alpha/commands/role","title":"SLAVE OUTPUT"},{"content":"<h2 id=\"-sentinel-output\">Sentinel output</h2><p>An example of Sentinel output:</p><p>The sentinel output is composed of the following parts:</p><p>@return</p><p>@array-reply: where the first element is one of <code>master</code>, <code>slave</code>, <code>sentinel</code> and the additional elements are role-specific as illustrated above.</p><p>@history</p><ul>\n<li>This command was introduced in the middle of a Redis stable release, specifically with Redis 2.8.12.</li>\n</ul><p>@examples</p>","link":"./alpha/commands/role.html","spaLink":"#/alpha/commands/role","title":"SENTINEL OUTPUT"},{"content":"<h2 id=\"-options\">Options</h2><p>Starting with Redis 2.6.12 <code>SET</code> supports a set of options that modify its\nbehavior:</p><ul>\n<li><code>EX</code> <em>seconds</em> — Set the specified expire time, in seconds.</li>\n<li><code>PX</code> <em>milliseconds</em> — Set the specified expire time, in milliseconds.</li>\n<li><code>NX</code> — Only set the key if it does not already exist.</li>\n<li><code>XX</code> — Only set the key if it already exist.</li>\n</ul><p>Note: Since the <code>SET</code> command options can replace <code>SETNX</code>, <code>SETEX</code>, <code>PSETEX</code>, it is possible that in future versions of Redis these three commands will be deprecated and finally removed.</p><p>@return</p><p>@simple-string-reply: <code>OK</code> if <code>SET</code> was executed correctly.\n@nil-reply: a Null Bulk Reply is returned if the <code>SET</code> operation was not performed because the user specified the <code>NX</code> or <code>XX</code> option but the condition was not met.</p><p>@examples</p>","link":"./alpha/commands/set.html","spaLink":"#/alpha/commands/set","title":"OPTIONS"},{"content":"<h2 id=\"-patterns\">Patterns</h2><p><strong>Note:</strong> The following pattern is discouraged in favor of <a href=\"http://redis.io/topics/distlock\">the Redlock algorithm</a> which is only a bit more complex to implement, but offers better guarantees and is fault tolerant.</p><p>The command <code>SET resource-name anystring NX EX max-lock-time</code> is a simple way to implement a locking system with Redis.</p><p>A client can acquire the lock if the above command returns <code>OK</code> (or retry after some time if the command returns Nil), and remove the lock just using <code>DEL</code>.</p><p>The lock will be auto-released after the expire time is reached.</p><p>It is possible to make this system more robust modifying the unlock schema as follows:</p><ul>\n<li>Instead of setting a fixed string, set a non-guessable large random string, called token.</li>\n<li>Instead of releasing the lock with <code>DEL</code>, send a script that only removes the key if the value matches.</li>\n</ul><p>This avoids that a client will try to release the lock after the expire time deleting the key created by another client that acquired the lock later.</p><p>An example of unlock script would be similar to the following:</p><p>The script should be called with <code>EVAL ...script... 1 resource-name token-value</code></p>","link":"./alpha/commands/set.html","spaLink":"#/alpha/commands/set","title":"PATTERNS"},{"content":"<h2 id=\"-scan-basic-usage\">SCAN basic usage</h2><p>SCAN is a cursor based iterator. This means that at every call of the command, the server returns an updated cursor that the user needs to use as the cursor argument in the next call.</p><p>An iteration starts when the cursor is set to 0, and terminates when the cursor returned by the server is 0. The following is an example of SCAN iteration:</p><p>In the example above, the first call uses zero as a cursor, to start the iteration. The second call uses the cursor returned by the previous call as the first element of the reply, that is, 17.</p><p>As you can see the <strong>SCAN return value</strong> is an array of two values: the first value is the new cursor to use in the next call, the second value is an array of elements.</p><p>Since in the second call the returned cursor is 0, the server signaled to the caller that the iteration finished, and the collection was completely explored. Starting an iteration with a cursor value of 0, and calling <code>SCAN</code> until the returned cursor is 0 again is called a <strong>full iteration</strong>.</p>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"SCAN BASIC USAGE"},{"content":"<h2 id=\"-scan-guarantees\">Scan guarantees</h2><p>The <code>SCAN</code> command, and the other commands in the <code>SCAN</code> family, are able to provide to the user a set of guarantees associated to full iterations.</p><ul>\n<li>A full iteration always retrieves all the elements that were present in the collection from the start to the end of a full iteration. This means that if a given element is inside the collection when an iteration is started, and is still there when an iteration terminates, then at some point <code>SCAN</code> returned it to the user.</li>\n<li>A full iteration never returns any element that was NOT present in the collection from the start to the end of a full iteration. So if an element was removed before the start of an iteration, and is never added back to the collection for all the time an iteration lasts, <code>SCAN</code> ensures that this element will never be returned.</li>\n</ul><p>However because <code>SCAN</code> has very little state associated (just the cursor) it has the following drawbacks:</p><ul>\n<li>A given element may be returned multiple times. It is up to the application to handle the case of duplicated elements, for example only using the returned elements in order to perform operations that are safe when re-applied multiple times.</li>\n<li>Elements that were not constantly present in the collection during a full iteration, may be returned or not: it is undefined.</li>\n</ul>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"SCAN GUARANTEES"},{"content":"<h2 id=\"-number-of-elements-returned-at-every-scan-call\">Number of elements returned at every SCAN call</h2><p><code>SCAN</code> family functions do not guarantee that the number of elements returned per call are in a given range. The commands are also allowed to return zero elements, and the client should not consider the iteration complete as long as the returned cursor is not zero.</p><p>However the number of returned elements is reasonable, that is, in practical terms SCAN may return a maximum number of elements in the order of a few tens of elements when iterating a large collection, or may return all the elements of the collection in a single call when the iterated collection is small enough to be internally represented as an encoded data structure (this happens for small sets, hashes and sorted sets).</p><p>However there is a way for the user to tune the order of magnitude of the number of returned elements per call using the <strong>COUNT</strong> option.</p>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"NUMBER OF ELEMENTS RETURNED AT EVERY SCAN CALL"},{"content":"<h2 id=\"-the-count-option\">The COUNT option</h2><p>While <code>SCAN</code> does not provide guarantees about the number of elements returned at every iteration, it is possible to empirically adjust the behavior of <code>SCAN</code> using the <strong>COUNT</strong> option. Basically with COUNT the user specified the <em>amount of work that should be done at every call in order to retrieve elements from the collection</em>. This is <strong>just an hint</strong> for the implementation, however generally speaking this is what you could expect most of the times from the implementation.</p><ul>\n<li>The default COUNT value is 10.</li>\n<li>When iterating the key space, or a Set, Hash or Sorted Set that is big enough to be represented by a hash table, assuming no <strong>MATCH</strong> option is used, the server will usually return <em>count</em> or a bit more than <em>count</em> elements per call.</li>\n<li>When iterating Sets encoded as intsets (small sets composed of just integers), or Hashes and Sorted Sets encoded as ziplists (small hashes and sets composed of small individual values), usually all the elements are returned in the first <code>SCAN</code> call regardless of the COUNT value.</li>\n</ul><p>Important: <strong>there is no need to use the same COUNT value</strong> for every iteration. The caller is free to change the count from one iteration to the other as required, as long as the cursor passed in the next call is the one obtained in the previous call to the command.</p>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"THE COUNT OPTION"},{"content":"<h2 id=\"-the-match-option\">The MATCH option</h2><p>It is possible to only iterate elements matching a given glob-style pattern, similarly to the behavior of the <code>KEYS</code> command that takes a pattern as only argument.</p><p>To do so, just append the <code>MATCH &lt;pattern&gt;</code> arguments at the end of the <code>SCAN</code> command (it works with all the SCAN family commands).</p><p>This is an example of iteration using <strong>MATCH</strong>:</p><p>It is important to note that the <strong>MATCH</strong> filter is applied after elements are retrieved from the collection, just before returning data to the client. This means that if the pattern matches very little elements inside the collection, <code>SCAN</code> will likely return no elements in most iterations. An example is shown below:</p><p>As you can see most of the calls returned zero elements, but the last call where a COUNT of 1000 was used in order to force the command to do more scanning for that iteration.</p>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"THE MATCH OPTION"},{"content":"<h2 id=\"-multiple-parallel-iterations\">Multiple parallel iterations</h2><p>It is possible for an infinite number of clients to iterate the same collection at the same time, as the full state of the iterator is in the cursor, that is obtained and returned to the client at every call. Server side no state is taken at all.</p>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"MULTIPLE PARALLEL ITERATIONS"},{"content":"<h2 id=\"-terminating-iterations-in-the-middle\">Terminating iterations in the middle</h2><p>Since there is no state server side, but the full state is captured by the cursor, the caller is free to terminate an iteration half-way without signaling this to the server in any way. An infinite number of iterations can be started and never terminated without any issue.</p>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"TERMINATING ITERATIONS IN THE MIDDLE"},{"content":"<h2 id=\"-calling-scan-with-a-corrupted-cursor\">Calling SCAN with a corrupted cursor</h2><p>Calling <code>SCAN</code> with a broken, negative, out of range, or otherwise invalid cursor, will result into undefined behavior but never into a crash. What will be undefined is that the guarantees about the returned elements can no longer be ensured by the <code>SCAN</code> implementation.</p><p>The only valid cursors to use are:</p><ul>\n<li>The cursor value of 0 when starting an iteration.</li>\n<li>The cursor returned by the previous call to SCAN in order to continue the iteration.</li>\n</ul>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"CALLING SCAN WITH A CORRUPTED CURSOR"},{"content":"<h2 id=\"-guarantee-of-termination\">Guarantee of termination</h2><p>The <code>SCAN</code> algorithm is guaranteed to terminate only if the size of the iterated collection remains bounded to a given maximum size, otherwise iterating a collection that always grows may result into <code>SCAN</code> to never terminate a full iteration.</p><p>This is easy to see intuitively: if the collection grows there is more and more work to do in order to visit all the possible elements, and the ability to terminate the iteration depends on the number of calls to <code>SCAN</code> and its COUNT option value compared with the rate at which the collection grows.</p>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"GUARANTEE OF TERMINATION"},{"content":"<h2 id=\"-return-value\">Return value</h2><p><code>SCAN</code>, <code>SSCAN</code>, <code>HSCAN</code> and <code>ZSCAN</code> return a two elements multi-bulk reply, where the first element is a string representing an unsigned 64 bit number (the cursor), and the second element is a multi-bulk with an array of elements.</p><ul>\n<li><code>SCAN</code> array of elements is a list of keys.</li>\n<li><code>SSCAN</code> array of elements is a list of Set members.</li>\n<li><code>HSCAN</code> array of elements contain two elements, a field and a value, for every returned element of the Hash.</li>\n<li><code>ZSCAN</code> array of elements contain two elements, a member and its associated score, for every returned element of the sorted set.</li>\n</ul>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"RETURN VALUE"},{"content":"<h2 id=\"-additional-examples\">Additional examples</h2><p>Iteration of a Hash value.</p>","link":"./alpha/commands/scan.html","spaLink":"#/alpha/commands/scan","title":"ADDITIONAL EXAMPLES"},{"content":"<h2 id=\"-design-pattern-locking-with-setnx\">Design pattern: Locking with <code>!SETNX</code></h2><p><strong>Please note that:</strong></p><p>That said, <code>SETNX</code> can be used, and was historically used, as a locking primitive. For example, to acquire the lock of the key <code>foo</code>, the client could try the\nfollowing:</p><p>If <code>SETNX</code> returns <code>1</code> the client acquired the lock, setting the <code>lock.foo</code> key\nto the Unix time at which the lock should no longer be considered valid.\nThe client will later use <code>DEL lock.foo</code> in order to release the lock.</p><p>If <code>SETNX</code> returns <code>0</code> the key is already locked by some other client.\nWe can either return to the caller if it’s a non blocking lock, or enter a loop\nretrying to hold the lock until we succeed or some kind of timeout expires.</p>","link":"./alpha/commands/setnx.html","spaLink":"#/alpha/commands/setnx","title":"DESIGN PATTERN: LOCKING WITH !SETNX"},{"content":"<h3 id=\"-design-pattern-locking-with-setnx-handling-deadlocks\">Handling deadlocks</h3><p>In the above locking algorithm there is a problem: what happens if a client\nfails, crashes, or is otherwise not able to release the lock?\nIt’s possible to detect this condition because the lock key contains a UNIX\ntimestamp.\nIf such a timestamp is equal to the current Unix time the lock is no longer\nvalid.</p><p>When this happens we can’t just call <code>DEL</code> against the key to remove the lock\nand then try to issue a <code>SETNX</code>, as there is a race condition here, when\nmultiple clients detected an expired lock and are trying to release it.</p><ul>\n<li>C1 and C2 read <code>lock.foo</code> to check the timestamp, because they both received\n<code>0</code> after executing <code>SETNX</code>, as the lock is still held by C3 that crashed\nafter holding the lock.</li>\n<li>C1 sends <code>DEL lock.foo</code></li>\n<li>C1 sends <code>SETNX lock.foo</code> and it succeeds</li>\n<li>C2 sends <code>DEL lock.foo</code></li>\n<li>C2 sends <code>SETNX lock.foo</code> and it succeeds</li>\n<li><strong>ERROR</strong>: both C1 and C2 acquired the lock because of the race condition.</li>\n</ul><p>Fortunately, it’s possible to avoid this issue using the following algorithm.\nLet’s see how C4, our sane client, uses the good algorithm:</p><ul>\n<li><p>C4 sends <code>SETNX lock.foo</code> in order to acquire the lock</p>\n</li>\n<li><p>The crashed client C3 still holds it, so Redis will reply with <code>0</code> to C4.</p>\n</li>\n<li><p>C4 sends <code>GET lock.foo</code> to check if the lock expired.\nIf it is not, it will sleep for some time and retry from the start.</p>\n</li>\n<li><p>Instead, if the lock is expired because the Unix time at <code>lock.foo</code> is older\nthan the current Unix time, C4 tries to perform:</p>\n<pre><code class=\"prettyprint prettyprinted\" style=\"\"><span class=\"pln\">GETSET </span><span class=\"kwd\">lock</span><span class=\"pun\">.</span><span class=\"pln\">foo </span><span class=\"pun\">&lt;</span><span class=\"pln\">current </span><span class=\"typ\">Unix</span><span class=\"pln\"> timestamp </span><span class=\"pun\">+</span><span class=\"pln\"> </span><span class=\"kwd\">lock</span><span class=\"pln\"> timeout </span><span class=\"pun\">+</span><span class=\"pln\"> </span><span class=\"lit\">1</span><span class=\"pun\">&gt;</span></code></pre>\n</li>\n<li><p>Because of the <code>GETSET</code> semantic, C4 can check if the old value stored at\n<code>key</code> is still an expired timestamp.\nIf it is, the lock was acquired.</p>\n</li>\n<li><p>If another client, for instance C5, was faster than C4 and acquired the lock\nwith the <code>GETSET</code> operation, the C4 <code>GETSET</code> operation will return a non\nexpired timestamp.\nC4 will simply restart from the first step.\nNote that even if C4 set the key a bit a few seconds in the future this is\nnot a problem.</p>\n</li>\n</ul><p>C4 sends <code>SETNX lock.foo</code> in order to acquire the lock</p><p>The crashed client C3 still holds it, so Redis will reply with <code>0</code> to C4.</p><p>C4 sends <code>GET lock.foo</code> to check if the lock expired.\nIf it is not, it will sleep for some time and retry from the start.</p><p>Instead, if the lock is expired because the Unix time at <code>lock.foo</code> is older\nthan the current Unix time, C4 tries to perform:</p><p>Because of the <code>GETSET</code> semantic, C4 can check if the old value stored at\n<code>key</code> is still an expired timestamp.\nIf it is, the lock was acquired.</p><p>If another client, for instance C5, was faster than C4 and acquired the lock\nwith the <code>GETSET</code> operation, the C4 <code>GETSET</code> operation will return a non\nexpired timestamp.\nC4 will simply restart from the first step.\nNote that even if C4 set the key a bit a few seconds in the future this is\nnot a problem.</p><p>In order to make this locking algorithm more robust, a\nclient holding a lock should always check the timeout didn’t expire before\nunlocking the key with <code>DEL</code> because client failures can be complex, not just\ncrashing but also blocking a lot of time against some operations and trying\nto issue <code>DEL</code> after a lot of time (when the LOCK is already held by another\nclient).</p>","link":"./alpha/commands/setnx.html","spaLink":"#/alpha/commands/setnx","title":"Handling deadlocks"},{"content":"<h2 id=\"-zadd-options-redis-302-or-greater\">ZADD options (Redis 3.0.2 or greater)</h2><p>ZADD supports a list of options, specified after the name of the key and before\nthe first score argument. Options are:</p><ul>\n<li><strong>XX</strong>: Only update elements that already exist. Never add elements.</li>\n<li><strong>NX</strong>: Don’t update already existing elements. Always add new elements.</li>\n<li><strong>CH</strong>: Modify the return value from the number of new elements added, to the total number of elements changed (CH is an abbreviation of <em>changed</em>). Changed elements are <strong>new elements added</strong> and elements already existing for which <strong>the score was updated</strong>. So elements specified in the command line having the same score as they had in the past are not counted. Note: normally the return value of <code>ZADD</code> only counts the number of new elements added.</li>\n<li><strong>INCR</strong>: When this option is specified <code>ZADD</code> acts like <code>ZINCRBY</code>. Only one score-element pair can be specified in this mode.</li>\n</ul>","link":"./alpha/commands/zadd.html","spaLink":"#/alpha/commands/zadd","title":"ZADD OPTIONS (REDIS 3.0.2 OR GREATER)"},{"content":"<h2 id=\"-range-of-integer-scores-that-can-be-expressed-precisely\">Range of integer scores that can be expressed precisely</h2><p>Redis sorted sets use a <em>double 64-bit floating point number</em> to represent the score. In all the architectures we support, this is represented as an <strong>IEEE 754 floating point number</strong>, that is able to represent precisely integer numbers between <code>-(2^53)</code> and <code>+(2^53)</code> included. In more practical terms, all the integers between -9007199254740992 and 9007199254740992 are perfectly representable. Larger integers, or fractions, are internally represented in exponential form, so it is possible that you get only an approximation of the decimal number, or of the very big integer, that you set as score.</p>","link":"./alpha/commands/zadd.html","spaLink":"#/alpha/commands/zadd","title":"RANGE OF INTEGER SCORES THAT CAN BE EXPRESSED PRECISELY"},{"content":"<h2 id=\"-sorted-sets-101\">Sorted sets 101</h2><p>Sorted sets are sorted by their score in an ascending way.\nThe same element only exists a single time, no repeated elements are\npermitted. The score can be modified both by <code>ZADD</code> that will update the\nelement score, and as a side effect, its position on the sorted set, and\nby <code>ZINCRBY</code> that can be used in order to update the score relatively to its\nprevious value.</p><p>The current score of an element can be retrieved using the <code>ZSCORE</code> command,\nthat can also be used to verify if an element already exists or not.</p><p>For an introduction to sorted sets, see the data types page on <a href=\"/topics/data-types#sorted-sets\">sorted\nsets</a>.</p>","link":"./alpha/commands/zadd.html","spaLink":"#/alpha/commands/zadd","title":"SORTED SETS 101"},{"content":"<h2 id=\"-elements-with-the-same-score\">Elements with the same score</h2><p>While the same element can’t be repeated in a sorted set since every element\nis unique, it is possible to add multiple different elements <em>having the same score</em>. When multiple elements have the same score, they are <em>ordered lexicographically</em> (they are still ordered by score as a first key, however, locally, all the elements with the same score are relatively ordered lexicographically).</p><p>The lexicographic ordering used is binary, it compares strings as array of bytes.</p><p>If the user inserts all the elements in a sorted set with the same score (for example 0), all the elements of the sorted set are sorted lexicographically, and range queries on elements are possible using the command <code>ZRANGEBYLEX</code> (Note: it is also possible to query sorted sets by range of scores using <code>ZRANGEBYSCORE</code>).</p><p>@return</p><p>@integer-reply, specifically:</p><ul>\n<li>The number of elements added to the sorted sets, not including elements\nalready existing for which the score was updated.</li>\n</ul><p>If the <code>INCR</code> option is specified, the return value will be @bulk-string-reply:</p><ul>\n<li>the new score of <code>member</code> (a double precision floating point number), represented as string.</li>\n</ul><p>@history</p><ul>\n<li><code>&gt;= 2.4</code>: Accepts multiple elements.\nIn Redis versions older than 2.4 it was possible to add or update a single\nmember per call.</li>\n</ul><p>@examples</p>","link":"./alpha/commands/zadd.html","spaLink":"#/alpha/commands/zadd","title":"ELEMENTS WITH THE SAME SCORE"},{"content":"<h2 id=\"-exclusive-intervals-and-infinity\">Exclusive intervals and infinity</h2><p><code>min</code> and <code>max</code> can be <code>-inf</code> and <code>+inf</code>, so that you are not required to know\nthe highest or lowest score in the sorted set to get all elements from or up to\na certain score.</p><p>By default, the interval specified by <code>min</code> and <code>max</code> is closed (inclusive).\nIt is possible to specify an open interval (exclusive) by prefixing the score\nwith the character <code>(</code>.\nFor example:</p><p>Will return all elements with <code>1 &lt; score &lt;= 5</code> while:</p><p>Will return all the elements with <code>5 &lt; score &lt; 10</code> (5 and 10 excluded).</p><p>@return</p><p>@array-reply: list of elements in the specified score range (optionally\nwith their scores).</p><p>@examples</p>","link":"./alpha/commands/zrangebyscore.html","spaLink":"#/alpha/commands/zrangebyscore","title":"EXCLUSIVE INTERVALS AND INFINITY"},{"content":"<h2 id=\"-how-to-specify-intervals\">How to specify intervals</h2><p>Valid <em>start</em> and <em>stop</em> must start with <code>(</code> or <code>[</code>, in order to specify\nif the range item is respectively exclusive or inclusive.\nThe special values of <code>+</code> or <code>-</code> for <em>start</em> and <em>stop</em> have the special\nmeaning or positively infinite and negatively infinite strings, so for\ninstance the command <strong>ZRANGEBYLEX myzset - +</strong> is guaranteed to return\nall the elements in the sorted set, if all the elements have the same\nscore.</p>","link":"./alpha/commands/zrangebylex.html","spaLink":"#/alpha/commands/zrangebylex","title":"HOW TO SPECIFY INTERVALS"},{"content":"<h2 id=\"-details-on-strings-comparison\">Details on strings comparison</h2><p>Strings are compared as binary array of bytes. Because of how the ASCII character\nset is specified, this means that usually this also have the effect of comparing\nnormal ASCII characters in an obvious dictionary way. However this is not true\nif non plain ASCII strings are used (for example utf8 strings).</p><p>However the user can apply a transformation to the encoded string so that\nthe first part of the element inserted in the sorted set will compare as the\nuser requires for the specific application. For example if I want to\nadd strings that will be compared in a case-insensitive way, but I still\nwant to retrieve the real case when querying, I can add strings in the\nfollowing way:</p><p>Because of the first <em>normalized</em> part in every element (before the colon character), we are forcing a given comparison, however after the range is queries using <code>ZRANGEBYLEX</code> the application can display to the user the second part of the string, after the colon.</p><p>The binary nature of the comparison allows to use sorted sets as a general\npurpose index, for example the first part of the element can be a 64 bit\nbig endian number: since big endian numbers have the most significant bytes\nin the initial positions, the binary comparison will match the numerical\ncomparison of the numbers. This can be used in order to implement range\nqueries on 64 bit values. As in the example below, after the first 8 bytes\nwe can store the value of the element we are actually indexing.</p><p>@return</p><p>@array-reply: list of elements in the specified score range.</p><p>@examples</p>","link":"./alpha/commands/zrangebylex.html","spaLink":"#/alpha/commands/zrangebylex","title":"DETAILS ON STRINGS COMPARISON"},{"content":"<h1 id=\"redis-administration\">Redis Administration</h1><p>This page contains topics related to the administration of Redis instances.\nEvery topic is self contained in form of a FAQ. New topics will be created in the future.</p>","link":"./alpha/topics/admin.html","spaLink":"#/alpha/topics/admin","title":"REDIS ADMINISTRATION"},{"content":"<h2 id=\"redis-administration-redis-setup-hints\">Redis setup hints</h2><ul>\n<li>We suggest deploying Redis using the <strong>Linux operating system</strong>. Redis is also tested heavily on OS X, and tested from time to time on FreeBSD and OpenBSD systems. However Linux is where we do all the major stress testing, and where most production deployments are working.</li>\n<li>Make sure to set the Linux kernel <strong>overcommit memory setting to 1</strong>. Add <code>vm.overcommit_memory = 1</code> to <code>/etc/sysctl.conf</code> and then reboot or run the command <code>sysctl vm.overcommit_memory=1</code> for this to take effect immediately.</li>\n<li>Make sure to disable Linux kernel feature <em>transparent huge pages</em>, it will affect greatly both memory usage and latency in a negative way. This is accomplished with the following command: <code>echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled</code>.</li>\n<li>Make sure to <strong>setup some swap</strong> in your system (we suggest as much as swap as memory). If Linux does not have swap and your Redis instance accidentally consumes too much memory, either Redis will crash for out of memory or the Linux kernel OOM killer will kill the Redis process.</li>\n<li>Set an explicit <code>maxmemory</code> option limit in your instance in order to make sure that the instance will report errors instead of failing when the system memory limit is near to be reached.</li>\n<li>If you are using Redis in a very write-heavy application, while saving an RDB file on disk or rewriting the AOF log <strong>Redis may use up to 2 times the memory normally used</strong>. The additional memory used is proportional to the number of memory pages modified by writes during the saving process, so it is often proportional to the number of keys (or aggregate types items) touched during this time. Make sure to size your memory accordingly.</li>\n<li>Use <code>daemonize no</code> when run under daemontools.</li>\n<li>Even if you have persistence disabled, Redis will need to perform RDB saves if you use replication, unless you use the new diskless replication feature, which is currently experimental.</li>\n<li>If you are using replication, make sure that either your master has persistence enabled, or that it does not automatically restarts on crashes: slaves will try to be an exact copy of the master, so if a master restarts with an empty data set, slaves will be wiped as well.</li>\n<li>By default Redis does not require <strong>any authentication and listens to all the network interfaces</strong>. This is a big security issue if you leave Redis exposed on the internet or other places where attackers can reach it. See for example <a href=\"http://antirez.com/news/96\">this attack</a> to see how dangerous it can be. Please check our <a href=\"/topics/security\">security page</a> and the <a href=\"/topic/quickstart\">quick start</a> for information about how to secure Redis.</li>\n</ul>","link":"./alpha/topics/admin.html","spaLink":"#/alpha/topics/admin","title":"REDIS SETUP HINTS"},{"content":"<h2 id=\"redis-administration-running-redis-on-ec2\">Running Redis on EC2</h2><ul>\n<li>Use HVM based instances, not PV based instances.</li>\n<li>Don’t use old instances families, for example: use m3.medium with HVM instead of m1.medium with PV.</li>\n<li>The use of Redis persistence with <strong>EC2 EBS volumes</strong> needs to be handled with care since sometimes EBS volumes have high latency characteristics.</li>\n<li>You may want to try the new <strong>diskless replication</strong> (currently experimental) if you have issues when slaves are synchronizing with the master.</li>\n</ul>","link":"./alpha/topics/admin.html","spaLink":"#/alpha/topics/admin","title":"RUNNING REDIS ON EC2"},{"content":"<h2 id=\"redis-administration-upgrading-or-restarting-a-redis-instance-without-downtime\">Upgrading or restarting a Redis instance without downtime</h2><p>Redis is designed to be a very long running process in your server.\nFor instance many configuration options can be modified without any kind of restart using the <a href=\"/commands/config-set\">CONFIG SET command</a>.</p><p>Starting from Redis 2.2 it is even possible to switch from AOF to RDB snapshots persistence or the other way around without restarting Redis. Check the output of the <code>CONFIG GET *</code> command for more information.</p><p>However from time to time a restart is mandatory, for instance in order to upgrade the Redis process to a newer version, or when you need to modify some configuration parameter that is currently not supported by the CONFIG command.</p><p>The following steps provide a very commonly used way in order to avoid any downtime.</p><ul>\n<li>Setup your new Redis instance as a slave for your current Redis instance. In order to do so you need a different server, or a server that has enough RAM to keep two instances of Redis running at the same time.</li>\n<li>If you use a single server, make sure that the slave is started in a different port than the master instance, otherwise the slave will not be able to start at all.</li>\n<li>Wait for the replication initial synchronization to complete (check the slave log file).</li>\n<li>Make sure using INFO that there are the same number of keys in the master and in the slave. Check with redis-cli that the slave is working as you wish and is replying to your commands.</li>\n<li>Allow writes to the slave using <strong>CONFIG SET slave-read-only no</strong></li>\n<li>Configure all your clients in order to use the new instance (that is, the slave).</li>\n<li>Once you are sure that the master is no longer receiving any query (you can check this with the <a href=\"/commands/monitor\">MONITOR command</a>), elect the slave to master using the <strong>SLAVEOF NO ONE</strong> command, and shut down your master.</li>\n</ul>","link":"./alpha/topics/admin.html","spaLink":"#/alpha/topics/admin","title":"UPGRADING OR RESTARTING A REDIS INSTANCE WITHOUT DOWNTIME"},{"content":"<h2 id=\"-consistency-and-wait\">Consistency and WAIT</h2><p>Note that <code>WAIT</code> does not make Redis a strongly consistent store: while synchronous replication is part of a replicated state machine, it is not the only thing needed. However in the context of Sentinel or Redis Cluster failover, <code>WAIT</code> improves the real world data safety.</p><p>Specifically if a given write is transferred to one or more slaves, it is more likely (but not guaranteed) that if the master fails, we’ll be able to promote, during a failover, a slave that received the write: both Sentinel and Redis Cluster will do a best-effort attempt to promote the best slave among the set of available slaves.</p><p>However this is just a best-effort attempt so it is possible to still lose a write synchronously replicated to multiple slaves.</p>","link":"./alpha/commands/wait.html","spaLink":"#/alpha/commands/wait","title":"CONSISTENCY AND WAIT"},{"content":"<h2 id=\"-implementation-details\">Implementation details</h2><p>Since the introduction of partial resynchronization with slaves (PSYNC feature)\nRedis slaves asynchronously ping their master with the offset they already\nprocessed in the replication stream. This is used in multiple ways:</p><p>In the specific case of the implementation of <code>WAIT</code>, Redis remembers, for each client, the replication offset of the produced replication stream when a given\nwrite command was executed in the context of a given client. When <code>WAIT</code> is\ncalled Redis checks if the specified number of slaves already acknowledged\nthis offset or a greater one.</p><p>@return</p><p>@integer-reply: The command returns the number of slaves reached by all the writes performed in the context of the current connection.</p><p>@examples</p><p>In the following example the first call to <code>WAIT</code> does not use a timeout and asks for the write to reach 1 slave. It returns with success. In the second attempt instead we put a timeout, and ask for the replication of the write to two slaves. Since there is a single slave available, after one second <code>WAIT</code> unblocks and returns 1, the number of slaves reached.</p>","link":"./alpha/commands/wait.html","spaLink":"#/alpha/commands/wait","title":"IMPLEMENTATION DETAILS"},{"content":"<h2 id=\"-specification-of-the-behavior-when-count-is-passed\">Specification of the behavior when count is passed</h2><p>When a count argument is passed and is positive, the elements are returned\nas if every selected element is removed from the set (like the extraction\nof numbers in the game of Bingo). However elements are <strong>not removed</strong> from\nthe Set. So basically:</p><ul>\n<li>No repeated elements are returned.</li>\n<li>If count is bigger than the number of elements inside the Set, the command will only return the whole set without additional elements.</li>\n</ul><p>When instead the count is negative, the behavior changes and the extraction happens as if you put the extracted element inside the bag again after every extraction, so repeated elements are possible, and the number of elements requested is always returned as we can repeat the same elements again and again, with the exception of an empty Set (non existing key) that will always produce an empty array as a result.</p>","link":"./alpha/commands/srandmember.html","spaLink":"#/alpha/commands/srandmember","title":"SPECIFICATION OF THE BEHAVIOR WHEN COUNT IS PASSED"},{"content":"<h2 id=\"-distribution-of-returned-elements\">Distribution of returned elements</h2><p>The distribution of the returned elements is far from perfect when the number of elements in the set is small, this is due to the fact that we used an approximated random element function that does not really guarantees good distribution.</p><p>The algorithm used, that is implemented inside dict.c, samples the hash table buckets to find a non-empty one. Once a non empty bucket is found, since we use chaining in our hash table implementation, the number of elements inside the bucked is checked and a random element is selected.</p><p>This means that if you have two non-empty buckets in the entire hash table, and one has three elements while one has just one, the element that is alone in its bucket will be returned with much higher probability.</p>","link":"./alpha/commands/srandmember.html","spaLink":"#/alpha/commands/srandmember","title":"DISTRIBUTION OF RETURNED ELEMENTS"},{"content":"<h2 id=\"-sorting-by-external-keys\">Sorting by external keys</h2><p>Sometimes you want to sort elements using external keys as weights to compare\ninstead of comparing the actual elements in the list, set or sorted set.\nLet’s say the list <code>mylist</code> contains the elements <code>1</code>, <code>2</code> and <code>3</code> representing\nunique IDs of objects stored in <code>object_1</code>, <code>object_2</code> and <code>object_3</code>.\nWhen these objects have associated weights stored in <code>weight_1</code>, <code>weight_2</code> and\n<code>weight_3</code>, <code>SORT</code> can be instructed to use these weights to sort <code>mylist</code> with\nthe following statement:</p><p>The <code>BY</code> option takes a pattern (equal to <code>weight_*</code> in this example) that is\nused to generate the keys that are used for sorting.\nThese key names are obtained substituting the first occurrence of <code>*</code> with the\nactual value of the element in the list (<code>1</code>, <code>2</code> and <code>3</code> in this example).</p>","link":"./alpha/commands/sort.html","spaLink":"#/alpha/commands/sort","title":"SORTING BY EXTERNAL KEYS"},{"content":"<h2 id=\"-skip-sorting-the-elements\">Skip sorting the elements</h2><p>The <code>!BY</code> option can also take a non-existent key, which causes <code>SORT</code> to skip\nthe sorting operation.\nThis is useful if you want to retrieve external keys (see the <code>!GET</code> option\nbelow) without the overhead of sorting.</p>","link":"./alpha/commands/sort.html","spaLink":"#/alpha/commands/sort","title":"SKIP SORTING THE ELEMENTS"},{"content":"<h2 id=\"-retrieving-external-keys\">Retrieving external keys</h2><p>Our previous example returns just the sorted IDs.\nIn some cases, it is more useful to get the actual objects instead of their IDs\n(<code>object_1</code>, <code>object_2</code> and <code>object_3</code>).\nRetrieving external keys based on the elements in a list, set or sorted set can\nbe done with the following command:</p><p>The <code>!GET</code> option can be used multiple times in order to get more keys for every\nelement of the original list, set or sorted set.</p><p>It is also possible to <code>!GET</code> the element itself using the special pattern <code>#</code>:</p>","link":"./alpha/commands/sort.html","spaLink":"#/alpha/commands/sort","title":"RETRIEVING EXTERNAL KEYS"},{"content":"<h2 id=\"-storing-the-result-of-a-sort-operation\">Storing the result of a SORT operation</h2><p>By default, <code>SORT</code> returns the sorted elements to the client.\nWith the <code>!STORE</code> option, the result will be stored as a list at the specified\nkey instead of being returned to the client.</p><p>An interesting pattern using <code>SORT ... STORE</code> consists in associating an\n<code>EXPIRE</code> timeout to the resulting key so that in applications where the result\nof a <code>SORT</code> operation can be cached for some time.\nOther clients will use the cached list instead of calling <code>SORT</code> for every\nrequest.\nWhen the key will timeout, an updated version of the cache can be created by\ncalling <code>SORT ... STORE</code> again.</p><p>Note that for correctly implementing this pattern it is important to avoid\nmultiple clients rebuilding the cache at the same time.\nSome kind of locking is needed here (for instance using <code>SETNX</code>).</p>","link":"./alpha/commands/sort.html","spaLink":"#/alpha/commands/sort","title":"STORING THE RESULT OF A SORT OPERATION"},{"content":"<h2 id=\"-using-hashes-in-by-and-get\">Using hashes in <code>!BY</code> and <code>!GET</code></h2><p>It is possible to use <code>!BY</code> and <code>!GET</code> options against hash fields with the\nfollowing syntax:</p><p>The string <code>-&gt;</code> is used to separate the key name from the hash field name.\nThe key is substituted as documented above, and the hash stored at the resulting\nkey is accessed to retrieve the specified hash field.</p><p>@return</p><p>@array-reply: list of sorted elements.</p>","link":"./alpha/commands/sort.html","spaLink":"#/alpha/commands/sort","title":"USING HASHES IN !BY AND !GET"},{"content":"<h1 id=\"faq\">FAQ</h1>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"FAQ"},{"content":"<h2 id=\"faq-why-redis-is-different-compared-to-other-key-value-stores\">Why Redis is different compared to other key-value stores?</h2><p>There are two main reasons.</p><ul>\n<li>Redis is a different evolution path in the key-value DBs where values can contain more complex data types, with atomic operations defined on those data types. Redis data types are closely related to fundamental data structures and are exposed to the programmer as such, without additional abstraction layers.</li>\n<li>Redis is an in-memory but persistent on disk database, so it represents a different trade off where very high write and read speed is achieved with the limitation of data sets that can’t be larger than memory. Another advantage of\nin memory databases is that the memory representation of complex data structures\nis much simpler to manipulate compared to the same data structure on disk, so\nRedis can do a lot, with little internal complexity. At the same time the\ntwo on-disk storage formats (RDB and AOF) don’t need to be suitable for random\naccess, so they are compact and always generated in an append-only fashion\n(Even the AOF log rotation is an append-only operation, since the new version\nis generated from the copy of data in memory).</li>\n</ul>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHY REDIS IS DIFFERENT COMPARED TO OTHER KEY-VALUE STORES?"},{"content":"<h2 id=\"faq-whats-the-redis-memory-footprint\">What’s the Redis memory footprint?</h2><p>To give you a few examples (all obtained using 64-bit instances):</p><ul>\n<li>An empty instance uses ~ 1MB of memory.</li>\n<li>1 Million small Keys -&gt; String Value pairs use ~ 100MB of memory.</li>\n<li>1 Million Keys -&gt; Hash value, representing an object with 5 fields, use ~ 200 MB of memory.</li>\n</ul><p>To test your use case is trivial using the <code>redis-benchmark</code> utility to generate random data sets and check with the <code>INFO memory</code> command the space used.</p><p>64-bit systems will use considerably more memory than 32-bit systems to store the same keys, especially if the keys and values are small. This is because pointers take 8 bytes in 64-bit systems. But of course the advantage is that you can\nhave a lot of memory in 64-bit systems, so in order to run large Redis servers a 64-bit system is more or less required. The alternative is sharding.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHAT’S THE REDIS MEMORY FOOTPRINT?"},{"content":"<h2 id=\"faq-i-like-rediss-high-level-operations-and-features-but-i-dont-like-that-it-takes-everything-in-memory-and-i-cant-have-a-dataset-larger-the-memory-plans-to-change-this\">I like Redis’s high level operations and features, but I don’t like that it takes everything in memory and I can’t have a dataset larger the memory. Plans to change this?</h2><p>In the past the Redis developers experimented with Virtual Memory and other systems in order to allow larger than RAM datasets, but after all we are very happy if we can do one thing well: data served from memory, disk used for storage. So for now there are no plans to create an on disk backend for Redis. Most of what\nRedis is, after all, is a direct result of its current design.</p><p>If your real problem is not the total RAM needed, but the fact that you need\nto split your data set into multiple Redis instances, please read the\n<a href=\"/topics/partitioning\">Partitioning page</a> in this documentation for more info.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"I LIKE REDIS’S HIGH LEVEL OPERATIONS AND FEATURES, BUT I DON’T LIKE THAT IT TAKES EVERYTHING IN MEMORY AND I CAN’T HAVE A DATASET LARGER THE MEMORY. PLANS TO CHANGE THIS?"},{"content":"<h2 id=\"faq-is-using-redis-together-with-an-on-disk-database-a-good-idea\">Is using Redis together with an on-disk database a good idea?</h2><p>Yes, a common design pattern involves taking very write-heavy small data\nin Redis (and data you need the Redis data structures to model your problem\nin an efficient way), and big <em>blobs</em> of data into an SQL or eventually\nconsistent on-disk database.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"IS USING REDIS TOGETHER WITH AN ON-DISK DATABASE A GOOD IDEA?"},{"content":"<h2 id=\"faq-is-there-something-i-can-do-to-lower-the-redis-memory-usage\">Is there something I can do to lower the Redis memory usage?</h2><p>If you can, use Redis 32 bit instances. Also make good use of small hashes,\nlists, sorted sets, and sets of integers, since Redis is able to represent\nthose data types in the special case of a few elements in a much more compact\nway. There is more info in the <a href=\"/topics/memory-optimization\">Memory Optimization page</a>.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"IS THERE SOMETHING I CAN DO TO LOWER THE REDIS MEMORY USAGE?"},{"content":"<h2 id=\"faq-what-happens-if-redis-runs-out-of-memory\">What happens if Redis runs out of memory?</h2><p>Redis will either be killed by the Linux kernel OOM killer,\ncrash with an error, or will start to slow down.\nWith modern operating systems malloc() returning NULL is not common, usually\nthe server will start swapping, and Redis performance will degrade, so\nyou’ll probably notice there is something wrong.</p><p>The INFO command will report the amount of memory Redis is using so you can\nwrite scripts that monitor your Redis servers checking for critical conditions.</p><p>Redis has built-in protections allowing the user to set a max limit to memory\nusage, using the <code>maxmemory</code> option in the config file to put a limit\nto the memory Redis can use. If this limit is reached Redis will start to reply\nwith an error to write commands (but will continue to accept read-only\ncommands), or you can configure it to evict keys when the max memory limit\nis reached in the case you are using Redis for caching.</p><p>We have documentation if you plan to use <a href=\"/topics/lru-cache\">Redis as an LRU cache</a>.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHAT HAPPENS IF REDIS RUNS OUT OF MEMORY?"},{"content":"<h2 id=\"faq-background-saving-is-failing-with-a-fork-error-under-linux-even-if-ive-a-lot-of-free-ram\">Background saving is failing with a fork() error under Linux even if I’ve a lot of free RAM!</h2><p>Short answer: <code>echo 1 &gt; /proc/sys/vm/overcommit_memory</code> :)</p><p>And now the long one:</p><p>Redis background saving schema relies on the copy-on-write semantic of fork in\nmodern operating systems: Redis forks (creates a child process) that is an\nexact copy of the parent. The child process dumps the DB on disk and finally\nexits. In theory the child should use as much memory as the parent being a\ncopy, but actually thanks to the copy-on-write semantic implemented by most\nmodern operating systems the parent and child process will <em>share</em> the common\nmemory pages. A page will be duplicated only when it changes in the child or in\nthe parent. Since in theory all the pages may change while the child process is\nsaving, Linux can’t tell in advance how much memory the child will take, so if\nthe <code>overcommit_memory</code> setting is set to zero fork will fail unless there is\nas much free RAM as required to really duplicate all the parent memory pages,\nwith the result that if you have a Redis dataset of 3 GB and just 2 GB of free\nmemory it will fail.</p><p>Setting <code>overcommit_memory</code> to 1 says Linux to relax and perform the fork in a\nmore optimistic allocation fashion, and this is indeed what you want for Redis.</p><p>A good source to understand how Linux Virtual Memory work and other\nalternatives for <code>overcommit_memory</code> and <code>overcommit_ratio</code> is this classic\nfrom Red Hat Magazine, <a href=\"http://www.redhat.com/magazine/001nov04/features/vm/\">“Understanding Virtual Memory”</a>.\nBeware, this article had <code>1</code> and <code>2</code> configuration values for <code>overcommit_memory</code>\nreversed: refer to the <a href=\"http://man7.org/linux/man-pages/man5/proc.5.html\">proc(5)</a> man page for the right meaning of the\navailable values.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"BACKGROUND SAVING IS FAILING WITH A FORK() ERROR UNDER LINUX EVEN IF I’VE A LOT OF FREE RAM!"},{"content":"<h2 id=\"faq-are-redis-on-disk-snapshots-atomic\">Are Redis on-disk-snapshots atomic?</h2><p>Yes, redis background saving process is always forked when the server is\noutside of the execution of a command, so every command reported to be atomic\nin RAM is also atomic from the point of view of the disk snapshot.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"ARE REDIS ON-DISK-SNAPSHOTS ATOMIC?"},{"content":"<h2 id=\"faq-redis-is-single-threaded-how-can-i-exploit-multiple-cpu-cores\">Redis is single threaded. How can I exploit multiple CPU / cores?</h2><p>It’s very unlikely that CPU becomes your bottleneck with Redis, as usually Redis is either memory or network bound. For instance, using pipelining Redis running\non an average Linux system can deliver even 500k requests per second, so\nif your application mainly uses O(N) or O(log(N)) commands, it is hardly\ngoing to use too much CPU.</p><p>However, to maximize CPU usage you can start multiple instances of Redis in\nthe same box and treat them as different servers. At some point a single\nbox may not be enough anyway, so if you want to use multiple CPUs you can\nstart thinking of some way to shard earlier.</p><p>You can find more information about using multiple Redis instances in the <a href=\"/topics/partitioning\">Partitioning page</a>.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"REDIS IS SINGLE THREADED. HOW CAN I EXPLOIT MULTIPLE CPU / CORES?"},{"content":"<h2 id=\"faq-what-is-the-maximum-number-of-keys-a-single-redis-instance-can-hold-and-what-the-max-number-of-elements-in-a-hash-list-set-sorted-set\">What is the maximum number of keys a single Redis instance can hold? and what the max number of elements in a Hash, List, Set, Sorted Set?</h2><p>Redis can handle up to 2^32 keys, and was tested in practice to\nhandle at least 250 million of keys per instance.</p><p>Every hash, list, set, and sorted set, can hold 2^32 elements.</p><p>In other words your limit is likely the available memory in your system.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHAT IS THE MAXIMUM NUMBER OF KEYS A SINGLE REDIS INSTANCE CAN HOLD? AND WHAT THE MAX NUMBER OF ELEMENTS IN A HASH, LIST, SET, SORTED SET?"},{"content":"<h2 id=\"faq-my-slave-claims-to-have-a-different-number-of-keys-compared-to-its-master-why\">My slave claims to have a different number of keys compared to its master, why?</h2><p>If you use keys with limited time to live (Redis expires) this is normal behavior. This is what happens:</p><ul>\n<li>The master generates an RDB file on the first synchronization with the slave.</li>\n<li>The RDB file will not include keys already expired in the master, but that are still in memory.</li>\n<li>However these keys are still in the memory of the Redis master, even if logically expired. They’ll not be considered as existing, but the memory will be reclaimed later, both incrementally and explicitly on access. However while these keys are not logical part of the dataset, they are advertised in <code>INFO</code> output and by the <code>DBSIZE</code> command.</li>\n<li>When the slave reads the RDB file generated by the master, this set of keys will not be loaded.</li>\n</ul><p>As a result of this, it is common for users with many keys with an expire set to see less keys in the slaves, because of this artifact, but there is no actual logical difference in the instances content.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"MY SLAVE CLAIMS TO HAVE A DIFFERENT NUMBER OF KEYS COMPARED TO ITS MASTER, WHY?"},{"content":"<h2 id=\"faq-what-redis-means-actually\">What Redis means actually?</h2><p>It means REmote DIctionary Server.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHAT REDIS MEANS ACTUALLY?"},{"content":"<h2 id=\"faq-why-did-you-start-the-redis-project\">Why did you start the Redis project?</h2><p>Originally Redis was started in order to scale <a href=\"http://lloogg.com\">LLOOGG</a>. But after I got the basic server working I liked the idea to share the work with other people, and Redis was turned into an open source project.</p>","link":"./alpha/topics/faq.html","spaLink":"#/alpha/topics/faq","title":"WHY DID YOU START THE REDIS PROJECT?"},{"content":"<h1 id=\"redis-event-library\">Redis Event Library</h1><p>Redis implements its own event library. The event library is implemented in <code>ae.c</code>.</p><p>The best way to understand how the Redis event library works is to understand how Redis uses it.</p>","link":"./alpha/topics/internals-rediseventlib.html","spaLink":"#/alpha/topics/internals-rediseventlib","title":"REDIS EVENT LIBRARY"},{"content":"<h2 id=\"redis-event-library-event-loop-initialization\">Event Loop Initialization</h2><p><code>initServer</code> function defined in <code>redis.c</code> initializes the numerous fields of the <code>redisServer</code> structure variable. One such field is the Redis event loop <code>el</code>:</p><p><code>initServer</code> initializes <code>server.el</code> field by calling <code>aeCreateEventLoop</code> defined in <code>ae.c</code>. The definition of <code>aeEventLoop</code> is below:</p>","link":"./alpha/topics/internals-rediseventlib.html","spaLink":"#/alpha/topics/internals-rediseventlib","title":"EVENT LOOP INITIALIZATION"},{"content":"<h2 id=\"redis-event-library-aecreateeventloop\"><code>aeCreateEventLoop</code></h2><p><code>aeCreateEventLoop</code> first <code>malloc</code>s <code>aeEventLoop</code> structure then calls <code>ae_epoll.c:aeApiCreate</code>.</p><p><code>aeApiCreate</code> <code>malloc</code>s <code>aeApiState</code> that has two fields - <code>epfd</code> that holds the <code>epoll</code> file descriptor returned by a call from <a href=\"http://man.cx/epoll_create%282%29\"><code>epoll_create</code></a> and <code>events</code> that is of type <code>struct epoll_event</code> define by the Linux <code>epoll</code> library. The use of the <code>events</code> field will be  described later.</p><p>Next is <code>ae.c:aeCreateTimeEvent</code>. But before that <code>initServer</code> call <code>anet.c:anetTcpServer</code> that creates and returns a <em>listening descriptor</em>. The descriptor listens on <em>port 6379</em> by default. The returned  <em>listening descriptor</em> is stored in <code>server.fd</code> field.</p>","link":"./alpha/topics/internals-rediseventlib.html","spaLink":"#/alpha/topics/internals-rediseventlib","title":"AECREATEEVENTLOOP"},{"content":"<h2 id=\"redis-event-library-aecreatetimeevent\"><code>aeCreateTimeEvent</code></h2><p><code>aeCreateTimeEvent</code> accepts the following as parameters:</p><ul>\n<li><code>eventLoop</code>: This is <code>server.el</code> in <code>redis.c</code></li>\n<li>milliseconds: The number of milliseconds from the current time after which the timer expires.</li>\n<li><code>proc</code>: Function pointer. Stores the address of the function that has to be called after the timer expires.</li>\n<li><code>clientData</code>: Mostly <code>NULL</code>.</li>\n<li><code>finalizerProc</code>: Pointer to the function that has to be called before the timed event is removed from the list of timed events.</li>\n</ul><p><code>initServer</code> calls <code>aeCreateTimeEvent</code> to add a timed event to <code>timeEventHead</code> field of <code>server.el</code>. <code>timeEventHead</code> is a pointer to a list of such timed events. The call to <code>aeCreateTimeEvent</code> from <code>redis.c:initServer</code> function is given below:</p><p><code>redis.c:serverCron</code> performs many operations that helps keep Redis running properly.</p>","link":"./alpha/topics/internals-rediseventlib.html","spaLink":"#/alpha/topics/internals-rediseventlib","title":"AECREATETIMEEVENT"},{"content":"<h2 id=\"redis-event-library-aecreatefileevent\"><code>aeCreateFileEvent</code></h2><p>The essence of <code>aeCreateFileEvent</code> function is to execute <a href=\"http://man.cx/epoll_ctl\"><code>epoll_ctl</code></a> system call which adds a watch for <code>EPOLLIN</code> event on the <em>listening descriptor</em> create by <code>anetTcpServer</code> and associate it with the <code>epoll</code> descriptor created by a call to <code>aeCreateEventLoop</code>.</p><p>Following is an explanation of what precisely <code>aeCreateFileEvent</code> does when called from <code>redis.c:initServer</code>.</p><p><code>initServer</code> passes the following arguments to <code>aeCreateFileEvent</code>:</p><ul>\n<li><code>server.el</code>: The event loop created by <code>aeCreateEventLoop</code>. The <code>epoll</code> descriptor is got from <code>server.el</code>.</li>\n<li><code>server.fd</code>: The <em>listening descriptor</em> that also serves as an index to access the relevant file event structure from the <code>eventLoop-&gt;events</code> table and store extra information like the callback function.</li>\n<li><code>AE_READABLE</code>: Signifies that <code>server.fd</code> has to be watched for <code>EPOLLIN</code> event.</li>\n<li><code>acceptHandler</code>: The function that has to be executed when the event being watched for is ready. This function pointer is stored in <code>eventLoop-&gt;events[server.fd]-&gt;rfileProc</code>.</li>\n</ul><p>This completes the initialization of Redis event loop.</p>","link":"./alpha/topics/internals-rediseventlib.html","spaLink":"#/alpha/topics/internals-rediseventlib","title":"AECREATEFILEEVENT"},{"content":"<h2 id=\"redis-event-library-event-loop-processing\">Event Loop Processing</h2><p><code>ae.c:aeMain</code> called from <code>redis.c:main</code> does the job of processing the event loop that is initialized in the previous phase.</p><p><code>ae.c:aeMain</code> calls <code>ae.c:aeProcessEvents</code> in a while loop that processes pending time and file events.</p>","link":"./alpha/topics/internals-rediseventlib.html","spaLink":"#/alpha/topics/internals-rediseventlib","title":"EVENT LOOP PROCESSING"},{"content":"<h2 id=\"redis-event-library-aeprocessevents\"><code>aeProcessEvents</code></h2><p><code>ae.c:aeProcessEvents</code> looks for the time event that will be pending in the smallest amount of time by calling <code>ae.c:aeSearchNearestTimer</code> on the event loop. In our case there is only one timer event in the event loop that was created by <code>ae.c:aeCreateTimeEvent</code>.</p><p>Remember, that timer event created by <code>aeCreateTimeEvent</code> has by now probably elapsed because it had a expiry time of one millisecond. Since, the timer has already expired the seconds and microseconds fields of the <code>tvp</code> <code>timeval</code> structure variable is initialized to zero.</p><p>The <code>tvp</code> structure variable along with the event loop variable is passed to <code>ae_epoll.c:aeApiPoll</code>.</p><p><code>aeApiPoll</code> functions does a <a href=\"http://man.cx/epoll_wait\"><code>epoll_wait</code></a> on the <code>epoll</code> descriptor and populates the <code>eventLoop-&gt;fired</code> table with the details:</p><ul>\n<li><code>fd</code>: The descriptor that is now ready to do a read/write operation depending on the mask value.</li>\n<li><code>mask</code>: The read/write event that can now be performed on the corresponding descriptor.</li>\n</ul><p><code>aeApiPoll</code> returns the number of such file events ready for operation. Now to put things in context, if any client has requested for a connection then <code>aeApiPoll</code> would have noticed it and populated the <code>eventLoop-&gt;fired</code> table with an entry of the descriptor being the <em>listening descriptor</em> and mask being <code>AE_READABLE</code>.</p><p>Now, <code>aeProcessEvents</code> calls the <code>redis.c:acceptHandler</code> registered as the callback. <code>acceptHandler</code> executes <a href=\"http://man.cx/accept\">accept</a> on the <em>listening descriptor</em> returning a <em>connected descriptor</em> with the client. <code>redis.c:createClient</code> adds a file event on the <em>connected descriptor</em> through a call to <code>ae.c:aeCreateFileEvent</code> like below:</p><p><code>c</code> is the <code>redisClient</code> structure variable and <code>c-&gt;fd</code> is the connected descriptor.</p><p>Next the <code>ae.c:aeProcessEvent</code> calls <code>ae.c:processTimeEvents</code></p>","link":"./alpha/topics/internals-rediseventlib.html","spaLink":"#/alpha/topics/internals-rediseventlib","title":"AEPROCESSEVENTS"},{"content":"<h2 id=\"redis-event-library-processtimeevents\"><code>processTimeEvents</code></h2><p><code>ae.processTimeEvents</code> iterates over list of time events starting at <code>eventLoop-&gt;timeEventHead</code>.</p><p>For every timed event that has elapsed <code>processTimeEvents</code> calls the registered callback. In this case it calls the only timed event callback registered, that is, <code>redis.c:serverCron</code>. The callback returns the time in milliseconds after which the callback must be called again. This change is recorded via a call to <code>ae.c:aeAddMilliSeconds</code> and will be handled on the next iteration of <code>ae.c:aeMain</code> while loop.</p><p>That’s all.</p>","link":"./alpha/topics/internals-rediseventlib.html","spaLink":"#/alpha/topics/internals-rediseventlib","title":"PROCESSTIMEEVENTS"},{"content":"<h1 id=\"pubsub\">Pub/Sub</h1><p><code>SUBSCRIBE</code>, <code>UNSUBSCRIBE</code> and <code>PUBLISH</code>\nimplement the <a href=\"http://en.wikipedia.org/wiki/Publish/subscribe\">Publish/Subscribe messaging\nparadigm</a> where\n(citing Wikipedia) senders (publishers) are not programmed to send\ntheir messages to specific receivers (subscribers). Rather, published\nmessages are characterized into channels, without knowledge of what (if\nany) subscribers there may be. Subscribers express interest in one or\nmore channels, and only receive messages that are of interest, without\nknowledge of what (if any) publishers there are. This decoupling of\npublishers and subscribers can allow for greater scalability and a more\ndynamic network topology.</p><p>For instance in order to subscribe to channels <code>foo</code> and <code>bar</code> the\nclient issues a <code>SUBSCRIBE</code> providing the names of the channels:</p><p>Messages sent by other clients to these channels will be pushed by Redis\nto all the subscribed clients.</p><p>A client subscribed to one or more channels should not issue commands,\nalthough it can subscribe and unsubscribe to and from other channels.\nThe replies to subscription and unsubscription operations are sent in\nthe form of messages, so that the client can just read a coherent\nstream of messages where the first element indicates the type of\nmessage. The commands that are allowed in the context of a subscribed\nclient are <code>SUBSCRIBE</code>, <code>PSUBSCRIBE</code>, <code>UNSUBSCRIBE</code>, <code>PUNSUBSCRIBE</code>,\n<code>PING</code> and <code>QUIT</code>.</p>","link":"./alpha/topics/pubsub.html","spaLink":"#/alpha/topics/pubsub","title":"PUB/SUB"},{"content":"<h2 id=\"pubsub-format-of-pushed-messages\">Format of pushed messages</h2><p>A message is a @array-reply with three elements.</p><p>The first element is the kind of message:</p><ul>\n<li><p><code>subscribe</code>: means that we successfully subscribed to the channel\ngiven as the second element in the reply. The third argument represents\nthe number of channels we are currently subscribed to.</p>\n</li>\n<li><p><code>unsubscribe</code>: means that we successfully unsubscribed from the\nchannel given as second element in the reply. The third argument\nrepresents the number of channels we are currently subscribed to. When\nthe last argument is zero, we are no longer subscribed to any channel,\nand the client can issue any kind of Redis command as we are outside the\nPub/Sub state.</p>\n</li>\n<li><p><code>message</code>: it is a message received as result of a <code>PUBLISH</code> command\nissued by another client. The second element is the name of the\noriginating channel, and the third argument is the actual message\npayload.</p>\n</li>\n</ul><p><code>subscribe</code>: means that we successfully subscribed to the channel\ngiven as the second element in the reply. The third argument represents\nthe number of channels we are currently subscribed to.</p><p><code>unsubscribe</code>: means that we successfully unsubscribed from the\nchannel given as second element in the reply. The third argument\nrepresents the number of channels we are currently subscribed to. When\nthe last argument is zero, we are no longer subscribed to any channel,\nand the client can issue any kind of Redis command as we are outside the\nPub/Sub state.</p><p><code>message</code>: it is a message received as result of a <code>PUBLISH</code> command\nissued by another client. The second element is the name of the\noriginating channel, and the third argument is the actual message\npayload.</p>","link":"./alpha/topics/pubsub.html","spaLink":"#/alpha/topics/pubsub","title":"FORMAT OF PUSHED MESSAGES"},{"content":"<h2 id=\"pubsub-database-scoping\">Database &amp; Scoping</h2><p>Pub/Sub has no relation to the key space.  It was made to not interfere with\nit on any level, including database numbers.</p><p>Publishing on db 10, will be heard by a subscriber on db 1.</p><p>If you need scoping of some kind, prefix the channels with the name of the\nenvironment (test, staging, production, …).</p>","link":"./alpha/topics/pubsub.html","spaLink":"#/alpha/topics/pubsub","title":"DATABASE & SCOPING"},{"content":"<h2 id=\"pubsub-wire-protocol-example\">Wire protocol example</h2><p>At this point, from another client we issue a <code>PUBLISH</code> operation\nagainst the channel named <code>second</code>:</p><p>This is what the first client receives:</p><p>Now the client unsubscribes itself from all the channels using the\n<code>UNSUBSCRIBE</code> command without additional arguments:</p>","link":"./alpha/topics/pubsub.html","spaLink":"#/alpha/topics/pubsub","title":"WIRE PROTOCOL EXAMPLE"},{"content":"<h2 id=\"pubsub-pattern-matching-subscriptions\">Pattern-matching subscriptions</h2><p>The Redis Pub/Sub implementation supports pattern matching. Clients may\nsubscribe to glob-style patterns in order to receive all the messages\nsent to channel names matching a given pattern.</p><p>For instance:</p><p>Will receive all the messages sent to the channel <code>news.art.figurative</code>,\n<code>news.music.jazz</code>, etc.  All the glob-style patterns are valid, so\nmultiple wildcards are supported.</p><p>Will then unsubscribe the client from that pattern.  No other subscriptions\nwill be affected by this call.</p><p>Messages received as a result of pattern matching are sent in a\ndifferent format:</p><ul>\n<li>The type of the message is <code>pmessage</code>: it is a message received\nas result of a <code>PUBLISH</code> command issued by another client, matching\na pattern-matching subscription. The second element is the original\npattern matched, the third element is the name of the originating\nchannel, and the last element the actual message payload.</li>\n</ul><p>Similarly to <code>SUBSCRIBE</code> and <code>UNSUBSCRIBE</code>, <code>PSUBSCRIBE</code> and\n<code>PUNSUBSCRIBE</code> commands are acknowledged by the system sending a message\nof type <code>psubscribe</code> and <code>punsubscribe</code> using the same format as the\n<code>subscribe</code> and <code>unsubscribe</code> message format.</p>","link":"./alpha/topics/pubsub.html","spaLink":"#/alpha/topics/pubsub","title":"PATTERN-MATCHING SUBSCRIPTIONS"},{"content":"<h2 id=\"pubsub-messages-matching-both-a-pattern-and-a-channel-subscription\">Messages matching both a pattern and a channel subscription</h2><p>A client may receive a single message multiple times if it’s subscribed\nto multiple patterns matching a published message, or if it is\nsubscribed to both patterns and channels matching the message. Like in\nthe following example:</p><p>In the above example, if a message is sent to channel <code>foo</code>, the client\nwill receive two messages: one of type <code>message</code> and one of type\n<code>pmessage</code>.</p>","link":"./alpha/topics/pubsub.html","spaLink":"#/alpha/topics/pubsub","title":"MESSAGES MATCHING BOTH A PATTERN AND A CHANNEL SUBSCRIPTION"},{"content":"<h2 id=\"pubsub-the-meaning-of-the-subscription-count-with-pattern-matching\">The meaning of the subscription count with pattern matching</h2><p>In <code>subscribe</code>, <code>unsubscribe</code>, <code>psubscribe</code> and <code>punsubscribe</code>\nmessage types, the last argument is the count of subscriptions still\nactive. This number is actually the total number of channels and\npatterns the client is still subscribed to. So the client will exit\nthe Pub/Sub state only when this count drops to zero as a result of\nunsubscribing from all the channels and patterns.</p>","link":"./alpha/topics/pubsub.html","spaLink":"#/alpha/topics/pubsub","title":"THE MEANING OF THE SUBSCRIPTION COUNT WITH PATTERN MATCHING"},{"content":"<h2 id=\"pubsub-programming-example\">Programming example</h2><p>Pieter Noordhuis provided a great example using EventMachine\nand Redis to create <a href=\"https://gist.github.com/pietern/348262\">a multi user high performance web\nchat</a>.</p>","link":"./alpha/topics/pubsub.html","spaLink":"#/alpha/topics/pubsub","title":"PROGRAMMING EXAMPLE"},{"content":"<h2 id=\"pubsub-client-library-implementation-hints\">Client library implementation hints</h2><p>Because all the messages received contain the original subscription\ncausing the message delivery (the channel in the case of message type,\nand the original pattern in the case of pmessage type) client libraries\nmay bind the original subscription to callbacks (that can be anonymous\nfunctions, blocks, function pointers), using a hash table.</p><p>When a message is received an O(1) lookup can be done in order to\ndeliver the message to the registered callback.</p>","link":"./alpha/topics/pubsub.html","spaLink":"#/alpha/topics/pubsub","title":"CLIENT LIBRARY IMPLEMENTATION HINTS"},{"content":"<h1 id=\"using-redis-as-an-lru-cache\">Using Redis as an LRU cache</h1><p>When Redis is used as a cache, sometimes it is handy to let it automatically\nevict old data as you add new one. This behavior is very well known in the\ncommunity of developers, since it is the default behavior of the popular\n<em>memcached</em> system.</p><p>LRU is actually only one of the supported eviction methods. This page covers\nthe more general topic of the Redis <code>maxmemory</code> directive that is used in\norder to limit the memory usage to a fixed amount, and it also covers in\ndepth the LRU algorithm used by Redis, that is actually an approximation of\nthe exact LRU.</p>","link":"./alpha/topics/lru-cache.html","spaLink":"#/alpha/topics/lru-cache","title":"USING REDIS AS AN LRU CACHE"},{"content":"<h2 id=\"using-redis-as-an-lru-cache-maxmemory-configuration-directive\">Maxmemory configuration directive</h2><p>The <code>maxmemory</code> configuration directive is used in order to configure Redis\nto use a specified amount of memory for the data set. It is possible to\nset the configuration directive using the <code>redis.conf</code> file, or later using\nthe <code>CONFIG SET</code> command at runtime.</p><p>For example in order to configure a memory limit of 100 megabytes, the\nfollowing directive can be used inside the <code>redis.conf</code> file.</p><p>Setting <code>maxmemory</code> to zero results into no memory limits. This is the\ndefault behavior for 64 bit systems, while 32 bit systems use an implicit\nmemory limit of 3GB.</p><p>When the specified amount of memory is reached, it is possible to select\namong different behaviors, called <strong>policies</strong>.\nRedis can just return errors for commands that could result in more memory\nbeing used, or it can evict some old data in order to return back to the\nspecified limit every time new data is added.</p>","link":"./alpha/topics/lru-cache.html","spaLink":"#/alpha/topics/lru-cache","title":"MAXMEMORY CONFIGURATION DIRECTIVE"},{"content":"<h2 id=\"using-redis-as-an-lru-cache-eviction-policies\">Eviction policies</h2><p>The exact behavior Redis follows when the <code>maxmemory</code> limit is reached is\nconfigured using the <code>maxmemory-policy</code> configuration directive.</p><p>The following policies are available:</p><ul>\n<li><strong>noeviction</strong>: return errors when the memory limit was reached and the client is trying to execute commands that could result in more memory to be used (most write commands, but <code>DEL</code> and a few more exceptions).</li>\n<li><strong>allkeys-lru</strong>: evict keys trying to remove the less recently used (LRU) keys first, in order to make space for the new data added.</li>\n<li><strong>volatile-lru</strong>: evict keys trying to remove the less recently used (LRU) keys first, but only among keys that have an <strong>expire set</strong>, in order to make space for the new data added.</li>\n<li><strong>allkeys-random</strong>: evict random keys in order to make space for the new data added.</li>\n<li><strong>volatile-random</strong>: evict random keys in order to make space for the new data added, but only evict keys with an <strong>expire set</strong>.</li>\n<li><strong>volatile-ttl</strong>: In order to make space for the new data, evict only keys with an <strong>expire set</strong>, and try to evict keys with a shorter time to live (TTL) first.</li>\n</ul><p>The policies <strong>volatile-lru</strong>, <strong>volatile-random</strong> and <strong>volatile-ttl</strong> behave like <strong>noeviction</strong> if there are no keys to evict matching the prerequisites.</p><p>To pick the right eviction policy is important depending on the access pattern \nof your application, however you can reconfigure the policy at runtime while \nthe application is running, and monitor the number of cache misses and hits \nusing the Redis <code>INFO</code> output in order to tune your setup.</p><p>In general as a rule of thumb:</p><ul>\n<li>Use the <strong>allkeys-lru</strong> policy when you expect a power-law distribution in the popularity of your requests, that is, you expect that a subset of elements will be accessed far more often than the rest. <strong>This is a good pick if you are unsure</strong>.</li>\n<li>Use the <strong>allkeys-random</strong> if you have a cyclic access where all the keys are scanned continuously, or when you expect the distribution to be uniform (all elements likely accessed with the same probability).</li>\n<li>Use the <strong>volatile-ttl</strong> if you want to be able to provide hints to Redis about what are good candidate for expiration by using different TTL values when you create your cache objects.</li>\n</ul><p>The <strong>allkeys-lru</strong> and <strong>volatile-random</strong> policies are mainly useful when you want to use a single instance for both caching and to have a set of persistent keys. However it is usually a better idea to run two Redis instances to solve such a problem.</p><p>It is also worth to note that setting an expire to a key costs memory, so using a policy like <strong>allkeys-lru</strong> is more memory efficient since there is no need to set an expire for the key to be evicted under memory pressure.</p>","link":"./alpha/topics/lru-cache.html","spaLink":"#/alpha/topics/lru-cache","title":"EVICTION POLICIES"},{"content":"<h2 id=\"using-redis-as-an-lru-cache-how-the-eviction-process-works\">How the eviction process works</h2><p>It is important to understand that the eviction process works like this:</p><ul>\n<li>A client runs a new command, resulting in more data added.</li>\n<li>Redis checks the memory usage, and if it is greater than the <code>maxmemory</code> limit , it evicts keys according to the policy.</li>\n<li>A new command is executed, and so forth.</li>\n</ul><p>So we continuously cross the boundaries of the memory limit, by going over it, and then by evicting keys to return back under the limits.</p><p>If a command results in a lot of memory being used (like a big set intersection stored into a new key) for some time the memory limit can be surpassed by a noticeable amount.</p>","link":"./alpha/topics/lru-cache.html","spaLink":"#/alpha/topics/lru-cache","title":"HOW THE EVICTION PROCESS WORKS"},{"content":"<h2 id=\"using-redis-as-an-lru-cache-approximated-lru-algorithm\">Approximated LRU algorithm</h2><p>Redis LRU algorithm is not an exact implementation. This means that Redis is\nnot able to pick the <em>best candidate</em> for eviction, that is, the access that\nwas accessed the most in the past. Instead it will try to run an approximation\nof the LRU algorithm, by sampling a small number of keys, and evicting the\none that is the best (with the oldest access time) among the sampled keys.</p><p>However since Redis 3.0 the algorithm was improved to also take a pool of good\ncandidates for eviction. This improved the performance of the algorithm, making\nit able to approximate more closely the behavior of a real LRU algorithm.</p><p>What is important about the Redis LRU algorithm is that you <strong>are able to tune</strong> the precision of the algorithm by changing the number of samples to check for every eviction. This parameter is controlled by the following configuration directive:</p><p>The reason why Redis does not use a true LRU implementation is because it\ncosts more memory. However the approximation is virtually equivalent for the\napplication using Redis. The following is a graphical comparison of how\nthe LRU approximation used by Redis compares with true LRU.</p><p><img src=\"http://redis.io/images/redisdoc/lru_comparison.png\" alt=\"LRU comparison\"></p><p>The test to generate the above graphs filled a Redis server with a given number of keys. The keys were accessed from the first to the last, so that the first keys are the best candidates for eviction using an LRU algorithm. Later more 50% of keys are added, in order to force half of the old keys to be evicted.</p><p>You can see three kind of dots in the graphs, forming three distinct bands.</p><ul>\n<li>The light gray band are objects that were evicted.</li>\n<li>The gray band are objects that were not evicted.</li>\n<li>The green band are objects that were added.</li>\n</ul><p>In a theoretical LRU implementation we expect that, among the old keys, the first half will be expired. The Redis LRU algorithm will instead only <em>probabilistically</em> expire the older keys.</p><p>As you can see Redis 3.0 does a better job with 5 samples compared to Redis 2.8, however most objects that are among the latest accessed are still retained by Redis 2.8. Using a sample size of 10 in Redis 3.0 the approximation is very close to the theoretical performance of Redis 3.0.</p><p>Note that LRU is just a model to predict how likely a given key will be accessed in the future. Moreover, if your data access pattern closely\nresembles the power law, most of the accesses will be in the set of keys that\nthe LRU approximated algorithm will be able to handle well.</p><p>In simulations we found that using a power law access pattern, the difference between true LRU and Redis approximation were minimal or non-existent.</p><p>However you can raise the sample size to 10 at the cost of some additional CPU\nusage in order to closely approximate true LRU, and check if this makes a\ndifference in your cache misses rate.</p><p>To experiment in production with different values for the sample size by using\nthe <code>CONFIG SET maxmemory-samples &lt;count&gt;</code> command, is very simple.</p>","link":"./alpha/topics/lru-cache.html","spaLink":"#/alpha/topics/lru-cache","title":"APPROXIMATED LRU ALGORITHM"},{"content":"<h1 id=\"redis-debugging-guide\">Redis debugging guide</h1><p>Redis is developed with a great stress on stability: we do our best with\nevery release to make sure you’ll experience a very stable product and no\ncrashes. However even with our best efforts it is impossible to avoid all\nthe critical bugs with 100% of success.</p><p>When Redis crashes it produces a detailed report of what happened, however\nsometimes looking at the crash report is not enough, nor it is possible for\nthe Redis core team to reproduce the issue independently: in this scenario we\nneed help from the user that is able to reproduce the issue.</p><p>This little guide shows how to use GDB to provide all the information the\nRedis developers will need to track the bug more easily.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"REDIS DEBUGGING GUIDE"},{"content":"<h2 id=\"redis-debugging-guide-what-is-gdb\">What is GDB?</h2><p>GDB is the Gnu Debugger: a program that is able to inspect the internal state\nof another program. Usually tracking and fixing a bug is an exercise in\ngathering more information about the state of the program at the moment the\nbug happens, so GDB is an extremely useful tool.</p><p>GDB can be used in two ways:</p><ul>\n<li>It can attach to a running program and inspect the state of it at runtime.</li>\n<li>It can inspect the state of a program that already terminated using what is called a <em>core file</em>, that is, the image of the memory at the time the program was running.</li>\n</ul><p>From the point of view of investigating Redis bugs we need to use both this\nGDB modes: the user able to reproduce the bug attaches GDB to his running Redis instance, and when the crash happens, he creates the <code>core</code> file that the in turn the developer will use to inspect the Redis internals at the time of the crash.</p><p>This way the developer can perform all the inspections in his computer without the help of the user, and the user is free to restart Redis in the production environment.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"WHAT IS GDB?"},{"content":"<h2 id=\"redis-debugging-guide-compiling-redis-without-optimizations\">Compiling Redis without optimizations</h2><p>By default Redis is compiled with the <code>-O2</code> switch, this means that compiler\noptimizations are enabled. This makes the Redis executable faster, but at the\nsame time it makes Redis (like any other program) harder to inspect using GDB.</p><p>It is better to attach GDB to Redis compiled without optimizations using the\n<code>make noopt</code> command to compile it (instead of just using the plain <code>make</code>\ncommand). However if you have an already running Redis in production there is\nno need to recompile and restart it if this is going to create problems on\nyour side. Even if by a lesser extent GDB still works against executables\ncompiled with optimizations.</p><p>It is great if you make sure to recompile Redis with <code>make noopt</code> after the\nfirst crash, so that the next time it will be simpler to track the issue.</p><p>You should not be concerned with the loss of performances compiling Redis\nwithout optimizations, it is very unlikely that this will cause problems in\nyour environment since it is usually just a matter of a small percentage\nbecause Redis is not very CPU-bound (it does a lot of I/O to serve queries).</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"COMPILING REDIS WITHOUT OPTIMIZATIONS"},{"content":"<h2 id=\"redis-debugging-guide-attaching-gdb-to-a-running-process\">Attaching GDB to a running process</h2><p>If you have an already running Redis server, you can attach GDB to it, so that\nif Redis will crash it will be possible to both inspect the internals and\ngenerate a <code>core dump</code> file.</p><p>After you attach GDB to the Redis process it will continue running as usually without any loss of performance, so this is not a dangerous procedure.</p><p>In order to attach GDB the first thing you need is the <em>process ID</em> of the running Redis instance (the <em>pid</em> of the process). You can easily obtain it using <code>redis-cli</code>:</p><p>In the above example the process ID is <strong>58414</strong>.</p><ul>\n<li>Login into your Redis server.</li>\n<li>(Optional but recommended) Start <strong>screen</strong> or <strong>tmux</strong> or any other program that will make sure that your GDB session will not be closed if your ssh connection will timeout. If you don’t know what screen is do yourself a favor and <a href=\"http://www.linuxjournal.com/article/6340\">Read this article</a></li>\n<li><p>Attach GDB to the running Redis server typing:</p>\n<p>  gdb <code>&lt;path-to-redis-executable&gt;</code> <code>&lt;pid&gt;</code></p>\n<p>  For example: gdb /usr/local/bin/redis-server 58414</p>\n</li>\n</ul><p>Attach GDB to the running Redis server typing:</p><p>  gdb <code>&lt;path-to-redis-executable&gt;</code> <code>&lt;pid&gt;</code></p><p>  For example: gdb /usr/local/bin/redis-server 58414</p><p>GDB will start and will attach to the running server printing something like the following:</p><ul>\n<li><p>At this point GDB is attached but <strong>your Redis instance is blocked by GDB</strong>. In order to let the Redis instance continue the execution just type <strong>continue</strong> at the GDB prompt, and press enter.</p>\n<pre><code class=\"prettyprint prettyprinted\" style=\"\"><span class=\"pln\">  </span><span class=\"pun\">(</span><span class=\"pln\">gdb</span><span class=\"pun\">)</span><span class=\"pln\"> </span><span class=\"kwd\">continue</span><span class=\"pln\">\n  </span><span class=\"typ\">Continuing</span><span class=\"pun\">.</span></code></pre>\n</li>\n<li><p>Done! Now your Redis instance has GDB attached. You can wait for… the next crash :)</p>\n</li>\n<li>Now it’s time to detach your screen / tmux session, if you are running GDB using it, pressing the usual <strong>Ctrl-a a</strong> key combination.</li>\n</ul><p>At this point GDB is attached but <strong>your Redis instance is blocked by GDB</strong>. In order to let the Redis instance continue the execution just type <strong>continue</strong> at the GDB prompt, and press enter.</p><p>Done! Now your Redis instance has GDB attached. You can wait for… the next crash :)</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"ATTACHING GDB TO A RUNNING PROCESS"},{"content":"<h2 id=\"redis-debugging-guide-after-the-crash\">After the crash</h2><p>Redis has a command to simulate a segmentation fault (in other words a bad\ncrash) using the <code>DEBUG SEGFAULT</code> command (don’t use it against a real production instance of course ;). So I’ll use this command to crash my instance to show what happens in the GDB side:</p><p>As you can see GDB detected that Redis crashed, and was able to show me\neven the file name and line number causing the crash. This is already much\nbetter than the Redis crash report back trace (containing just function\nnames and binary offsets).</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"AFTER THE CRASH"},{"content":"<h2 id=\"redis-debugging-guide-obtaining-the-stack-trace\">Obtaining the stack trace</h2><p>The first thing to do is to obtain a full stack trace with GDB. This is as\nsimple as using the <strong>bt</strong> command: (that is a short for backtrace):</p><p>This shows the backtrace, but we also want to dump the processor registers using the <strong>info registers</strong> command:</p><p>Please <strong>make sure to include</strong> both this outputs in your bug report.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"OBTAINING THE STACK TRACE"},{"content":"<h2 id=\"redis-debugging-guide-obtaining-the-core-file\">Obtaining the core file</h2><p>The next step is to generate the core dump, that is the image of the memory of the running Redis process. This is performed using the <code>gcore</code> command:</p><p>Now you have the core dump to send to the Redis developer, but <strong>it is important to understand</strong> that this happens to contain all the data that was inside the Redis instance at the time of the crash: Redis developers will make sure to don’t share the content with any other, and will delete the file as soon as it is no longer used for debugging purposes, but you are warned that sending the core file you are sending your data.</p><p>If there are sensible stuff in the data set we suggest sending the dump directly to Salvatore Sanfilippo (that is the guy writing this doc) at the email address <strong>antirez at gmail dot com</strong>.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"OBTAINING THE CORE FILE"},{"content":"<h2 id=\"redis-debugging-guide-what-to-send-to-developers\">What to send to developers</h2><p>Finally you can send everything to the Redis core team:</p><ul>\n<li>The Redis executable you are using.</li>\n<li>The stack trace produced by the <strong>bt</strong> command, and the registers dump.</li>\n<li>The core file you generated with gdb.</li>\n<li>Information about the operating system and GCC version, and Redis version you are using.</li>\n</ul>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"WHAT TO SEND TO DEVELOPERS"},{"content":"<h2 id=\"redis-debugging-guide-thank-you\">Thank you</h2><p>Your help is extremely important! Many issues can only be tracked this way, thanks! It is also possible that helping Redis debugging you’ll be among the winners of the next <a href=\"http://antirez.com/post/redis-moka-awards-2011.html\">Redis Moka Award</a>.</p>","link":"./alpha/topics/debugging.html","spaLink":"#/alpha/topics/debugging","title":"THANK YOU"},{"content":"<h1 id=\"guidelines-for-redis-clients-with-support-for-redis-sentinel\">Guidelines for Redis clients with support for Redis Sentinel</h1><p>Redis Sentinel is a monitoring solution for Redis instances that handles\nautomatic failover of Redis masters and service discovery (who is the current\nmaster for a given group of instances?). Since Sentinel is both responsible\nto reconfigure instances during failovers, and to provide configurations to\nclients connecting to Redis masters or slaves, clients require to have\nexplicit support for Redis Sentinel.</p><p>This document is targeted at Redis clients developers that want to support Sentinel in their clients implementation with the following goals:</p><ul>\n<li>Automatic configuration of clients via Sentinel.</li>\n<li>Improved safety of Redis Sentinel automatic failover.</li>\n</ul><p>For details about how Redis Sentinel works, please check the <a href=\"/topics/sentinel\">Redis Documentation</a>, as this document only contains information needed for Redis client developers, and it is expected that readers are familiar with the way Redis Sentinel works.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"GUIDELINES FOR REDIS CLIENTS WITH SUPPORT FOR REDIS SENTINEL"},{"content":"<h1 id=\"redis-service-discovery-via-sentinel\">Redis service discovery via Sentinel</h1><p>Redis Sentinel identify every master with a name like “stats” or “cache”.\nEvery name actually identifies a <em>group of instances</em>, composed of a master\nand a variable number of slaves.</p><p>The address of the Redis master that is used for a specific purpose inside a network may change after events like an automatic failover, a manually triggered failover (for instance in order to upgrade a Redis instance), and other reasons.</p><p>Normally Redis clients have some kind of hard-coded configuration that specifies the address of a Redis master instance within a network as IP address and port number. However if the master address changes, manual intervention in every client is needed.</p><p>A Redis client supporting Sentinel can automatically discover the address of a Redis master from the master name using Redis Sentinel. So instead of a hard coded IP address and port, a client supporting Sentinel should optionally be able to take as input:</p><ul>\n<li>A list of ip:port pairs pointing to known Sentinel instances.</li>\n<li>The name of the service, like “cache” or “timelines”.</li>\n</ul><p>This is the procedure a client should follow in order to obtain the master address starting from the list of Sentinels and the service name.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"REDIS SERVICE DISCOVERY VIA SENTINEL"},{"content":"<h2 id=\"redis-service-discovery-via-sentinel-step-1-connecting-to-the-first-sentinel\">Step 1: connecting to the first Sentinel</h2><p>The client should iterate the list of Sentinel addresses. For every address it should try to connect to the Sentinel, using a short timeout (in the order of a few hundreds of milliseconds). On errors or timeouts the next Sentinel address should be tried.</p><p>If all the Sentinel addresses were tried without success, an error should be returned to the client.</p><p>The first Sentinel replying to the client request should be put at the start of the list, so that at the next reconnection, we’ll try first the Sentinel that was reachable in the previous connection attempt, minimizing latency.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"STEP 1: CONNECTING TO THE FIRST SENTINEL"},{"content":"<h2 id=\"redis-service-discovery-via-sentinel-step-2-ask-for-master-address\">Step 2: ask for master address</h2><p>Once a connection with a Sentinel is established, the client should retry to execute the following command on the Sentinel:</p><p>Where <em>master-name</em> should be replaced with the actual service name specified by the user.</p><p>The result from this call can be one of the following two replies:</p><ul>\n<li>An ip:port pair.</li>\n<li>A null reply. This means Sentinel does not know this master.</li>\n</ul><p>If an ip:port pair is received, this address should be used to connect to the Redis master. Otherwise if a null reply is received, the client should try the next Sentinel in the list.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"STEP 2: ASK FOR MASTER ADDRESS"},{"content":"<h2 id=\"redis-service-discovery-via-sentinel-step-3-call-the-role-command-in-the-target-instance\">Step 3: call the ROLE command in the target instance</h2><p>Once the client discovered the address of the master instance, it should\nattempt a connection with the master, and call the <code>ROLE</code> command in order\nto verify the role of the instance is actually a master.</p><p>If the <code>ROLE</code> commands is not available (it was introduced in Redis 2.8.12), a client may resort to the <code>INFO replication</code> command parsing the <code>role:</code> field of the output.</p><p>If the instance is not a master as expected, the client should wait a short amount of time (a few hundreds of milliseconds) and should try again starting from Step 1.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"STEP 3: CALL THE ROLE COMMAND IN THE TARGET INSTANCE"},{"content":"<h1 id=\"handling-reconnections\">Handling reconnections</h1><p>Once the service name is resolved into the master address and a connection is established with the Redis master instance, every time a reconnection is needed, the client should resolve again the address using Sentinels restarting from Step 1. For instance Sentinel should contacted again the following cases:</p><ul>\n<li>If the client reconnects after a timeout or socket error.</li>\n<li>If the client reconnects because it was explicitly closed or reconnected by the user.</li>\n</ul><p>In the above cases and any other case where the client lost the connection with the Redis server, the client should resolve the master address again.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"HANDLING RECONNECTIONS"},{"content":"<h1 id=\"sentinel-failover-disconnection\">Sentinel failover disconnection</h1><p>Starting with Redis 2.8.12, when Redis Sentinel changes the configuration of\nan instance, for example promoting a slave to a master, demoting a master to\nreplicate to the new master after a failover, or simply changing the master\naddress of a stale slave instance, it sends a <code>CLIENT KILL type normal</code>\ncommand to the instance in order to make sure all the clients are disconnected\nfrom the reconfigured instance. This will force clients to resolve the master\naddress again.</p><p>If the client will contact a Sentinel with yet not updated information, the verification of the Redis instance role via the <code>ROLE</code> command will fail, allowing the client to detect that the contacted Sentinel provided stale information, and will try again.</p><p>Note: it is possible that a stale master returns online at the same time a client contacts a stale Sentinel instance, so the client may connect with a stale master, and yet the ROLE output will match. However when the master is back again Sentinel will try to demote it to slave, triggering a new disconnection. The same reasoning applies to connecting to stale slaves that will get reconfigured to replicate with a different master.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"SENTINEL FAILOVER DISCONNECTION"},{"content":"<h1 id=\"connecting-to-slaves\">Connecting to slaves</h1><p>Sometimes clients are interested to connect to slaves, for example in order to scale read requests. This protocol supports connecting to slaves by modifying step 2 slightly. Instead of calling the following command:</p><p>The clients should call instead:</p><p>In order to retrieve a list of slave instances.</p><p>Symmetrically the client should verify with the <code>ROLE</code> command that the\ninstance is actually a slave, in order to avoid scaling read queries with\nthe master.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"CONNECTING TO SLAVES"},{"content":"<h1 id=\"connection-pools\">Connection pools</h1><p>For clients implementing connection pools, on reconnection of a single connection, the Sentinel should be contacted again, and in case of a master address change all the existing connections should be closed and connected to the new address.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"CONNECTION POOLS"},{"content":"<h1 id=\"error-reporting\">Error reporting</h1><p>The client should correctly return the information to the user in case of errors. Specifically:</p><ul>\n<li>If no Sentinel can be contacted (so that the client was never able to get the reply to <code>SENTINEL get-master-addr-by-name</code>), an error that clearly states that Redis Sentinel is unreachable should be returned.</li>\n<li>If all the Sentinels in the pool replied with a null reply, the user should be informed with an error that Sentinels don’t know this master name.</li>\n</ul>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"ERROR REPORTING"},{"content":"<h1 id=\"sentinels-list-automatic-refresh\">Sentinels list automatic refresh</h1><p>Optionally once a successful reply to <code>get-master-addr-by-name</code> is received, a client may update its internal list of Sentinel nodes following this procedure:</p><ul>\n<li>Obtain a list of other Sentinels for this master using the command <code>SENTINEL sentinels &lt;master-name&gt;</code>.</li>\n<li>Add every ip:port pair not already existing in our list at the end of the list.</li>\n</ul><p>It is not needed for a client to be able to make the list persistent updating its own configuration. The ability to upgrade the in-memory representation of the list of Sentinels can be already useful to improve reliability.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"SENTINELS LIST AUTOMATIC REFRESH"},{"content":"<h1 id=\"subscribe-to-sentinel-events-to-improve-responsiveness\">Subscribe to Sentinel events to improve responsiveness</h1><p>The <a href=\"/topics/sentinel\">Sentinel documentation</a> shows how clients can connect to\nSentinel instances using Pub/Sub in order to subscribe to changes in the\nRedis instances configurations.</p><p>This mechanism can be used in order to speedup the reconfiguration of clients,\nthat is, clients may listen to Pub/Sub in order to know when a configuration\nchange happened in order to run the three steps protocol explained in this\ndocument in order to resolve the new Redis master (or slave) address.</p><p>However update messages received via Pub/Sub should not substitute the\nabove procedure, since there is no guarantee that a client is able to\nreceive all the update messages.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"SUBSCRIBE TO SENTINEL EVENTS TO IMPROVE RESPONSIVENESS"},{"content":"<h1 id=\"additional-information\">Additional information</h1><p>For additional information or to discuss specific aspects of this guidelines, please drop a message to the <a href=\"https://groups.google.com/group/redis-db\">Redis Google Group</a>.</p>","link":"./alpha/topics/sentinel-clients.html","spaLink":"#/alpha/topics/sentinel-clients","title":"ADDITIONAL INFORMATION"},{"content":"<h1 id=\"how-fast-is-redis\">How fast is Redis?</h1><p>Redis includes the <code>redis-benchmark</code> utility that simulates running commands done\nby N clients at the same time sending M total queries (it is similar to the\nApache’s <code>ab</code> utility). Below you’ll find the full output of a benchmark executed\nagainst a Linux box.</p><p>The following options are supported:</p><p>You need to have a running Redis instance before launching the benchmark.\nA typical example would be:</p><p>Using this tool is quite easy, and you can also write your own benchmark,\nbut as with any benchmarking activity, there are some pitfalls to avoid.</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"HOW FAST IS REDIS?"},{"content":"<h2 id=\"how-fast-is-redis-running-only-a-subset-of-the-tests\">Running only a subset of the tests</h2><p>You don’t need to run all the default tests every time you execute redis-benchmark.\nThe simplest thing to select only a subset of tests is to use the <code>-t</code> option\nlike in the following example:</p><p>In the above example we asked to just run test the SET and LPUSH commands,\nin quiet mode (see the <code>-q</code> switch).</p><p>It is also possible to specify the command to benchmark directly like in the\nfollowing example:</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"RUNNING ONLY A SUBSET OF THE TESTS"},{"content":"<h2 id=\"how-fast-is-redis-selecting-the-size-of-the-key-space\">Selecting the size of the key space</h2><p>By default the benchmark runs against a single key. In Redis the difference\nbetween such a synthetic benchmark and a real one is not huge since it is an\nin-memory system, however it is possible to stress cache misses and in general\nto simulate a more real-world work load by using a large key space.</p><p>This is obtained by using the <code>-r</code> switch. For instance if I want to run\none million SET operations, using a random key for every operation out of\n100k possible keys, I’ll use the following command line:</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"SELECTING THE SIZE OF THE KEY SPACE"},{"content":"<h2 id=\"how-fast-is-redis-using-pipelining\">Using pipelining</h2><p>By default every client (the benchmark simulates 50 clients if not otherwise\nspecified with <code>-c</code>) sends the next command only when the reply of the previous\ncommand is received, this means that the server will likely need a read call\nin order to read each command from every client. Also RTT is paid as well.</p><p>Redis supports <a href=\"pipelining\">/topics/pipelining</a>, so it is possible to send\nmultiple commands at once, a feature often exploited by real world applications.\nRedis pipelining is able to dramatically improve the number of operations per\nsecond a server is able do deliver.</p><p>This is an example of running the benchmark in a MacBook Air 11” using a\npipelining of 16 commands:</p><p>Using pipelining results in a significant increase in performance.</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"USING PIPELINING"},{"content":"<h2 id=\"how-fast-is-redis-pitfalls-and-misconceptions\">Pitfalls and misconceptions</h2><p>The first point is obvious: the golden rule of a useful benchmark is to\nonly compare apples and apples. Different versions of Redis can be compared\non the same workload for instance. Or the same version of Redis, but with\ndifferent options. If you plan to compare Redis to something else, then it is\nimportant to evaluate the functional and technical differences, and take them\nin account.</p><ul>\n<li>Redis is a server: all commands involve network or IPC round trips. It is\nmeaningless to compare it to embedded data stores such as SQLite, Berkeley DB,\nTokyo/Kyoto Cabinet, etc … because the cost of most operations is\nprimarily in network/protocol management.</li>\n<li>Redis commands return an acknowledgment for all usual commands. Some other\ndata stores do not (for instance MongoDB does not implicitly acknowledge write\noperations). Comparing Redis to stores involving one-way queries is only\nmildly useful.</li>\n<li>Naively iterating on synchronous Redis commands does not benchmark Redis\nitself, but rather measure your network (or IPC) latency. To really test Redis,\nyou need multiple connections (like redis-benchmark) and/or to use pipelining\nto aggregate several commands and/or multiple threads or processes.</li>\n<li>Redis is an in-memory data store with some optional persistence options. If\nyou plan to compare it to transactional servers (MySQL, PostgreSQL, etc …),\nthen you should consider activating AOF and decide on a suitable fsync policy.</li>\n<li>Redis is a single-threaded server. It is not designed to benefit from\nmultiple CPU cores. People are supposed to launch several Redis instances to\nscale out on several cores if needed. It is not really fair to compare one\nsingle Redis instance to a multi-threaded data store.</li>\n</ul><p>A common misconception is that redis-benchmark is designed to make Redis\nperformances look stellar, the throughput achieved by redis-benchmark being\nsomewhat artificial, and not achievable by a real application. This is\nactually plain wrong.</p><p>The redis-benchmark program is a quick and useful way to get some figures and\nevaluate the performance of a Redis instance on a given hardware. However,\nby default, it does not represent the maximum throughput a Redis instance can\nsustain. Actually, by using pipelining and a fast client (hiredis), it is fairly\neasy to write a program generating more throughput than redis-benchmark. The\ndefault behavior of redis-benchmark is to achieve throughput by exploiting\nconcurrency only (i.e. it creates several connections to the server).\nIt does not use pipelining or any parallelism at all (one pending query per\nconnection at most, and no multi-threading).</p><p>To run a benchmark using pipelining mode (and achieve higher throughput),\nyou need to explicitly use the -P option. Please note that it is still a\nrealistic behavior since a lot of Redis based applications actively use\npipelining to improve performance.</p><p>Finally, the benchmark should apply the same operations, and work in the same way\nwith the multiple data stores you want to compare. It is absolutely pointless to\ncompare the result of redis-benchmark to the result of another benchmark\nprogram and extrapolate.</p><p>For instance, Redis and memcached in single-threaded mode can be compared on\nGET/SET operations. Both are in-memory data stores, working mostly in the same\nway at the protocol level. Provided their respective benchmark application is\naggregating queries in the same way (pipelining) and use a similar number of\nconnections, the comparison is actually meaningful.</p><p>This perfect example is illustrated by the dialog between Redis (antirez) and\nmemcached (dormando) developers.</p><p><a href=\"http://antirez.com/post/redis-memcached-benchmark.html\">antirez 1 - On Redis, Memcached, Speed, Benchmarks and The Toilet</a></p><p><a href=\"http://dormando.livejournal.com/525147.html\">dormando - Redis VS Memcached (slightly better bench)</a></p><p><a href=\"http://antirez.com/post/update-on-memcached-redis-benchmark.html\">antirez 2 - An update on the Memcached/Redis benchmark</a></p><p>You can see that in the end, the difference between the two solutions is not\nso staggering, once all technical aspects are considered. Please note both\nRedis and memcached have been optimized further after these benchmarks.</p><p>Finally, when very efficient servers are benchmarked (and stores like Redis\nor memcached definitely fall in this category), it may be difficult to saturate\nthe server. Sometimes, the performance bottleneck is on client side,\nand not server-side. In that case, the client (i.e. the benchmark program itself)\nmust be fixed, or perhaps scaled out, in order to reach the maximum throughput.</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"PITFALLS AND MISCONCEPTIONS"},{"content":"<h2 id=\"how-fast-is-redis-factors-impacting-redis-performance\">Factors impacting Redis performance</h2><p>There are multiple factors having direct consequences on Redis performance.\nWe mention them here, since they can alter the result of any benchmarks.\nPlease note however, that a typical Redis instance running on a low end,\nuntuned box usually provides good enough performance for most applications.</p><ul>\n<li>Network bandwidth and latency usually have a direct impact on the performance.\nIt is a good practice to use the ping program to quickly check the latency\nbetween the client and server hosts is normal before launching the benchmark.\nRegarding the bandwidth, it is generally useful to estimate\nthe throughput in Gbit/s and compare it to the theoretical bandwidth\nof the network. For instance a benchmark setting 4 KB strings\nin Redis at 100000 q/s, would actually consume 3.2 Gbit/s of bandwidth\nand probably fit within a 10 Gbit/s link, but not a 1 Gbit/s one. In many real\nworld scenarios, Redis throughput is limited by the network well before being\nlimited by the CPU. To consolidate several high-throughput Redis instances\non a single server, it worth considering putting a 10 Gbit/s NIC\nor multiple 1 Gbit/s NICs with TCP/IP bonding.</li>\n<li>CPU is another very important factor. Being single-threaded, Redis favors\nfast CPUs with large caches and not many cores. At this game, Intel CPUs are\ncurrently the winners. It is not uncommon to get only half the performance on\nan AMD Opteron CPU compared to similar Nehalem EP/Westmere EP/Sandy Bridge\nIntel CPUs with Redis. When client and server run on the same box, the CPU is\nthe limiting factor with redis-benchmark.</li>\n<li>Speed of RAM and memory bandwidth seem less critical for global performance\nespecially for small objects. For large objects (&gt;10 KB), it may become\nnoticeable though. Usually, it is not really cost-effective to buy expensive\nfast memory modules to optimize Redis.</li>\n<li>Redis runs slower on a VM compared to running without virtualization using\nthe same hardware. If you have the chance to run Redis on a physical machine\nthis is preferred. However this does not mean that Redis is slow in\nvirtualized environments, the delivered performances are still very good\nand most of the serious performance issues you may incur in virtualized\nenvironments are due to over-provisioning, non-local disks with high latency,\nor old hypervisor software that have slow <code>fork</code> syscall implementation.</li>\n<li>When the server and client benchmark programs run on the same box, both\nthe TCP/IP loopback and unix domain sockets can be used. Depending on the\nplatform, unix domain sockets can achieve around 50% more throughput than\nthe TCP/IP loopback (on Linux for instance). The default behavior of\nredis-benchmark is to use the TCP/IP loopback.</li>\n<li>The performance benefit of unix domain sockets compared to TCP/IP loopback\ntends to decrease when pipelining is heavily used (i.e. long pipelines).</li>\n<li>When an ethernet network is used to access Redis, aggregating commands using\npipelining is especially efficient when the size of the data is kept under\nthe ethernet packet size (about 1500 bytes). Actually, processing 10 bytes,\n100 bytes, or 1000 bytes queries almost result in the same throughput.\nSee the graph below.</li>\n</ul><p><img src=\"https://github.com/dspezia/redis-doc/raw/client_command/topics/Data_size.png\" alt=\"Data size impact\"></p><ul>\n<li>On multi CPU sockets servers, Redis performance becomes dependent on the\nNUMA configuration and process location. The most visible effect is that\nredis-benchmark results seem non-deterministic because client and server\nprocesses are distributed randomly on the cores. To get deterministic results,\nit is required to use process placement tools (on Linux: taskset or numactl).\nThe most efficient combination is always to put the client and server on two\ndifferent cores of the same CPU to benefit from the L3 cache.\nHere are some results of 4 KB SET benchmark for 3 server CPUs (AMD Istanbul,\nIntel Nehalem EX, and Intel Westmere) with different relative placements.\nPlease note this benchmark is not meant to compare CPU models between themselves\n(CPUs exact model and frequency are therefore not disclosed).</li>\n</ul><p><img src=\"https://github.com/dspezia/redis-doc/raw/6374a07f93e867353e5e946c1e39a573dfc83f6c/topics/NUMA_chart.gif\" alt=\"NUMA chart\"></p><ul>\n<li>With high-end configurations, the number of client connections is also an\nimportant factor. Being based on epoll/kqueue, the Redis event loop is quite\nscalable. Redis has already been benchmarked at more than 60000 connections,\nand was still able to sustain 50000 q/s in these conditions. As a rule of thumb,\nan instance with 30000 connections can only process half the throughput\nachievable with 100 connections. Here is an example showing the throughput of\na Redis instance per number of connections:</li>\n</ul><p><img src=\"https://github.com/dspezia/redis-doc/raw/system_info/topics/Connections_chart.png\" alt=\"connections chart\"></p><ul>\n<li>With high-end configurations, it is possible to achieve higher throughput by\ntuning the NIC(s) configuration and associated interruptions. Best throughput\nis achieved by setting an affinity between Rx/Tx NIC queues and CPU cores,\nand activating RPS (Receive Packet Steering) support. More information in this\n<a href=\"https://groups.google.com/forum/#!msg/redis-db/gUhc19gnYgc/BruTPCOroiMJ\">thread</a>.\nJumbo frames may also provide a performance boost when large objects are used.</li>\n<li>Depending on the platform, Redis can be compiled against different memory\nallocators (libc malloc, jemalloc, tcmalloc), which may have different behaviors\nin term of raw speed, internal and external fragmentation.\nIf you did not compile Redis yourself, you can use the INFO command to check\nthe mem_allocator field. Please note most benchmarks do not run long enough to\ngenerate significant external fragmentation (contrary to production Redis\ninstances).</li>\n</ul>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"FACTORS IMPACTING REDIS PERFORMANCE"},{"content":"<h2 id=\"how-fast-is-redis-other-things-to-consider\">Other things to consider</h2><p>One important goal of any benchmark is to get reproducible results, so they\ncan be compared to the results of other tests.</p><ul>\n<li>A good practice is to try to run tests on isolated hardware as much as possible.\nIf it is not possible, then the system must be monitored to check the benchmark\nis not impacted by some external activity.</li>\n<li>Some configurations (desktops and laptops for sure, some servers as well)\nhave a variable CPU core frequency mechanism. The policy controlling this\nmechanism can be set at the OS level. Some CPU models are more aggressive than\nothers at adapting the frequency of the CPU cores to the workload. To get\nreproducible results, it is better to set the highest possible fixed frequency\nfor all the CPU cores involved in the benchmark.</li>\n<li>An important point is to size the system accordingly to the benchmark.\nThe system must have enough RAM and must not swap. On Linux, do not forget\nto set the overcommit_memory parameter correctly. Please note 32 and 64 bit\nRedis instances do not have the same memory footprint.</li>\n<li>If you plan to use RDB or AOF for your benchmark, please check there is no other\nI/O activity in the system. Avoid putting RDB or AOF files on NAS or NFS shares,\nor on any other devices impacting your network bandwidth and/or latency\n(for instance, EBS on Amazon EC2).</li>\n<li>Set Redis logging level (loglevel parameter) to warning or notice. Avoid putting\nthe generated log file on a remote filesystem.</li>\n<li>Avoid using monitoring tools which can alter the result of the benchmark. For\ninstance using INFO at regular interval to gather statistics is probably fine,\nbut MONITOR will impact the measured performance significantly.</li>\n</ul>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"OTHER THINGS TO CONSIDER"},{"content":"<h1 id=\"benchmark-results-on-different-virtualized-and-bare-metal-servers\">Benchmark results on different virtualized and bare-metal servers.</h1><ul>\n<li>The test was done with 50 simultaneous clients performing 2 million requests.</li>\n<li>Redis 2.6.14 is used for all the tests.</li>\n<li>Test was executed using the loopback interface.</li>\n<li>Test was executed using a key space of 1 million keys.</li>\n<li>Test was executed with and without pipelining (16 commands pipeline).</li>\n</ul><p><strong>Intel(R) Xeon(R) CPU E5520  @ 2.27GHz (with pipelining)</strong></p><p><strong>Intel(R) Xeon(R) CPU E5520  @ 2.27GHz (without pipelining)</strong></p><p><strong>Linode 2048 instance (with pipelining)</strong></p><p><strong>Linode 2048 instance (without pipelining)</strong></p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"BENCHMARK RESULTS ON DIFFERENT VIRTUALIZED AND BARE-METAL SERVERS."},{"content":"<h2 id=\"benchmark-results-on-different-virtualized-and-bare-metal-servers-more-detailed-tests-without-pipelining\">More detailed tests without pipelining</h2><p>Notes: changing the payload from 256 to 1024 or 4096 bytes does not change the\nnumbers significantly (but reply packets are glued together up to 1024 bytes so\nGETs may be slower with big payloads). The same for the number of clients, from\n50 to 256 clients I got the same numbers. With only 10 clients it starts to get\na bit slower.</p><p>You can expect different results from different boxes. For example a low\nprofile box like <em>Intel core duo T5500 clocked at 1.66 GHz running Linux 2.6</em>\nwill output the following:</p><p>Another one using a 64-bit box, a Xeon L5420 clocked at 2.5 GHz:</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"MORE DETAILED TESTS WITHOUT PIPELINING"},{"content":"<h1 id=\"example-of-benchmark-results-with-optimized-high-end-server-hardware\">Example of benchmark results with optimized high-end server hardware</h1><ul>\n<li>Redis version <strong>2.4.2</strong></li>\n<li>Default number of connections, payload size = 256</li>\n<li>The Linux box is running <em>SLES10 SP3 2.6.16.60-0.54.5-smp</em>, CPU is 2 x <em>Intel X5670 @ 2.93 GHz</em>.</li>\n<li>Test executed while running Redis server and benchmark client on the same CPU, but different cores.</li>\n</ul><p>Using a unix domain socket:</p><p>Using the TCP loopback:</p>","link":"./alpha/topics/benchmarks.html","spaLink":"#/alpha/topics/benchmarks","title":"EXAMPLE OF BENCHMARK RESULTS WITH OPTIMIZED HIGH-END SERVER HARDWARE"},{"content":"<h1 id=\"redis-lua-scripts-debugger\">Redis Lua scripts debugger</h1><p>Starting with version 3.2 Redis includes a complete Lua debugger, that can be\nused in order to make the task of writing complex Redis scripts much simpler.</p><p>Because Redis 3.2 is still in beta, please download the <code>unstable</code> branch of Redis from Github and compile it in order to test the debugger. You can use Redis unstable in order to debug your scripts that you’ll later run in a stable version of Redis, so the debugger is already usable in practical terms.</p><p>The Redis Lua debugger, codename LDB, has the following important features:</p><ul>\n<li>It uses a server-client model, so it’s a remote debugger. The Redis server acts as the debugging server, while the default client is <code>redis-cli</code>. However other clients can be developed by following the simple protocol implemented by the server.</li>\n<li>By default every new debugging session is a forked session. It means that while the Redis Lua script is being debugged, the server does not block and is usable for development or in order to execute multiple debugging sessions in parallel. This also means that changes are <strong>rolled back</strong> after the script debugging session finished, so that’s possible to restart a new debugging session again, using exactly the same Redis data set as the previous debugging session.</li>\n<li>An alternative synchronous (non forked) debugging model is available on demand, so that changes to the dataset can be retained. In this mode the server blocks for the time the debugging session is active.</li>\n<li>Support for step by step execution.</li>\n<li>Support for static and dynamic breakpoints.</li>\n<li>Support from logging the debugged script into the debugger console.</li>\n<li>Inspection of Lua variables.</li>\n<li>Tracing of Redis commands executed by the script.</li>\n<li>Pretty printing of Redis and Lua values.</li>\n<li>Infinite loops and long execution detection, which simulates a breakpoint.</li>\n</ul>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"REDIS LUA SCRIPTS DEBUGGER"},{"content":"<h2 id=\"redis-lua-scripts-debugger-quick-start\">Quick start</h2><p>A simple way to get started with the Lua debugger is to watch this video\nintroduction:</p><p><strong>Important note:</strong> please make sure to avoid debugging Lua scripts using your Redis production server. Use a development server instead. Also note that using the synchronous debugging mode (which is NOT the default) results into the Redis server blocking for all the time the debugging session lasts.</p><p>To start a new debugging session using <code>redis-cli</code> do the following steps:</p><p>Start a debugging session with:</p><p> ./redis-cli —ldb —eval /tmp/script.lua</p><p>Note that with the <code>--eval</code> option of <code>redis-cli</code> you can pass key names and arguments to the script, separated by a comma, like in the following example:</p><p>You’ll enter a special mode where <code>redis-cli</code> no longer accepts its normal\ncommands, but instead prints an help screen and passes the unmodified debugging\ncommands directly to Redis.</p><p>The only commands which are not passed to the Redis debugger are:</p><ul>\n<li><code>quit</code> — this will terminate the debugging session. It’s like removing all the breakpoints and using the <code>continue</code> debugging command. Moreover the command will exit from <code>redis-cli</code>.</li>\n<li><code>restart</code> — the debugging session will restart from scratch, <strong>reloading the new version of the script from the file</strong>. So a normal debugging cycle involves modifying the script after some debugging, and calling <code>restart</code> in order to start debugging again with the new script changes.</li>\n<li><code>help</code> — this command is passed to the Redis Lua debugger, that will print a list of commands like the following:</li>\n</ul><p>Note that when you start the debugger it will start in <strong>stepping mode</strong>. It will stop at the first line of the script that actually does something before executing it.</p><p>From this point you usually call <code>step</code> in order to execute the line and go to the next line. While you step Redis will show all the commands executed by the server like in the following example:</p><p>The <code>&lt;redis&gt;</code> and <code>&lt;reply&gt;</code> lines show the command executed by the line just\nexecuted, and the reply from the server. Note that this happens only in stepping mode. If you use <code>continue</code> in order to execute the script till the next breakpoint, commands will not be dumped on the screen to prevent too much output.</p>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"QUICK START"},{"content":"<h2 id=\"redis-lua-scripts-debugger-termination-of-the-debugging-session\">Termination of the debugging session</h2><p>When the scripts terminates naturally, the debugging session ends and\n<code>redis-cli</code> returns in its normal non-debugging mode. You can restart the\nsession using the <code>restart</code> command as usually.</p><p>Another way to stop a debugging session is just interrupting <code>redis-cli</code>\nmanually by pressing <code>Ctrl+C</code>. Note that also any event breaking the\nconnection between <code>redis-cli</code> and the <code>redis-server</code> will interrupt the\ndebugging session.</p><p>All the forked debugging sessions are terminated when the server is shut\ndown.</p>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"TERMINATION OF THE DEBUGGING SESSION"},{"content":"<h2 id=\"redis-lua-scripts-debugger-abbreviating-debugging-commands\">Abbreviating debugging commands</h2><p>Debugging can be a very repetitive task. For this reason every Redis\ndebugger command starts with a different character, and you can use the single\ninitial character in order to refer to the command.</p><p>So for example instead of typing <code>step</code> you can just type <code>s</code>.</p>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"ABBREVIATING DEBUGGING COMMANDS"},{"content":"<h2 id=\"redis-lua-scripts-debugger-breakpoints\">Breakpoints</h2><p>Adding and removing breakpoints is trivial as described in the online help.\nJust use <code>b 1 2 3 4</code> to add a breakpoint in line 1, 2, 3, 4.\nThe command <code>b 0</code> removes all the breakpoints. Selected breakpoints can be\nremoved using as argument the line where the breakpoint we want to remove is, but prefixed by a minus sign. So for example <code>b -3</code> removes the breakpoint from line 3.</p><p>Note that adding breakpoints to lines that Lua never executes, like declaration of local variables or comments, will not work. The breakpoint will be added but since this part of the script will never be executed, the program will never stop.</p>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"BREAKPOINTS"},{"content":"<h2 id=\"redis-lua-scripts-debugger-dynamic-breakpoints\">Dynamic breakpoints</h2><p>Using the <code>breakpoint</code> command it is possible to add breakpoints into specific\nlines. However sometimes we want to stop the execution of the program only\nwhen something special happens. In order to do so, you can use the\n<code>redis.breakpoint()</code> function inside your Lua script. When called it simulates\na breakpoint in the next line that will be executed.</p><p>This feature is extremely useful when debugging, so that we can avoid to\ncontinue the script execution manually multiple times until a given condition\nis encountered.</p>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"DYNAMIC BREAKPOINTS"},{"content":"<h2 id=\"redis-lua-scripts-debugger-synchronous-mode\">Synchronous mode</h2><p>As explained previously, but default LDB uses forked sessions with rollback\nof all the data changes operated by the script while it has being debugged.\nDeterminism is usually a good thing to have during debugging, so that successive\ndebugging sessions can be started without having to reset the database content\nto its original state.</p><p>However for tracking certain bugs, you may want to retain the changes performed\nto the key space by each debugging session. When this is a good idea you\nshould start the debugger using a special option, <code>ldb-sync-mode</code>, in <code>redis-cli</code>.</p><p><strong>Note that the Redis server will be unreachable during the debugging session in this mode</strong>, so use with care.</p><p>In this special mode, the <code>abort</code> command can stop the script half-way taking the changes operated to the dataset. Note that this is different compared to ending the debugging session normally. If you just interrupt <code>redis-cli</code> the script will be fully executed and then the session terminated. Instead with <code>abort</code> you can interrupt the script execution in the middle and start a new debugging session if needed.</p>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"SYNCHRONOUS MODE"},{"content":"<h2 id=\"redis-lua-scripts-debugger-logging-from-scripts\">Logging from scripts</h2><p>The <code>redis.debug()</code> command is a powerful debugging facility that can be\ncalled inside the Redis Lua script in order to log things into the debug\nconsole:</p><p>If the script is executed outside of a debugging session, <code>redis.debug()</code> has no effects at all. Note that the function accepts multiple arguments, that are separated by a comma and a space in the output.</p><p>Tables and nested tables are displayed correctly in order to make values simple to observe for the programmer debugging the script.</p>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"LOGGING FROM SCRIPTS"},{"content":"<h2 id=\"redis-lua-scripts-debugger-inspecting-the-program-state-with-print-and-eval\">Inspecting the program state with <code>print</code> and <code>eval</code></h2><p>While the <code>redis.debug()</code> function can be used in order to print values\ndirectly from within the Lua script, often it is useful to observe the local\nvariables of a program while stepping or when stopped into a breakpoint.</p><p>The <code>print</code> command does just that, and performs lookup in the call frames\nstarting from the current one back to the previous ones, up to top-level.\nThis means that even if we are into a nested function inside a Lua script,\nwe can still use <code>print foo</code> to look at the value of <code>foo</code> in the context\nof the calling function. When called without a variable name, <code>print</code> will\nprint all variables and their respective values.</p><p>The <code>eval</code> command executes small pieces of Lua scripts <strong>outside the context of the current call frame</strong> (evaluating inside the context of the current call frame is not possible with the current Lua internals). However you can use this command in order to test Lua functions.</p>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"INSPECTING THE PROGRAM STATE WITH PRINT AND EVAL"},{"content":"<h2 id=\"redis-lua-scripts-debugger-debugging-clients\">Debugging clients</h2><p>LDB uses the client-server model where the Redis servers acts as a debugging server that communicates using <a href=\"/topics/protocol\">RESP</a>. While <code>redis-cli</code> is the default debug client, any <a href=\"/clients\">client</a> can be used for debugging as long as it meets one of the following conditions:</p><p>For example, the <a href=\"https://redislabs.com/blog/zerobrane-studio-plugin-for-redis-lua-scripts\">Redis plugin</a> for <a href=\"http://studio.zerobrane.com/\">ZeroBrane Studio</a> integrates with LDB using <a href=\"https://github.com/nrk/redis-lua\">redis-lua</a>. The following Lua code is a simplified example of how the plugin achieves that:</p>","link":"./alpha/topics/ldb.html","spaLink":"#/alpha/topics/ldb","title":"DEBUGGING CLIENTS"},{"content":"<h1 id=\"redis-latency-monitoring-framework\">Redis latency monitoring framework</h1><p>Redis is often used in the context of demanding use cases, where it\nserves a big amount of queries per second per instance, and at the same\ntime, there are very strict latency requirements both for the average response\ntime and for the worst case latency.</p><p>While Redis is an in memory system, it deals with the operating system in\ndifferent ways, for example, in the context of persisting to disk.\nMoreover Redis implements a rich set of commands. Certain commands\nare fast and run in constant or logarithmic time, other commands are slower\nO(N) commands, that can cause latency spikes.</p><p>Finally Redis is single threaded: this is usually an advantage\nfrom the point of view of the amount of work it can perform per core, and in\nthe latency figures it is able to provide, but at the same time it poses\na challenge from the point of view of latency, since the single\nthread must be able to perform certain tasks incrementally, like for\nexample keys expiration, in a way that does not impact the other clients\nthat are served.</p><p>For all these reasons, Redis 2.8.13 introduced a new feature called\n<strong>Latency Monitoring</strong>, that helps the user to check and troubleshoot possible\nlatency problems. Latency monitoring is composed of the following conceptual\nparts:</p><ul>\n<li>Latency hooks that sample different latency sensitive code paths.</li>\n<li>Time series recording of latency spikes split by different event.</li>\n<li>Reporting engine to fetch raw data from the time series.</li>\n<li>Analysis engine to provide human readable reports and hints according to the measurements.</li>\n</ul><p>The remaining part of this document covers the latency monitoring subsystem\ndetails, however for more information about the general topic of Redis\nand latency, please read the <a href=\"/topics/latency\">Redis latency problems troubleshooting</a> page in this documentation.</p>","link":"./alpha/topics/latency-monitor.html","spaLink":"#/alpha/topics/latency-monitor","title":"REDIS LATENCY MONITORING FRAMEWORK"},{"content":"<h2 id=\"redis-latency-monitoring-framework-events-and-time-series\">Events and time series</h2><p>Different monitored code paths have different names, and are called <em>events</em>.\nFor example <code>command</code> is an event measuring latency spikes of possibly slow\ncommands executions, while <code>fast-command</code> is the event name for the monitoring\nof the O(1) and O(log N) commands. Other events are less generic, and monitor\na very specific operation performed by Redis. For example the <code>fork</code> event\nonly monitors the time taken by Redis to execute the <code>fork(2)</code> system call.</p><p>A latency spike is an event that runs in more time than the configured latency\nthreshold. There is a separated time series associated with every monitored\nevent. This is how the time series work:</p><ul>\n<li>Every time a latency spike happens, it is logged in the appropriate time series.</li>\n<li>Every time series is composed of 160 elements.</li>\n<li>Each element is a pair: an unix timestamp of the time the latency spike was measured, and the number of milliseconds the event took to executed.</li>\n<li>Latency spikes for the same event happening in the same second are merged (by taking the maximum latency), so even if continuous latency spikes are measured for a given event, for example because the user set a very low threshold, at least 180 seconds of history are available.</li>\n<li>For every element the all-time maximum latency is recorded.</li>\n</ul>","link":"./alpha/topics/latency-monitor.html","spaLink":"#/alpha/topics/latency-monitor","title":"EVENTS AND TIME SERIES"},{"content":"<h2 id=\"redis-latency-monitoring-framework-how-to-enable-latency-monitoring\">How to enable latency monitoring</h2><p>What is high latency for an use case, is not high latency for another. There are applications where all the queries must be served in less than 1 millisecond and applications where from time to time a small percentage of clients experiencing a 2 seconds latency is acceptable.</p><p>So the first step to enable the latency monitor is to set a <strong>latency threshold</strong> in milliseconds. Only events that will take more than the specified threshold will be logged as latency spikes. The user should set the threshold according to its needs. For example if for the requirements of the application based on Redis the maximum acceptable latency is 100 milliseconds, the threshold should be set to such a value in order to log all the events blocking the server for a time equal or greater to 100 milliseconds.</p><p>The latency monitor can easily be enabled at runtime in a production server\nwith the following command:</p><p>By default monitoring is disabled (threshold set to 0), even if the actual cost of latency monitoring is near zero. However while the memory requirements of latency monitoring are very small, there is no good reason to raise the baseline memory usage of a Redis instance that is working well.</p>","link":"./alpha/topics/latency-monitor.html","spaLink":"#/alpha/topics/latency-monitor","title":"HOW TO ENABLE LATENCY MONITORING"},{"content":"<h2 id=\"redis-latency-monitoring-framework-information-reporting-with-the-latency-command\">Information reporting with the LATENCY command</h2><p>The user interface to the latency monitoring subsystem is the <code>LATENCY</code> command.\nLike many other Redis commands, <code>LATENCY</code> accept subcommands that modify the\nbehavior of the command. The next sections document each subcommand.</p>","link":"./alpha/topics/latency-monitor.html","spaLink":"#/alpha/topics/latency-monitor","title":"INFORMATION REPORTING WITH THE LATENCY COMMAND"},{"content":"<h2 id=\"redis-latency-monitoring-framework-latency-latest\">LATENCY LATEST</h2><p>The <code>LATENCY LATEST</code> command reports the latest latency events logged. Each event has the following fields:</p><ul>\n<li>Event name.</li>\n<li>Unix timestamp of the latest latency spike for the event.</li>\n<li>Latest event latency in millisecond.</li>\n<li>All time maximum latency for this event.</li>\n</ul><p>All time does not really mean the maximum latency since the Redis instance was\nstarted, because it is possible to reset events data using <code>LATENCY RESET</code> as we’ll see later.</p><p>The following is an example output:</p>","link":"./alpha/topics/latency-monitor.html","spaLink":"#/alpha/topics/latency-monitor","title":"LATENCY LATEST"},{"content":"<h2 id=\"redis-latency-monitoring-framework-latency-history-event-name\">LATENCY HISTORY <code>event-name</code></h2><p>The <code>LATENCY HISTORY</code> command is useful in order to fetch raw data from the\nevent time series, as timestamp-latency pairs. The command will return up\nto 160 elements for a given event. An application may want to fetch raw data\nin order to perform monitoring, display graphs, and so forth.</p><p>Example output:</p>","link":"./alpha/topics/latency-monitor.html","spaLink":"#/alpha/topics/latency-monitor","title":"LATENCY HISTORY EVENT-NAME"},{"content":"<h2 id=\"redis-latency-monitoring-framework-latency-reset-event-name-event-name\">LATENCY RESET [<code>event-name</code> … <code>event-name</code>]</h2><p>The <code>LATENCY RESET</code> command, if called without arguments, resets all the\nevents, discarding the currently logged latency spike events, and resetting\nthe maximum event time register.</p><p>It is possible to reset only specific events by providing the event names\nas arguments. The command returns the number of events time series that were\nreset during the command execution.</p>","link":"./alpha/topics/latency-monitor.html","spaLink":"#/alpha/topics/latency-monitor","title":"LATENCY RESET [EVENT-NAME … EVENT-NAME]"},{"content":"<h2 id=\"redis-latency-monitoring-framework-latency-graph-event-name\">LATENCY GRAPH <code>event-name</code></h2><p>Produces an ASCII-art style graph for the specified event:</p><p>The vertical labels under each graph column represent the amount of seconds,\nminutes, hours or days ago the event happened. For example “15s” means that the\nfirst graphed event happened 15 seconds ago.</p><p>The graph is normalized in the min-max scale so that the zero (the underscore\nin the lower row) is the minimum, and a # in the higher row is the maximum.</p><p>The graph subcommand is useful in order to get a quick idea about the trend\nof a given latency event without using additional tooling, and without the\nneed to interpret raw data as provided by <code>LATENCY HISTORY</code>.</p>","link":"./alpha/topics/latency-monitor.html","spaLink":"#/alpha/topics/latency-monitor","title":"LATENCY GRAPH EVENT-NAME"},{"content":"<h2 id=\"redis-latency-monitoring-framework-latency-doctor\">LATENCY DOCTOR</h2><p>The <code>LATENCY DOCTOR</code> command is the most powerful analysis tool in the latency\nmonitoring, and is able to provide additional statistical data like the average\nperiod between latency spikes, the median deviation, and an human readable\nanalysis of the event. For certain events, like <code>fork</code>, additional information\nis provided, like the rate at which the system forks processes.</p><p>This is the output you should post in the Redis mailing list if you are\nlooking for help about Latency related issues.</p><p>Example output:</p><p>The doctor has erratic psychological behaviors, so we recommend interacting with\nit carefully.</p>","link":"./alpha/topics/latency-monitor.html","spaLink":"#/alpha/topics/latency-monitor","title":"LATENCY DOCTOR"},{"content":"<h1 id=\"redis-persistence\">Redis Persistence</h1><p>Redis provides a different range of persistence options:</p><ul>\n<li>The RDB persistence performs point-in-time snapshots of your dataset at specified intervals.</li>\n<li>the AOF persistence logs every write operation received by the server, that will be played again at server startup, reconstructing the original dataset. Commands are logged using the same format as the Redis protocol itself, in an append-only fashion. Redis is able to rewrite the log on background when it gets too big.</li>\n<li>If you wish, you can disable persistence at all, if you want your data to just exist as long as the server is running.</li>\n<li>It is possible to combine both AOF and RDB in the same instance. Notice that, in this case, when Redis restarts the AOF file will be used to reconstruct the original dataset since it is guaranteed to be the most complete.</li>\n</ul><p>The most important thing to understand is the different trade-offs between the\nRDB and AOF persistence. Let’s start with RDB:</p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"REDIS PERSISTENCE"},{"content":"<h2 id=\"redis-persistence-rdb-advantages\">RDB advantages</h2><ul>\n<li>RDB is a very compact single-file point-in-time representation of your Redis data. RDB files are perfect for backups. For instance you may want to archive your RDB files every hour for the latest 24 hours, and to save an RDB snapshot every day for 30 days. This allows you to easily restore different versions of the data set in case of disasters.</li>\n<li>RDB is very good for disaster recovery, being a single compact file can be transferred to far data centers, or on Amazon S3 (possibly encrypted).</li>\n<li>RDB maximizes Redis performances since the only work the Redis parent process needs to do in order to persist is forking a child that will do all the rest. The parent instance will never perform disk I/O or alike.</li>\n<li>RDB allows faster restarts with big datasets compared to AOF.</li>\n</ul>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"RDB ADVANTAGES"},{"content":"<h2 id=\"redis-persistence-rdb-disadvantages\">RDB disadvantages</h2><ul>\n<li>RDB is NOT good if you need to minimize the chance of data loss in case Redis stops working (for example after a power outage). You can configure different <em>save points</em> where an RDB is produced (for instance after at least five minutes and 100 writes against the data set, but you can have multiple save points). However you’ll usually create an RDB snapshot every five minutes or more, so in case of Redis stopping working without a correct shutdown for any reason you should be prepared to lose the latest minutes of data.</li>\n<li>RDB needs to fork() often in order to persist on disk using a child process. Fork() can be time consuming if the dataset is big, and may result in Redis to stop serving clients for some millisecond or even for one second if the dataset is very big and the CPU performance not great. AOF also needs to fork() but you can tune how often you want to rewrite your logs without any trade-off on durability.</li>\n</ul>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"RDB DISADVANTAGES"},{"content":"<h2 id=\"redis-persistence-aof-advantages\">AOF advantages</h2><ul>\n<li>Using AOF Redis is much more durable: you can have different fsync policies: no fsync at all, fsync every second, fsync at every query. With the default policy of fsync every second write performances are still great (fsync is performed using a background thread and the main thread will try hard to perform writes when no fsync is in progress.) but you can only lose one second worth of writes.</li>\n<li>The AOF log is an append only log, so there are no seeks, nor corruption problems if there is a power outage. Even if the log ends with an half-written command for some reason (disk full or other reasons) the redis-check-aof tool is able to fix it easily.</li>\n<li>Redis is able to automatically rewrite the AOF in background when it gets too big. The rewrite is completely safe as while Redis continues appending to the old file, a completely new one is produced with the minimal set of operations needed to create the current data set, and once this second file is ready Redis switches the two and starts appending to the new one.</li>\n<li>AOF contains a log of all the operations one after the other in an easy to understand and parse format. You can even easily export an AOF file. For instance even if you flushed everything for an error using a FLUSHALL command, if no rewrite of the log was performed in the meantime you can still save your data set just stopping the server, removing the latest command, and restarting Redis again.</li>\n</ul>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"AOF ADVANTAGES"},{"content":"<h2 id=\"redis-persistence-aof-disadvantages\">AOF disadvantages</h2><ul>\n<li>AOF files are usually bigger than the equivalent RDB files for the same dataset.</li>\n<li>AOF can be slower than RDB depending on the exact fsync policy. In general with fsync set to <em>every second</em> performances are still very high, and with fsync disabled it should be exactly as fast as RDB even under high load. Still RDB is able to provide more guarantees about the maximum latency even in the case of an huge write load.</li>\n<li>In the past we experienced rare bugs in specific commands (for instance there was one involving blocking commands like BRPOPLPUSH) causing the AOF produced to not reproduce exactly the same dataset on reloading. This bugs are rare and we have tests in the test suite creating random complex datasets automatically and reloading them to check everything is ok, but this kind of bugs are almost impossible with RDB persistence. To make this point more clear: the Redis AOF works incrementally updating an existing state, like MySQL or MongoDB does, while the RDB snapshotting creates everything from scratch again and again, that is conceptually more robust. However -\n1) It should be noted that every time the AOF is rewritten by Redis it is recreated from scratch starting from the actual data contained in the data set, making resistance to bugs stronger compared to an always appending AOF file (or one rewritten reading the old AOF instead of reading the data in memory).\n2) We never had a single report from users about an AOF corruption that was detected in the real world.</li>\n</ul>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"AOF DISADVANTAGES"},{"content":"<h2 id=\"redis-persistence-ok-so-what-should-i-use\">Ok, so what should I use?</h2><p>The general indication is that you should use both persistence methods if\nyou want a degree of data safety comparable to what PostgreSQL can provide you.</p><p>If you care a lot about your data, but still can live with a few minutes of\ndata loss in case of disasters, you can simply use RDB alone.</p><p>There are many users using AOF alone, but we discourage it since to have an\nRDB snapshot from time to time is a great idea for doing database backups,\nfor faster restarts, and in the event of bugs in the AOF engine.</p><p>Note: for all these reasons we’ll likely end up unifying AOF and RDB into a single persistence model in the future (long term plan).</p><p>The following sections will illustrate a few more details about the two persistence models.</p><p><a name=\"snapshotting\"></a></p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"OK, SO WHAT SHOULD I USE?"},{"content":"<h2 id=\"redis-persistence-snapshotting\">Snapshotting</h2><p>By default Redis saves snapshots of the dataset on disk, in a binary\nfile called <code>dump.rdb</code>. You can configure Redis to have it save the\ndataset every N seconds if there are at least M changes in the dataset,\nor you can manually call the <code>SAVE</code> or <code>BGSAVE</code> commands.</p><p>For example, this configuration will make Redis automatically dump the\ndataset to disk every 60 seconds if at least 1000 keys changed:</p><p>This strategy is known as <em>snapshotting</em>.</p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"SNAPSHOTTING"},{"content":"<h3 id=\"redis-persistence-snapshotting-how-it-works\">How it works</h3><p>Whenever Redis needs to dump the dataset to disk, this is what happens:</p><ul>\n<li><p>Redis <a href=\"http://linux.die.net/man/2/fork\">forks</a>. We now have a child\nand a parent process.</p>\n</li>\n<li><p>The child starts to write the dataset to a temporary RDB file.</p>\n</li>\n<li><p>When the child is done writing the new RDB file, it replaces the old\none.</p>\n</li>\n</ul><p>Redis <a href=\"http://linux.die.net/man/2/fork\">forks</a>. We now have a child\nand a parent process.</p><p>The child starts to write the dataset to a temporary RDB file.</p><p>When the child is done writing the new RDB file, it replaces the old\none.</p><p>This method allows Redis to benefit from copy-on-write semantics.</p><p><a name=\"append-only-file\"></a></p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"How it works"},{"content":"<h2 id=\"redis-persistence-append-only-file\">Append-only file</h2><p>Snapshotting is not very durable. If your computer running Redis stops,\nyour power line fails, or you accidentally <code>kill -9</code> your instance, the\nlatest data written on Redis will get lost.  While this may not be a big\ndeal for some applications, there are use cases for full durability, and\nin these cases Redis was not a viable option.</p><p>The <em>append-only file</em> is an alternative, fully-durable strategy for\nRedis.  It became available in version 1.1.</p><p>You can turn on the AOF in your configuration file:</p><p>From now on, every time Redis receives a command that changes the\ndataset (e.g. <code>SET</code>) it will append it to the AOF.  When you restart\nRedis it will re-play the AOF to rebuild the state.</p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"APPEND-ONLY FILE"},{"content":"<h3 id=\"redis-persistence-append-only-file-log-rewriting\">Log rewriting</h3><p>As you can guess, the AOF gets bigger and bigger as write operations are\nperformed.  For example, if you are incrementing a counter 100 times,\nyou’ll end up with a single key in your dataset containing the final\nvalue, but 100 entries in your AOF. 99 of those entries are not needed\nto rebuild the current state.</p><p>So Redis supports an interesting feature: it is able to rebuild the AOF\nin the background without interrupting service to clients. Whenever\nyou issue a <code>BGREWRITEAOF</code> Redis will write the shortest sequence of\ncommands needed to rebuild the current dataset in memory.  If you’re\nusing the AOF with Redis 2.2 you’ll need to run <code>BGREWRITEAOF</code> from time to\ntime. Redis 2.4 is able to trigger log rewriting automatically (see the\n2.4 example configuration file for more information).</p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"Log rewriting"},{"content":"<h3 id=\"redis-persistence-append-only-file-how-durable-is-the-append-only-file\">How durable is the append only file?</h3><p>You can configure how many times Redis will\n<a href=\"http://linux.die.net/man/2/fsync\"><code>fsync</code></a> data on disk. There are\nthree options:</p><ul>\n<li><p><code>fsync</code> every time a new command is appended to the AOF. Very very\nslow, very safe.</p>\n</li>\n<li><p><code>fsync</code> every second. Fast enough (in 2.4 likely to be as fast as snapshotting), and you can lose 1 second of data if there is a disaster.</p>\n</li>\n<li><p>Never <code>fsync</code>, just put your data in the hands of the Operating\nSystem. The faster and less safe method.</p>\n</li>\n</ul><p><code>fsync</code> every time a new command is appended to the AOF. Very very\nslow, very safe.</p><p><code>fsync</code> every second. Fast enough (in 2.4 likely to be as fast as snapshotting), and you can lose 1 second of data if there is a disaster.</p><p>Never <code>fsync</code>, just put your data in the hands of the Operating\nSystem. The faster and less safe method.</p><p>The suggested (and default) policy is to <code>fsync</code> every second. It is\nboth very fast and pretty safe. The <code>always</code> policy is very slow in\npractice (although it was improved in Redis 2.0) – there is no way to\nmake <code>fsync</code> faster than it is.</p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"How durable is the append only file?"},{"content":"<h3 id=\"redis-persistence-append-only-file-what-should-i-do-if-my-aof-gets-corrupted\">What should I do if my AOF gets corrupted?</h3><p>It is possible that the server crashes while writing the AOF file (this\nstill should never lead to inconsistencies), corrupting the file in a\nway that is no longer loadable by Redis. When this happens you can fix\nthis problem using the following procedure:</p><ul>\n<li><p>Make a backup copy of your AOF file.</p>\n</li>\n<li><p>Fix the original file using the <code>redis-check-aof</code> tool that ships with\nRedis:</p>\n<pre><code class=\"prettyprint prettyprinted\" style=\"\"><span class=\"pln\">$ redis</span><span class=\"pun\">-</span><span class=\"pln\">check</span><span class=\"pun\">-</span><span class=\"pln\">aof </span><span class=\"pun\">--</span><span class=\"pln\">fix </span><span class=\"str\">&lt;filename&gt;</span></code></pre>\n</li>\n<li><p>Optionally use <code>diff -u</code> to check what is the difference between two\nfiles.</p>\n</li>\n<li><p>Restart the server with the fixed file.</p>\n</li>\n</ul><p>Make a backup copy of your AOF file.</p><p>Fix the original file using the <code>redis-check-aof</code> tool that ships with\nRedis:</p><p>Optionally use <code>diff -u</code> to check what is the difference between two\nfiles.</p><p>Restart the server with the fixed file.</p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"What should I do if my AOF gets corrupted?"},{"content":"<h3 id=\"redis-persistence-append-only-file-how-it-works\">How it works</h3><p>Log rewriting uses the same copy-on-write trick already in use for\nsnapshotting.  This is how it works:</p><ul>\n<li><p>Redis <a href=\"http://linux.die.net/man/2/fork\">forks</a>, so now we have a child\nand a parent process.</p>\n</li>\n<li><p>The child starts writing the new AOF in a temporary file.</p>\n</li>\n<li><p>The parent accumulates all the new changes in an in-memory buffer (but\nat the same time it writes the new changes in the old append-only file,\nso if the rewriting fails, we are safe).</p>\n</li>\n<li><p>When the child is done rewriting the file, the parent gets a signal,\nand appends the in-memory buffer at the end of the file generated by the\nchild.</p>\n</li>\n<li><p>Profit! Now Redis atomically renames the old file into the new one,\nand starts appending new data into the new file.</p>\n</li>\n</ul><p>Redis <a href=\"http://linux.die.net/man/2/fork\">forks</a>, so now we have a child\nand a parent process.</p><p>The child starts writing the new AOF in a temporary file.</p><p>The parent accumulates all the new changes in an in-memory buffer (but\nat the same time it writes the new changes in the old append-only file,\nso if the rewriting fails, we are safe).</p><p>When the child is done rewriting the file, the parent gets a signal,\nand appends the in-memory buffer at the end of the file generated by the\nchild.</p><p>Profit! Now Redis atomically renames the old file into the new one,\nand starts appending new data into the new file.</p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"How it works"},{"content":"<h3 id=\"redis-persistence-append-only-file-how-i-can-switch-to-aof-if-im-currently-using-dumprdb-snapshots\">How I can switch to AOF, if I’m currently using dump.rdb snapshots?</h3><p>There is a different procedure to do this in Redis 2.0 and Redis 2.2, as you\ncan guess it’s simpler in Redis 2.2 and does not require a restart at all.</p><p><strong>Redis &gt;= 2.2</strong></p><ul>\n<li>Make a backup of your latest dump.rdb file.</li>\n<li>Transfer this backup into a safe place.</li>\n<li>Issue the following two commands:</li>\n<li>redis-cli config set appendonly yes</li>\n<li>redis-cli config set save “”</li>\n<li>Make sure that your database contains the same number of keys it contained.</li>\n<li>Make sure that writes are appended to the append only file correctly.</li>\n</ul><p>The first CONFIG command enables the Append Only File. In order to do so <strong>Redis will block</strong> to generate the initial dump, then will open the file for writing, and will start appending all the next write queries.</p><p>The second CONFIG command is used to turn off snapshotting persistence. This is optional, if you wish you can take both the persistence methods enabled.</p><p><strong>IMPORTANT:</strong> remember to edit your redis.conf to turn on the AOF, otherwise\nwhen you restart the server the configuration changes will be lost and the\nserver will start again with the old configuration.</p><p><strong>Redis 2.0</strong></p><ul>\n<li>Make a backup of your latest dump.rdb file.</li>\n<li>Transfer this backup into a safe place.</li>\n<li>Stop all the writes against the database!</li>\n<li>Issue a redis-cli bgrewriteaof. This will create the append only file.</li>\n<li>Stop the server when Redis finished generating the AOF dump.</li>\n<li>Edit redis.conf end enable append only file persistence.</li>\n<li>Restart the server.</li>\n<li>Make sure that your database contains the same number of keys it contained.</li>\n<li>Make sure that writes are appended to the append only file correctly.</li>\n</ul>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"How I can switch to AOF, if I’m currently using dump.rdb snapshots?"},{"content":"<h2 id=\"redis-persistence-interactions-between-aof-and-rdb-persistence\">Interactions between AOF and RDB persistence</h2><p>Redis &gt;= 2.4 makes sure to avoid triggering an AOF rewrite when an RDB\nsnapshotting operation is already in progress, or allowing a BGSAVE while the\nAOF rewrite is in progress. This prevents two Redis background processes\nfrom doing heavy disk I/O at the same time.</p><p>When snapshotting is in progress and the user explicitly requests a log\nrewrite operation using BGREWRITEAOF the server will reply with an OK\nstatus code telling the user the operation is scheduled, and the rewrite\nwill start once the snapshotting is completed.</p><p>In the case both AOF and RDB persistence are enabled and Redis restarts the\nAOF file will be used to reconstruct the original dataset since it is\nguaranteed to be the most complete.</p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"INTERACTIONS BETWEEN AOF AND RDB PERSISTENCE"},{"content":"<h2 id=\"redis-persistence-backing-up-redis-data\">Backing up Redis data</h2><p>Before starting this section, make sure to read the following sentence: <strong>Make Sure to Backup Your Database</strong>. Disks break, instances in the cloud disappear, and so forth: no backups means huge risk of data disappearing into /dev/null.</p><p>Redis is very data backup friendly since you can copy RDB files while the\ndatabase is running: the RDB is never modified once produced, and while it\ngets produced it uses a temporary name and is renamed into its final destination\natomically using rename(2) only when the new snapshot is complete.</p><p>This means that copying the RDB file is completely safe while the server is\nrunning. This is what we suggest:</p><ul>\n<li>Create a cron job in your server creating hourly snapshots of the RDB file in one directory, and daily snapshots in a different directory.</li>\n<li>Every time the cron script runs, make sure to call the <code>find</code> command to make sure too old snapshots are deleted: for instance you can take hourly snapshots for the latest 48 hours, and daily snapshots for one or two months. Make sure to name the snapshots with data and time information.</li>\n<li>At least one time every day make sure to transfer an RDB snapshot <em>outside your data center</em> or at least <em>outside the physical machine</em> running your Redis instance.</li>\n</ul>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"BACKING UP REDIS DATA"},{"content":"<h2 id=\"redis-persistence-disaster-recovery\">Disaster recovery</h2><p>Disaster recovery in the context of Redis is basically the same story as\nbackups, plus the ability to transfer those backups in many different external\ndata centers. This way data is secured even in the case of some catastrophic\nevent affecting the main data center where Redis is running and producing its\nsnapshots.</p><p>Since many Redis users are in the startup scene and thus don’t have plenty\nof money to spend we’ll review the most interesting disaster recovery techniques\nthat don’t have too high costs.</p><ul>\n<li>Amazon S3 and other similar services are a good way for mounting your disaster recovery system. Simply transfer your daily or hourly RDB snapshot to S3 in an encrypted form. You can encrypt your data using <code>gpg -c</code> (in symmetric encryption mode). Make sure to store your password in many different safe places (for instance give a copy to the most important people of your organization). It is recommended to use multiple storage services for improved data safety.</li>\n<li>Transfer your snapshots using SCP (part of SSH) to far servers. This is a fairly simple and safe route: get a small VPS in a place that is very far from you, install ssh there, and generate an ssh client key without passphrase, then make\nadd it in the authorized_keys file of your small VPS. You are ready to transfer\nbackups in an automated fashion. Get at least two VPS in two different providers\nfor best results.</li>\n</ul><p>It is important to understand that this system can easily fail if not coded\nin the right way. At least make absolutely sure that after the transfer is\ncompleted you are able to verify the file size (that should match the one of\nthe file you copied) and possibly the SHA1 digest if you are using a VPS.</p><p>You also need some kind of independent alert system if the transfer of fresh\nbackups is not working for some reason.</p>","link":"./alpha/topics/persistence.html","spaLink":"#/alpha/topics/persistence","title":"DISASTER RECOVERY"},{"content":"<h1 id=\"redis-protocol-specification\">Redis Protocol specification</h1><p>Redis clients communicate with the Redis server using a protocol called <strong>RESP</strong> (REdis Serialization Protocol). While the protocol was designed specifically for Redis, it can be used for other client-server software projects.</p><p>RESP is a compromise between the following things:</p><ul>\n<li>Simple to implement.</li>\n<li>Fast to parse.</li>\n<li>Human readable.</li>\n</ul><p>RESP can serialize different data types like integers, strings, arrays. There is also a specific type for errors. Requests are sent from the client to the Redis server as arrays of strings representing the arguments of the command to execute. Redis replies with a command-specific data type.</p><p>RESP is binary-safe and does not require processing of bulk data transferred from one process to another, because it uses prefixed-length to transfer bulk data.</p><p>Note: the protocol outlined here is only used for client-server communication. Redis Cluster uses a different binary protocol in order to exchange messages between nodes.</p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"REDIS PROTOCOL SPECIFICATION"},{"content":"<h2 id=\"redis-protocol-specification-networking-layer\">Networking layer</h2><p>A client connects to a Redis server creating a TCP connection to the port 6379.</p><p>While RESP is technically non-TCP specific, in the context of Redis the protocol is only used with TCP connections (or equivalent stream oriented connections like Unix sockets).</p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"NETWORKING LAYER"},{"content":"<h2 id=\"redis-protocol-specification-request-response-model\">Request-Response model</h2><p>Redis accepts commands composed of different arguments.\nOnce a command is received, it is processed and a reply is sent back to the client.</p><p>This is the simplest model possible, however there are two exceptions:</p><ul>\n<li>Redis supports pipelining (covered later in this document). So it is possible for clients to send multiple commands at once, and wait for replies later.</li>\n<li>When a Redis client subscribes to a Pub/Sub channel, the protocol changes semantics and becomes a <em>push</em> protocol, that is, the client no longer requires to send commands, because the server will automatically send to the client new messages (for the channels the client is subscribed to) as soon as they are received.</li>\n</ul><p>Excluding the above two exceptions, the Redis protocol is a simple request-response protocol.</p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"REQUEST-RESPONSE MODEL"},{"content":"<h2 id=\"redis-protocol-specification-resp-protocol-description\">RESP protocol description</h2><p>The RESP protocol was introduced in Redis 1.2, but it became the\nstandard way for talking with the Redis server in Redis 2.0.\nThis is the protocol you should implement in your Redis client.</p><p>RESP is actually a serialization protocol that supports the following\ndata types: Simple Strings, Errors, Integers, Bulk Strings and Arrays.</p><p>The way RESP is used in Redis as a request-response protocol is the\nfollowing:</p><ul>\n<li>Clients send commands to a Redis server as a RESP Array of Bulk Strings.</li>\n<li>The server replies with one of the RESP types according to the command implementation.</li>\n</ul><p>In RESP, the type of some data depends on the first byte:</p><ul>\n<li>For <strong>Simple Strings</strong> the first byte of the reply is “+”</li>\n<li>For <strong>Errors</strong> the first byte of the reply is “-“</li>\n<li>For <strong>Integers</strong> the first byte of the reply is “:”</li>\n<li>For <strong>Bulk Strings</strong> the first byte of the reply is “$”</li>\n<li>For <strong>Arrays</strong> the first byte of the reply is “<code>*</code>“</li>\n</ul><p>Additionally RESP is able to represent a Null value using a special variation of Bulk Strings or Array as specified later.</p><p>In RESP different parts of the protocol are always terminated with “\\r\\n” (CRLF).</p><p><a name=\"simple-string-reply\"></a></p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"RESP PROTOCOL DESCRIPTION"},{"content":"<h2 id=\"redis-protocol-specification-resp-simple-strings\">RESP Simple Strings</h2><p>Simple Strings are encoded in the following way: a plus character, followed by a string that cannot contain a CR or LF character (no newlines are allowed), terminated by CRLF (that is “\\r\\n”).</p><p>Simple Strings are used to transmit non binary safe strings with minimal overhead. For example many Redis commands reply with just “OK” on success, that as a RESP Simple String is encoded with the following 5 bytes:</p><p>In order to send binary-safe strings, RESP Bulk Strings are used instead.</p><p>When Redis replies with a Simple String, a client library should return\nto the caller a string composed of the first character after the ‘+’\nup to the end of the string, excluding the final CRLF bytes.</p><p><a name=\"error-reply\"></a></p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"RESP SIMPLE STRINGS"},{"content":"<h2 id=\"redis-protocol-specification-resp-errors\">RESP Errors</h2><p>RESP has a specific data type for errors. Actually errors are exactly like\nRESP Simple Strings, but the first character is a minus ‘-‘ character instead\nof a plus. The real difference between Simple Strings and Errors in RESP is that\nerrors are treated by clients as exceptions, and the string that composes\nthe Error type is the error message itself.</p><p>The basic format is:</p><p>Error replies are only sent when something wrong happens, for instance if\nyou try to perform an operation against the wrong data type, or if the command\ndoes not exist and so forth. An exception should be raised by the library\nclient when an Error Reply is received.</p><p>The following are examples of error replies:</p><p>The first word after the “-“, up to the first space or newline, represents\nthe kind of error returned. This is just a convention used by Redis and is not\npart of the RESP Error format.</p><p>For example, <code>ERR</code> is the generic error, while <code>WRONGTYPE</code> is a more specific\nerror that implies that the client tried to perform an operation against the\nwrong data type. This is called an <strong>Error Prefix</strong> and is a way to allow\nthe client to understand the kind of error returned by the server without\nto rely on the exact message given, that may change over the time.</p><p>A client implementation may return different kind of exceptions for different\nerrors, or may provide a generic way to trap errors by directly providing\nthe error name to the caller as a string.</p><p>However, such a feature should not be considered vital as it is rarely useful, and a limited client implementation may simply return a generic error condition, such as <code>false</code>.</p><p><a name=\"integer-reply\"></a></p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"RESP ERRORS"},{"content":"<h2 id=\"redis-protocol-specification-resp-integers\">RESP Integers</h2><p>This type is just a CRLF terminated string representing an integer,\nprefixed by a “:” byte. For example “:0\\r\\n”, or “:1000\\r\\n” are integer\nreplies.</p><p>Many Redis commands return RESP Integers, like <code>INCR</code>, <code>LLEN</code> and <code>LASTSAVE</code>.</p><p>There is no special meaning for the returned integer, it is just an\nincremental number for <code>INCR</code>, a UNIX time for <code>LASTSAVE</code> and so forth. However,\nthe returned integer is guaranteed to be in the range of a signed 64 bit\ninteger.</p><p>Integer replies are also extensively used in order to return true or false.\nFor instance commands like <code>EXISTS</code> or <code>SISMEMBER</code> will return 1 for true\nand 0 for false.</p><p>Other commands like <code>SADD</code>, <code>SREM</code> and <code>SETNX</code> will return 1 if the operation\nwas actually performed, 0 otherwise.</p><p>The following commands will reply with an integer reply: <code>SETNX</code>, <code>DEL</code>,\n<code>EXISTS</code>, <code>INCR</code>, <code>INCRBY</code>, <code>DECR</code>, <code>DECRBY</code>, <code>DBSIZE</code>, <code>LASTSAVE</code>,\n<code>RENAMENX</code>, <code>MOVE</code>, <code>LLEN</code>, <code>SADD</code>, <code>SREM</code>, <code>SISMEMBER</code>, <code>SCARD</code>.</p><p><a name=\"nil-reply\"></a>\n<a name=\"bulk-string-reply\"></a></p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"RESP INTEGERS"},{"content":"<h2 id=\"redis-protocol-specification-resp-bulk-strings\">RESP Bulk Strings</h2><p>Bulk Strings are used in order to represent a single binary safe\nstring up to 512 MB in length.</p><p>Bulk Strings are encoded in the following way:</p><ul>\n<li>A “$” byte followed by the number of bytes composing the string (a prefixed length), terminated by CRLF.</li>\n<li>The actual string data.</li>\n<li>A final CRLF.</li>\n</ul><p>So the string “foobar” is encoded as follows:</p><p>When an empty string is just:</p><p>RESP Bulk Strings can also be used in order to signal non-existence of a value\nusing a special format that is used to represent a Null value. In this special\nformat the length is -1, and there is no data, so a Null is represented as:</p><p>This is called a <strong>Null Bulk String</strong>.</p><p>The client library API should not return an empty string, but a nil object,\nwhen the server replies with a Null Bulk String.\nFor example a Ruby library should return ‘nil’ while a C library should\nreturn NULL (or set a special flag in the reply object), and so forth.</p><p><a name=\"array-reply\"></a></p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"RESP BULK STRINGS"},{"content":"<h2 id=\"redis-protocol-specification-resp-arrays\">RESP Arrays</h2><p>Clients send commands to the Redis server using RESP Arrays. Similarly\ncertain Redis commands returning collections of elements to the client\nuse RESP Arrays are reply type. An example is the <code>LRANGE</code> command that\nreturns elements of a list.</p><p>RESP Arrays are sent using the following format:</p><ul>\n<li>A <code>*</code> character as the first byte, followed by the number of elements in the array as a decimal number, followed by CRLF.</li>\n<li>An additional RESP type for every element of the Array.</li>\n</ul><p>So an empty Array is just the following:</p><p>While an array of two RESP Bulk Strings “foo” and “bar” is encoded as:</p><p>As you can see after the <code>*&lt;count&gt;CRLF</code> part prefixing the array, the other\ndata types composing the array are just concatenated one after the other.\nFor example an Array of three integers is encoded as follows:</p><p>Arrays can contain mixed types, it’s not necessary for the\nelements to be of the same type. For instance, a list of four\nintegers and a bulk string can be encoded as the follows:</p><p>(The reply was split into multiple lines for clarity).</p><p>The first line the server sent is <code>*5\\r\\n</code> in order to specify that five\nreplies will follow. Then every reply constituting the items of the\nMulti Bulk reply are transmitted.</p><p>The concept of Null Array exists as well, and is an alternative way to\nspecify a Null value (usually the Null Bulk String is used, but for historical\nreasons we have two formats).</p><p>For instance when the <code>BLPOP</code> command times out, it returns a Null Array\nthat has a count of <code>-1</code> as in the following example:</p><p>A client library API should return a null object and not an empty Array when\nRedis replies with a Null Array. This is necessary to distinguish\nbetween an empty list and a different condition (for instance the timeout\ncondition of the <code>BLPOP</code> command).</p><p>Arrays of arrays are possible in RESP. For example an array of two arrays\nis encoded as follows:</p><p>(The format was split into multiple lines to make it easier to read).</p><p>The above RESP data type encodes a two elements Array consisting of an Array that contains three Integers 1, 2, 3 and an array of a Simple String and an Error.</p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"RESP ARRAYS"},{"content":"<h2 id=\"redis-protocol-specification-null-elements-in-arrays\">Null elements in Arrays</h2><p>Single elements of an Array may be Null. This is used in Redis replies  in\norder to signal that this elements are missing and not empty strings. This\ncan happen with the SORT command when used with the GET <em>pattern</em> option\nwhen the specified key is missing. Example of an Array reply containing a\nNull element:</p><p>The second element is a Null. The client library should return something\nlike this:</p><p>Note that this is not an exception to what said in the previous sections, but\njust an example to further specify the protocol.</p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"NULL ELEMENTS IN ARRAYS"},{"content":"<h2 id=\"redis-protocol-specification-sending-commands-to-a-redis-server\">Sending commands to a Redis Server</h2><p>Now that you are familiar with the RESP serialization format, writing an\nimplementation of a Redis client library will be easy. We can further specify\nhow the interaction between the client and the server works:</p><ul>\n<li>A client sends to the Redis server a RESP Array consisting of just Bulk Strings.</li>\n<li>A Redis server replies to clients sending any valid RESP data type as reply.</li>\n</ul><p>So for example a typical interaction could be the following.</p><p>The client sends the command <strong>LLEN mylist</strong> in order to get the length of the list stored at key <em>mylist</em>, and the server replies with an Integer reply as in the following example (C: is the client, S: the server).</p><p>As usually we separate different parts of the protocol with newlines for simplicity, but the actual interaction is the client sending <code>*2\\r\\n$4\\r\\nLLEN\\r\\n$6\\r\\nmylist\\r\\n</code> as a whole.</p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"SENDING COMMANDS TO A REDIS SERVER"},{"content":"<h2 id=\"redis-protocol-specification-multiple-commands-and-pipelining\">Multiple commands and pipelining</h2><p>A client can use the same connection in order to issue multiple commands.\nPipelining is supported so multiple commands can be sent with a single\nwrite operation by the client, without the need to read the server reply\nof the previous command before issuing the next one.\nAll the replies can be read at the end.</p><p>For more information please check our <a href=\"/topics/pipelining\">page about Pipelining</a>.</p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"MULTIPLE COMMANDS AND PIPELINING"},{"content":"<h2 id=\"redis-protocol-specification-inline-commands\">Inline Commands</h2><p>Sometimes you have only <code>telnet</code> in your hands and you need to send a command\nto the Redis server. While the Redis protocol is simple to implement it is\nnot ideal to use in interactive sessions, and <code>redis-cli</code> may not always be\navailable. For this reason Redis also accepts commands in a special way that\nis designed for humans, and is called the <strong>inline command</strong> format.</p><p>The following is an example of a server/client chat using an inline command\n(the server chat starts with S:, the client chat with C:)</p><p>The following is another example of an inline command returning an integer:</p><p>Basically you simply write space-separated arguments in a telnet session.\nSince no command starts with <code>*</code> that is instead used in the unified request\nprotocol, Redis is able to detect this condition and parse your command.</p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"INLINE COMMANDS"},{"content":"<h2 id=\"redis-protocol-specification-high-performance-parser-for-the-redis-protocol\">High performance parser for the Redis protocol</h2><p>While the Redis protocol is very human readable and easy to implement it can\nbe implemented with a performance similar to that of a binary protocol.</p><p>RESP uses prefixed lengths to transfer bulk data, so there is\nnever need to scan the payload for special characters like it happens for\ninstance with JSON, nor to quote the payload that needs to be sent to the\nserver.</p><p>The Bulk and Multi Bulk lengths can be processed with code that performs\na single operation per character while at the same time scanning for the\nCR character, like the following C code:</p><p>After the first CR is identified, it can be skipped along with the following\nLF without any processing. Then the bulk data can be read using a single\nread operation that does not inspect the payload in any way. Finally\nthe remaining the CR and LF character are discarded without any processing.</p><p>While comparable in performance to a binary protocol the Redis protocol is\nsignificantly simpler to implement in most very high level languages,\nreducing the number of bugs in client software.</p>","link":"./alpha/topics/protocol.html","spaLink":"#/alpha/topics/protocol","title":"HIGH PERFORMANCE PARSER FOR THE REDIS PROTOCOL"},{"content":"<h1 id=\"an-introduction-to-redis-data-types-and-abstractions\">An introduction to Redis data types and abstractions</h1><p>Redis is not a <em>plain</em> key-value store, actually it is a <em>data structures server</em>, supporting different kind of values. What this means is that, while in\ntraditional key-value stores you associated string keys to string values, in\nRedis the value is not limited to a simple string, but can also hold more complex\ndata structures. The following is the list of all the data structures supported\nby Redis, which will be covered separately in this tutorial:</p><ul>\n<li>Binary-safe strings.</li>\n<li>Lists: collections of string elements sorted according to the order of insertion. They are basically <em>linked lists</em>.</li>\n<li>Sets: collections of unique, unsorted string elements.</li>\n<li>Sorted sets, similar to Sets but where every string element is associated to a\nfloating number value, called <em>score</em>. The elements are always taken sorted\nby their score, so unlike Sets it is possible to retrieve a range of elements\n(for example you may ask: give me the top 10, or the bottom 10).</li>\n<li>Hashes, which are maps composed of fields associated with values. Both the\nfield and the value are strings. This is very similar to Ruby or Python\nhashes.</li>\n<li>Bit arrays (or simply bitmaps): it is possible, using special commands, to\nhandle String values like an array of bits: you can set and clear individual\nbits, count all the bits set to 1, find the first set or unset bit, and so\nforth.</li>\n<li>HyperLogLogs: this is a probabilistic data structure which is used in order\nto estimate the cardinality of a set. Don’t be scared, it is simpler than\nit seems… See later in the HyperLogLog section of this tutorial.</li>\n</ul><p>It’s not always trivial to grasp how these data types work and what to use in\norder to solve a given problem from the <a href=\"/commands\">command reference</a>, so this\ndocument is a crash course to Redis data types and their most common patterns.</p><p>For all the examples we’ll use the <code>redis-cli</code> utility, a simple but\nhandy command-line utility, to issue commands against the Redis server.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"AN INTRODUCTION TO REDIS DATA TYPES AND ABSTRACTIONS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-keys\">Redis keys</h2><p>Redis keys are binary safe, this means that you can use any binary sequence as a\nkey, from a string like “foo” to the content of a JPEG file.\nThe empty string is also a valid key.</p><p>A few other rules about keys:</p><ul>\n<li>Very long keys are not a good idea. For instance a key of 1024 bytes is a bad\nidea not only memory-wise, but also because the lookup of the key in the\ndataset may require several costly key-comparisons. Even when the task at hand\nis to match the existence of a large value, hashing it (for example\nwith SHA1) is a better idea, especially from the perspective of memory\nand bandwidth.</li>\n<li>Very short keys are often not a good idea. There is little point in writing\n“u1000flw” as a key if you can instead write “user:1000:followers”.  The latter\nis more readable and the added space is minor compared to the space used by\nthe key object itself and the value object. While short keys will obviously\nconsume a bit less memory, your job is to find the right balance.</li>\n<li>Try to stick with a schema. For instance “object-type:id” is a good\nidea, as in “user:1000”. Dots or dashes are often used for multi-word\nfields, as in “comment:1234:reply.to” or “comment:1234:reply-to”.</li>\n<li>The maximum allowed key size is 512 MB.</li>\n</ul><p><a name=\"strings\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS KEYS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-strings\">Redis Strings</h2><p>The Redis String type is the simplest type of value you can associate with\na Redis key. It is the only data type in Memcached, so it is also very natural\nfor newcomers to use it in Redis.</p><p>Since Redis keys are strings, when we use the string type as a value too,\nwe are mapping a string to another string. The string data type is useful\nfor a number of use cases, like caching HTML fragments or pages.</p><p>Let’s play a bit with the string type, using <code>redis-cli</code> (all the examples\nwill be performed via <code>redis-cli</code> in this tutorial).</p><p>As you can see using the <code>SET</code> and the <code>GET</code> commands are the way we set\nand retrieve a string value. Note that <code>SET</code> will replace any existing value\nalready stored into the key, in the case that the key already exists, even if\nthe key is associated with a non-string value. So <code>SET</code> performs an assignment.</p><p>Values can be strings (including binary data) of every kind, for instance you\ncan store a jpeg image inside a key. A value can’t be bigger than 512 MB.</p><p>The <code>SET</code> command has interesting options, that are provided as additional\narguments. For example, I may ask <code>SET</code> to fail if the key already exists,\nor the opposite, that it only succeed if the key already exists:</p><p>Even if strings are the basic values of Redis, there are interesting operations\nyou can perform with them. For instance, one is atomic increment:</p><p>The <a href=\"/commands/incr\">INCR</a> command parses the string value as an integer,\nincrements it by one, and finally sets the obtained value as the new value.\nThere are other similar commands like <a href=\"/commands/incrby\">INCRBY</a>,\n<a href=\"/commands/decr\">DECR</a> and <a href=\"/commands/decrby\">DECRBY</a>. Internally it’s\nalways the same command, acting in a slightly different way.</p><p>What does it mean that INCR is atomic?\nThat even multiple clients issuing INCR against\nthe same key will never enter into a race condition. For instance, it will never\nhappen that client 1 reads “10”, client 2 reads “10” at the same time, both\nincrement to 11, and set the new value to 11. The final value will always be\n12 and the read-increment-set operation is performed while all the other\nclients are not executing a command at the same time.</p><p>There are a number of commands for operating on strings. For example\nthe <code>GETSET</code> command sets a key to a new value, returning the old value as the\nresult. You can use this command, for example, if you have a\nsystem that increments a Redis key using <code>INCR</code>\nevery time your web site receives a new visitor. You may want to collect this\ninformation once every hour, without losing a single increment.\nYou can <code>GETSET</code> the key, assigning it the new value of “0” and reading the\nold value back.</p><p>The ability to set or retrieve the value of multiple keys in a single\ncommand is also useful for reduced latency. For this reason there are\nthe <code>MSET</code> and <code>MGET</code> commands:</p><p>When <code>MGET</code> is used, Redis returns an array of values.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS STRINGS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-altering-and-querying-the-key-space\">Altering and querying the key space</h2><p>There are commands that are not defined on particular types, but are useful\nin order to interact with the space of keys, and thus, can be used with\nkeys of any type.</p><p>For example the <code>EXISTS</code> command returns 1 or 0 to signal if a given key\nexists or not in the database, while the <code>DEL</code> command deletes a key\nand associated value, whatever the value is.</p><p>From the examples you can also see how <code>DEL</code> itself returns 1 or 0 depending on whether\nthe key was removed (it existed) or not (there was no such key with that\nname).</p><p>There are many key space related commands, but the above two are the\nessential ones together with the <code>TYPE</code> command, which returns the kind\nof value stored at the specified key:</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"ALTERING AND QUERYING THE KEY SPACE"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-expires-keys-with-limited-time-to-live\">Redis expires: keys with limited time to live</h2><p>Before continuing with more complex data structures, we need to discuss\nanother feature which works regardless of the value type, and is\ncalled <strong>Redis expires</strong>. Basically you can set a timeout for a key, which\nis a limited time to live. When the time to live elapses, the key is\nautomatically destroyed, exactly as if the user called the <code>DEL</code> command\nwith the key.</p><p>A few quick info about Redis expires:</p><ul>\n<li>They can be set both using seconds or milliseconds precision.</li>\n<li>However the expire time resolution is always 1 millisecond.</li>\n<li>Information about expires are replicated and persisted on disk, the time virtually passes when your Redis server remains stopped (this means that Redis saves the date at which a key will expire).</li>\n</ul><p>Setting an expire is trivial:</p><p>The key vanished between the two <code>GET</code> calls, since the second call was\ndelayed more than 5 seconds. In the example above we used <code>EXPIRE</code> in\norder to set the expire (it can also be used in order to set a different\nexpire to a key already having one, like <code>PERSIST</code> can be used in order\nto remove the expire and make the key persistent forever). However we\ncan also create keys with expires using other Redis commands. For example\nusing <code>SET</code> options:</p><p>The example above sets a key with the string value <code>100</code>, having an expire\nof ten seconds. Later the <code>TTL</code> command is called in order to check the\nremaining time to live for the key.</p><p>In order to set and check expires in milliseconds, check the <code>PEXPIRE</code> and\nthe <code>PTTL</code> commands, and the full list of <code>SET</code> options.</p><p><a name=\"lists\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS EXPIRES: KEYS WITH LIMITED TIME TO LIVE"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-lists\">Redis Lists</h2><p>To explain the List data type it’s better to start with a little bit of theory,\nas the term <em>List</em> is often used in an improper way by information technology\nfolks. For instance “Python Lists” are not what the name may suggest (Linked\nLists), but rather Arrays (the same data type is called Array in\nRuby actually).</p><p>From a very general point of view a List is just a sequence of ordered\nelements: 10,20,1,2,3 is a list. But the properties of a List implemented using\nan Array are very different from the properties of a List implemented using a\n<em>Linked List</em>.</p><p>Redis lists are implemented via Linked Lists. This means that even if you have\nmillions of elements inside a list, the operation of adding a new element in\nthe head or in the tail of the list is performed <em>in constant time</em>. The speed of adding a\nnew element with the <code>LPUSH</code> command to the head of a list with ten\nelements is the same as adding an element to the head of list with 10\nmillion elements.</p><p>What’s the downside? Accessing an element <em>by index</em> is very fast in lists\nimplemented with an Array (constant time indexed access) and not so fast in\nlists implemented by linked lists (where the operation requires an amount of\nwork proportional to the index of the accessed element).</p><p>Redis Lists are implemented with linked lists because for a database system it\nis crucial to be able to add elements to a very long list in a very fast way.\nAnother strong advantage, as you’ll see in a moment, is that Redis Lists can be\ntaken at constant length in constant time.</p><p>When fast access to the middle of a large collection of elements is important,\nthere is a different data structure that can be used, called sorted sets.\nSorted sets will be covered later in this tutorial.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-first-steps-with-redis-lists\">First steps with Redis Lists</h2><p>The <code>LPUSH</code> command adds a new element into a list, on the\nleft (at the head), while the <code>RPUSH</code> command adds a new\nelement into a list ,on the right (at the tail). Finally the\n<code>LRANGE</code> command extracts ranges of elements from lists:</p><p>Note that <a href=\"/commands/lrange\">LRANGE</a> takes two indexes, the first and the last\nelement of the range to return. Both the indexes can be negative, telling Redis\nto start counting from the end: so -1 is the last element, -2 is the\npenultimate element of the list, and so forth.</p><p>As you can see <code>RPUSH</code> appended the elements on the right of the list, while\nthe final <code>LPUSH</code> appended the element on the left.</p><p>Both commands are <em>variadic commands</em>, meaning that you are free to push\nmultiple elements into a list in a single call:</p><p>An important operation defined on Redis lists is the ability to <em>pop elements</em>.\nPopping elements is the operation of both retrieving the element from the list,\nand eliminating it from the list, at the same time. You can pop elements\nfrom left and right, similarly to how you can push elements in both sides\nof the list:</p><p>We added three elements and popped three elements, so at the end of this\nsequence of commands the list is empty and there are no more elements to\npop. If we try to pop yet another element, this is the result we get:</p><p>Redis returned a NULL value to signal that there are no elements into the\nlist.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"FIRST STEPS WITH REDIS LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-common-use-cases-for-lists\">Common use cases for lists</h2><p>Lists are useful for a number of tasks, two very representative use cases\nare the following:</p><ul>\n<li>Remember the latest updates posted by users into a social network.</li>\n<li>Communication between processes, using a consumer-producer pattern where the producer pushes items into a list, and a consumer (usually a <em>worker</em>) consumes those items and executed actions. Redis has special list commands to make this use case both more reliable and efficient.</li>\n</ul><p>For example both the popular Ruby libraries <a href=\"https://github.com/resque/resque\">resque</a> and\n<a href=\"https://github.com/mperham/sidekiq\">sidekiq</a> use Redis lists under the hood in order to\nimplement background jobs.</p><p>The popular Twitter social network <a href=\"http://www.infoq.com/presentations/Real-Time-Delivery-Twitter\">takes the latest tweets</a>\nposted by users into Redis lists.</p><p>To describe a common use case step by step, imagine your home page shows the latest\nphotos published in a photo sharing social network and you want to speedup access.</p><ul>\n<li>Every time a user posts a new photo, we add its ID into a list with <code>LPUSH</code>.</li>\n<li>When users visit the home page, we use <code>LRANGE 0 9</code> in order to get the latest 10 posted items.</li>\n</ul>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"COMMON USE CASES FOR LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-capped-lists\">Capped lists</h2><p>In many use cases we just want to use lists to store the <em>latest items</em>,\nwhatever they are: social network updates, logs, or anything else.</p><p>Redis allows us to use lists as a capped collection, only remembering the latest\nN items and discarding all the oldest items using the <code>LTRIM</code> command.</p><p>The <code>LTRIM</code> command is similar to <code>LRANGE</code>, but <strong>instead of displaying the\nspecified range of elements</strong> it sets this range as the new list value. All\nthe elements outside the given range are removed.</p><p>An example will make it more clear:</p><p>The above <code>LTRIM</code> command tells Redis to take just list elements from index\n0 to 2, everything else will be discarded. This allows for a very simple but\nuseful pattern: doing a List push operation + a List trim operation together\nin order to add a new element and discard elements exceeding a limit:</p><p>The above combination adds a new element and takes only the 1000\nnewest elements into the list. With <code>LRANGE</code> you can access the top items\nwithout any need to remember very old data.</p><p>Note: while <code>LRANGE</code> is technically an O(N) command, accessing small ranges\ntowards the head or the tail of the list is a constant time operation.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"CAPPED LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-blocking-operations-on-lists\">Blocking operations on lists</h2><p>Lists have a special feature that make them suitable to implement queues,\nand in general as a building block for inter process communication systems:\nblocking operations.</p><p>Imagine you want to push items into a list with one process, and use\na different process in order to actually do some kind of work with those\nitems. This is the usual producer / consumer setup, and can be implemented\nin the following simple way:</p><ul>\n<li>To push items into the list, producers call <code>LPUSH</code>.</li>\n<li>To extract / process items from the list, consumers call <code>RPOP</code>.</li>\n</ul><p>However it is possible that sometimes the list is empty and there is nothing\nto process, so <code>RPOP</code> just returns NULL. In this case a consumer is forced to wait\nsome time and retry again with <code>RPOP</code>. This is called <em>polling</em>, and is not\na good idea in this context because it has several drawbacks:</p><p>So Redis implements commands called <code>BRPOP</code> and <code>BLPOP</code> which are versions\nof <code>RPOP</code> and <code>LPOP</code> able to block if the list is empty: they’ll return to\nthe caller only when a new element is added to the list, or when a user-specified\ntimeout is reached.</p><p>This is an example of a <code>BRPOP</code> call we could use in the worker:</p><p>It means: “wait for elements in the list <code>tasks</code>, but return if after 5 seconds\nno element is available”.</p><p>Note that you can use 0 as timeout to wait for elements forever, and you can\nalso specify multiple lists and not just one, in order to wait on multiple\nlists at the same time, and get notified when the first list receives an\nelement.</p><p>A few things to note about <code>BRPOP</code>:</p><p>There are more things you should know about lists and blocking ops. We\nsuggest that you read more on the following:</p><ul>\n<li>It is possible to build safer queues or rotating queues using <code>RPOPLPUSH</code>.</li>\n<li>There is also a blocking variant of the command, called <code>BRPOPLPUSH</code>.</li>\n</ul>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"BLOCKING OPERATIONS ON LISTS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-automatic-creation-and-removal-of-keys\">Automatic creation and removal of keys</h2><p>So far in our examples we never had to create empty lists before pushing\nelements, or removing empty lists when they no longer have elements inside.\nIt is Redis’ responsibility to delete keys when lists are left empty, or to create\nan empty list if the key does not exist and we are trying to add elements\nto it, for example, with <code>LPUSH</code>.</p><p>This is not specific to lists, it applies to all the Redis data types\ncomposed of multiple elements — Sets, Sorted Sets and Hashes.</p><p>Basically we can summarize the behavior with three rules:</p><p>Examples of rule 1:</p><p>However we can’t perform operations against the wrong type of the key exists:</p><p>Example of rule 2:</p><p>The key no longer exists after all the elements are popped.</p><p>Example of rule 3:</p><p><a name=\"hashes\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"AUTOMATIC CREATION AND REMOVAL OF KEYS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-hashes\">Redis Hashes</h2><p>Redis hashes look exactly how one might expect a “hash” to look, with field-value pairs:</p><p>While hashes are handy to represent <em>objects</em>, actually the number of fields you can\nput inside a hash has no practical limits (other than available memory), so you can use\nhashes in many different ways inside your application.</p><p>The command <code>HMSET</code> sets multiple fields of the hash, while <code>HGET</code> retrieves\na single field. <code>HMGET</code> is similar to <code>HGET</code> but returns an array of values:</p><p>There are commands that are able to perform operations on individual fields\nas well, like <code>HINCRBY</code>:</p><p>You can find the <a href=\"http://redis.io/commands#hash\">full list of hash commands in the documentation</a>.</p><p>It is worth noting that small hashes (i.e., a few elements with small values) are\nencoded in special way in memory that make them very memory efficient.</p><p><a name=\"sets\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS HASHES"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-sets\">Redis Sets</h2><p>Redis Sets are unordered collections of strings. The\n<code>SADD</code> command adds new elements to a set. It’s also possible\nto do a number of other operations against sets like testing if a given element\nalready exists, performing the intersection, union or difference between\nmultiple sets, and so forth.</p><p>Here I’ve added three elements to my set and told Redis to return all the\nelements. As you can see they are not sorted — Redis is free to return the\nelements in any order at every call, since there is no contract with the\nuser about element ordering.</p><p>Redis has commands to test for membership. For example, checking if an element exists:</p><p>“3” is a member of the set, while “30” is not.</p><p>Sets are good for expressing relations between objects.\nFor instance we can easily use sets in order to implement tags.</p><p>A simple way to model this problem is to have a set for every object we\nwant to tag. The set contains the IDs of the tags associated with the object.</p><p>One illustration is tagging news articles.\nIf article ID 1000 is tagged with tags 1, 2, 5 and 77, a set\ncan associate these tag IDs with the news item:</p><p>We may also want to have the inverse relation as well: the list\nof all the news tagged with a given tag:</p><p>To get all the tags for a given object is trivial:</p><p>Note: in the example we assume you have another data structure, for example\na Redis hash, which maps tag IDs to tag names.</p><p>There are other non trivial operations that are still easy to implement\nusing the right Redis commands. For instance we may want a list of all the\nobjects with the tags 1, 2, 10, and 27 together. We can do this using\nthe <code>SINTER</code> command, which performs the intersection between different\nsets. We can use:</p><p>In addition to intersection you can also perform\nunions, difference, extract a random element, and so forth.</p><p>The command to extract an element is called <code>SPOP</code>, and is handy to model\ncertain problems. For example in order to implement a web-based poker game,\nyou may want to represent your deck with a set. Imagine we use a one-char\nprefix for (C)lubs, (D)iamonds, (H)earts, (S)pades:</p><p>Now we want to provide each player with 5 cards. The <code>SPOP</code> command\nremoves a random element, returning it to the client, so it is the\nperfect operation in this case.</p><p>However if we call it against our deck directly, in the next play of the\ngame we’ll need to populate the deck of cards again, which may not be\nideal. So to start, we can make a copy of the set stored in the <code>deck</code> key\ninto the <code>game:1:deck</code> key.</p><p>This is accomplished using <code>SUNIONSTORE</code>, which normally performs the\nunion between multiple sets, and stores the result into another set.\nHowever, since the union of a single set is itself, I can copy my deck\nwith:</p><p>Now I’m ready to provide the first player with five cards:</p><p>One pair of jacks, not great…</p><p>This is a good time to introduce the set command that provides the number\nof elements inside a set. This is often called the <em>cardinality of a set</em>\nin the context of set theory, so the Redis command is called <code>SCARD</code>.</p><p>The math works: 52 - 5 = 47.</p><p>When you need to just get random elements without removing them from the\nset, there is the <code>SRANDMEMBER</code> command suitable for the task. It also features\nthe ability to return both repeating and non-repeating elements.</p><p><a name=\"sorted-sets\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS SETS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-redis-sorted-sets\">Redis Sorted sets</h2><p>Sorted sets are a data type which is similar to a mix between a Set and\na Hash. Like sets, sorted sets are composed of unique, non-repeating\nstring elements, so in some sense a sorted set is a set as well.</p><p>However while elements inside sets are not ordered, every element in\na sorted set is associated with a floating point value, called <em>the score</em>\n(this is why the type is also similar to a hash, since every element\nis mapped to a value).</p><p>Moreover, elements in a sorted sets are <em>taken in order</em> (so they are not\nordered on request, order is a peculiarity of the data structure used to\nrepresent sorted sets). They are ordered according to the following rule:</p><ul>\n<li>If A and B are two elements with a different score, then A &gt; B if A.score is &gt; B.score.</li>\n<li>If A and B have exactly the same score, then A &gt; B if the A string is lexicographically greater than the B string. A and B strings can’t be equal since sorted sets only have unique elements.</li>\n</ul><p>Let’s start with a simple example, adding a few selected hackers names as\nsorted set elements, with their year of birth as “score”.</p><p>As you can see <code>ZADD</code> is similar to <code>SADD</code>, but takes one additional argument\n(placed before the element to be added) which is the score.\n<code>ZADD</code> is also variadic, so you are free to specify multiple score-value\npairs, even if this is not used in the example above.</p><p>With sorted sets it is trivial to return a list of hackers sorted by their\nbirth year because actually <em>they are already sorted</em>.</p><p>Implementation note: Sorted sets are implemented via a\ndual-ported data structure containing both a skip list and a hash table, so\nevery time we add an element Redis performs an O(log(N)) operation. That’s\ngood, but when we ask for sorted elements Redis does not have to do any work at\nall, it’s already all sorted:</p><p>Note: 0 and -1 means from element index 0 to the last element (-1 works\nhere just as it does in the case of the <code>LRANGE</code> command).</p><p>What if I want to order them the opposite way, youngest to oldest?\nUse <a href=\"/commands/zrevrange\">ZREVRANGE</a> instead of <a href=\"/commands/zrange\">ZRANGE</a>:</p><p>It is possible to return scores as well, using the <code>WITHSCORES</code> argument:</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"REDIS SORTED SETS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-operating-on-ranges\">Operating on ranges</h2><p>Sorted sets are more powerful than this. They can operate on ranges.\nLet’s get all the individuals that were born up to 1950 inclusive. We\nuse the <code>ZRANGEBYSCORE</code> command to do it:</p><p>We asked Redis to return all the elements with a score between negative\ninfinity and 1950 (both extremes are included).</p><p>It’s also possible to remove ranges of elements. Let’s remove all\nthe hackers born between 1940 and 1960 from the sorted set:</p><p><code>ZREMRANGEBYSCORE</code> is perhaps not the best command name,\nbut it can be very useful, and returns the number of removed elements.</p><p>Another extremely useful operation defined for sorted set elements\nis the get-rank operation. It is possible to ask what is the\nposition of an element in the set of the ordered elements.</p><p>The <code>ZREVRANK</code> command is also available in order to get the rank, considering\nthe elements sorted a descending way.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"OPERATING ON RANGES"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-lexicographical-scores\">Lexicographical scores</h2><p>With recent versions of Redis 2.8, a new feature was introduced that allows\ngetting ranges lexicographically, assuming elements in a sorted set are all\ninserted with the same identical score (elements are compared with the C\n<code>memcmp</code> function, so it is guaranteed that there is no collation, and every\nRedis instance will reply with the same output).</p><p>The main commands to operate with lexicographical ranges are <code>ZRANGEBYLEX</code>,\n<code>ZREVRANGEBYLEX</code>, <code>ZREMRANGEBYLEX</code> and <code>ZLEXCOUNT</code>.</p><p>For example, let’s add again our list of famous hackers, but this time\nuse a score of zero for all the elements:</p><p>Because of the sorted sets ordering rules, they are already sorted\nlexicographically:</p><p>Using <code>ZRANGEBYLEX</code> we can ask for lexicographical ranges:</p><p>Ranges can be inclusive or exclusive (depending on the first character),\nalso string infinite and minus infinite are specified respectively with\nthe <code>+</code> and <code>-</code> strings. See the documentation for more information.</p><p>This feature is important because it allows us to use sorted sets as a generic\nindex. For example, if you want to index elements by a 128-bit unsigned\ninteger argument, all you need to do is to add elements into a sorted\nset with the same score (for example 0) but with an 8 byte prefix\nconsisting of <strong>the 128 bit number in big endian</strong>. Since numbers in big\nendian, when ordered lexicographically (in raw bytes order) are actually\nordered numerically as well, you can ask for ranges in the 128 bit space,\nand get the element’s value discarding the prefix.</p><p>If you want to see the feature in the context of a more serious demo,\ncheck the <a href=\"http://autocomplete.redis.io\">Redis autocomplete demo</a>.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"LEXICOGRAPHICAL SCORES"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-updating-the-score-leader-boards\">Updating the score: leader boards</h2><p>Just a final note about sorted sets before switching to the next topic.\nSorted sets’ scores can be updated at any time. Just calling <code>ZADD</code> against\nan element already included in the sorted set will update its score\n(and position) with O(log(N)) time complexity.  As such, sorted sets are suitable\nwhen there are tons of updates.</p><p>Because of this characteristic a common use case is leader boards.\nThe typical application is a Facebook game where you combine the ability to\ntake users sorted by their high score, plus the get-rank operation, in order\nto show the top-N users, and the user rank in the leader board (e.g., “you are\nthe #4932 best score here”).</p><p><a name=\"bitmaps\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"UPDATING THE SCORE: LEADER BOARDS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-bitmaps\">Bitmaps</h2><p>Bitmaps are not an actual data type, but a set of bit-oriented operations\ndefined on the String type. Since strings are binary safe blobs and their\nmaximum length is 512 MB, they are suitable to set up to 2^32 different\nbits.</p><p>Bit operations are divided into two groups: constant-time single bit\noperations, like setting a bit to 1 or 0, or getting its value, and\noperations on groups of bits, for example counting the number of set\nbits in a given range of bits (e.g., population counting).</p><p>One of the biggest advantages of bitmaps is that they often provide\nextreme space savings when storing information. For example in a system\nwhere different users are represented by incremental user IDs, it is possible\nto remember a single bit information (for example, knowing whether\na user wants to receive a newsletter) of 4 billion of users using just 512 MB of memory.</p><p>Bits are set and retrieved using the <code>SETBIT</code> and <code>GETBIT</code> commands:</p><p>The <code>SETBIT</code> command takes as its first argument the bit number, and as its second\nargument the value to set the bit to, which is 1 or 0. The command\nautomatically enlarges the string if the addressed bit is outside the\ncurrent string length.</p><p><code>GETBIT</code> just returns the value of the bit at the specified index.\nOut of range bits (addressing a bit that is outside the length of the string\nstored into the target key) are always considered to be zero.</p><p>There are three commands operating on group of bits:</p><p>Both <code>BITPOS</code> and <code>BITCOUNT</code> are able to operate with byte ranges of the\nstring, instead of running for the whole length of the string. The following\nis a trivial example of <code>BITCOUNT</code> call:</p><p>Common user cases for bitmaps are:</p><ul>\n<li>Real time analytics of all kinds.</li>\n<li>Storing space efficient but high performance boolean information associated with object IDs.</li>\n</ul><p>For example imagine you want to know the longest streak of daily visits of\nyour web site users. You start counting days starting from zero, that is the\nday you made your web site public, and set a bit with <code>SETBIT</code> every time\nthe user visits the web site. As a bit index you simply take the current unix\ntime, subtract the initial offset, and divide by 3600*24.</p><p>This way for each user you have a small string containing the visit\ninformation for each day. With <code>BITCOUNT</code> it is possible to easily get\nthe number of days a given user visited the web site, while with\na few <code>BITPOS</code> calls, or simply fetching and analyzing the bitmap client-side,\nit is possible to easily compute the longest streak.</p><p>Bitmaps are trivial to split into multiple keys, for example for\nthe sake of sharding the data set and because in general it is better to\navoid working with huge keys. To split a bitmap across different keys\ninstead of setting all the bits into a key, a trivial strategy is just\nto store M bits per key and obtain the key name with <code>bit-number/M</code> and\nthe Nth bit to address inside the key with <code>bit-number MOD M</code>.</p><p><a name=\"hyperloglogs\"></a></p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"BITMAPS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-hyperloglogs\">HyperLogLogs</h2><p>A HyperLogLog is a probabilistic data structure used in order to count\nunique things (technically this is referred to estimating the cardinality\nof a set). Usually counting unique items requires using an amount of memory\nproportional to the number of items you want to count, because you need\nto remember the elements you have already seen in the past in order to avoid\ncounting them multiple times. However there is a set of algorithms that trade\nmemory for precision: you end with an estimated measure with a standard error,\nin the case of the Redis implementation, which is less than 1%.  The\nmagic of this algorithm is that you no longer need to use an amount of memory\nproportional to the number of items counted, and instead can use a\nconstant amount of memory! 12k bytes in the worst case, or a lot less if your\nHyperLogLog (We’ll just call them HLL from now) has seen very few elements.</p><p>HLLs in Redis, while technically a different data structure, is encoded\nas a Redis string, so you can call <code>GET</code> to serialize a HLL, and <code>SET</code>\nto deserialize it back to the server.</p><p>Conceptually the HLL API is like using Sets to do the same task. You would\n<code>SADD</code> every observed element into a set, and would use <code>SCARD</code> to check the\nnumber of elements inside the set, which are unique since <code>SADD</code> will not\nre-add an existing element.</p><p>While you don’t really <em>add items</em> into an HLL, because the data structure\nonly contains a state that does not include actual elements, the API is the\nsame:</p><ul>\n<li>Every time you see a new element, you add it to the count with <code>PFADD</code>.</li>\n<li><p>Every time you want to retrieve the current approximation of the unique elements <em>added</em> with <code>PFADD</code> so far, you use the <code>PFCOUNT</code>.</p>\n<pre><code class=\"prettyprint prettyprinted\" style=\"\"><span class=\"pln\">  </span><span class=\"pun\">&gt;</span><span class=\"pln\"> pfadd hll a b c d\n  </span><span class=\"pun\">(</span><span class=\"pln\">integer</span><span class=\"pun\">)</span><span class=\"pln\"> </span><span class=\"lit\">1</span><span class=\"pln\">\n  </span><span class=\"pun\">&gt;</span><span class=\"pln\"> pfcount hll\n  </span><span class=\"pun\">(</span><span class=\"pln\">integer</span><span class=\"pun\">)</span><span class=\"pln\"> </span><span class=\"lit\">4</span></code></pre>\n</li>\n</ul><p>Every time you want to retrieve the current approximation of the unique elements <em>added</em> with <code>PFADD</code> so far, you use the <code>PFCOUNT</code>.</p><p>An example of use case for this data structure is counting unique queries\nperformed by users in a search form every day.</p><p>Redis is also able to perform the union of HLLs, please check the\n<a href=\"/commands#hyperloglog\">full documentation</a> for more information.</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"HYPERLOGLOGS"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-other-notable-features\">Other notable features</h2><p>There are other important things in the Redis API that can’t be explored\nin the context of this document, but are worth your attention:</p><ul>\n<li>It is possible to <a href=\"/commands/scan\">iterate the key space of a large collection incrementally</a>.</li>\n<li>It is possible to run <a href=\"/commands/eval\">Lua scripts server side</a> to win latency and bandwidth.</li>\n<li>Redis is also a <a href=\"/topics/pubsub\">Pub-Sub server</a>.</li>\n</ul>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"OTHER NOTABLE FEATURES"},{"content":"<h2 id=\"an-introduction-to-redis-data-types-and-abstractions-learn-more\">Learn more</h2><p>This tutorial is in no way complete and has covered just the basics of the API.\nRead the <a href=\"/commands\">command reference</a> to discover a lot more.</p><p>Thanks for reading, and have fun hacking with Redis!</p>","link":"./alpha/topics/data-types-intro.html","spaLink":"#/alpha/topics/data-types-intro","title":"LEARN MORE"},{"content":"<h1 id=\"redis-latency-problems-troubleshooting\">Redis latency problems troubleshooting</h1><p>This document will help you understand what the problem could be if you\nare experiencing latency problems with Redis.</p><p>In this context <em>latency</em> is the maximum delay between the time a client\nissues a command and the time the reply to the command is received by the\nclient. Usually Redis processing time is extremely low, in the sub microsecond\nrange, but there are certain conditions leading to higher latency figures.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"REDIS LATENCY PROBLEMS TROUBLESHOOTING"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-ive-little-time-give-me-the-checklist\">I’ve little time, give me the checklist</h2><p>The following documentation is very important in order to run Redis in\na low latency fashion. However I understand that we are busy people, so\nlet’s start with a quick checklist. If you fail following these steps, please\nreturn here to read the full documentation.</p><p>In general, use the following table for durability VS latency/performance tradeoffs, ordered from stronger safety to better latency.</p><p>And now for people with 15 minutes to spend, the details…</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"I’VE LITTLE TIME, GIVE ME THE CHECKLIST"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-measuring-latency\">Measuring latency</h2><p>If you are experiencing latency problems, probably you know how to measure\nit in the context of your application, or maybe your latency problem is very\nevident even macroscopically. However redis-cli can be used to measure the\nlatency of a Redis server in milliseconds, just try:</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"MEASURING LATENCY"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-using-the-internal-redis-latency-monitoring-subsystem\">Using the internal Redis latency monitoring subsystem</h2><p>Since Redis 2.8.13, Redis provides latency monitoring capabilities that\nare able to sample different execution paths to understand where the\nserver is blocking. This makes debugging of the problems illustrated in\nthis documentation much simpler, so we suggest to enable latency monitoring\nASAP. Please refer to the <a href=\"/topics/latency-monitor\">Latency monitor documentation</a>.</p><p>While the latency monitoring sampling and reporting capabilities will make\nsimpler to understand the source of latency in your Redis system, it is still\nadvised that you read this documentation extensively to better understand\nthe topic of Redis and latency spikes.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"USING THE INTERNAL REDIS LATENCY MONITORING SUBSYSTEM"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-latency-baseline\">Latency baseline</h2><p>There is a kind of latency that is inherently part of the environment where\nyou run Redis, that is the latency provided by your operating system kernel\nand, if you are using virtualization, by the hypervisor you are using.</p><p>While this latency can’t be removed it is important to study it because\nit is the baseline, or in other words, you’ll not be able to achieve a Redis\nlatency that is better than the latency that every process running in your\nenvironment will experience because of the kernel or hypervisor implementation\nor setup.</p><p>We call this kind of latency <strong>intrinsic latency</strong>, and <code>redis-cli</code> starting\nfrom Redis version 2.8.7 is able to measure it. This is an example run\nunder Linux 3.11.0 running on an entry level server.</p><p>Note: the argument <code>100</code> is the number of seconds the test will be executed.\nThe more time we run the test, the more likely we’ll be able to spot\nlatency spikes. 100 seconds is usually appropriate, however you may want\nto perform a few runs at different times. Please note that the test is CPU\nintensive and will likely saturate a single core in your system.</p><p>Note: redis-cli in this special case needs to <strong>run in the server</strong> where you run or plan to run Redis, not in the client. In this special mode redis-cli does no connect to a Redis server at all: it will just try to measure the largest time the kernel does not provide CPU time to run to the redis-cli process itself.</p><p>In the above example, the intrinsic latency of the system is just 0.115\nmilliseconds (or 115 microseconds), which is a good news, however keep in mind\nthat the intrinsic latency may change over time depending on the load of the\nsystem.</p><p>Virtualized environments will not show so good numbers, especially with high\nload or if there are noisy neighbors. The following is a run on a Linode 4096\ninstance running Redis and Apache:</p><p>Here we have an intrinsic latency of 9.7 milliseconds: this means that we can’t ask better than that to Redis. However other runs at different times in different virtualization environments with higher load or with noisy neighbors can easily show even worse values. We were able to measured up to 40 milliseconds in\nsystems otherwise apparently running normally.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"LATENCY BASELINE"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-latency-induced-by-network-and-communication\">Latency induced by network and communication</h2><p>Clients connect to Redis using a TCP/IP connection or a Unix domain connection.\nThe typical latency of a 1 Gbit/s network is about 200 us, while the latency\nwith a Unix domain socket can be as low as 30 us. It actually depends on your\nnetwork and system hardware. On top of the communication itself, the system\nadds some more latency (due to thread scheduling, CPU caches, NUMA placement,\netc …). System induced latencies are significantly higher on a virtualized\nenvironment than on a physical machine.</p><p>The consequence is even if Redis processes most commands in sub microsecond\nrange, a client performing many roundtrips to the server will have to pay\nfor these network and system related latencies.</p><p>An efficient client will therefore try to limit the number of roundtrips by\npipelining several commands together. This is fully supported by the servers\nand most clients. Aggregated commands like MSET/MGET can be also used for\nthat purpose. Starting with Redis 2.4, a number of commands also support\nvariadic parameters for all data types.</p><p>Here are some guidelines:</p><ul>\n<li>If you can afford it, prefer a physical machine over a VM to host the server.</li>\n<li>Do not systematically connect/disconnect to the server (especially true\nfor web based applications). Keep your connections as long lived as possible.</li>\n<li>If your client is on the same host than the server, use Unix domain sockets.</li>\n<li>Prefer to use aggregated commands (MSET/MGET), or commands with variadic\nparameters (if possible) over pipelining.</li>\n<li>Prefer to use pipelining (if possible) over sequence of roundtrips.</li>\n<li>Redis supports Lua server-side scripting to cover cases that are not suitable\nfor raw pipelining (for instance when the result of a command is an input for\nthe following commands).</li>\n</ul><p>On Linux, some people can achieve better latencies by playing with process\nplacement (taskset), cgroups, real-time priorities (chrt), NUMA\nconfiguration (numactl), or by using a low-latency kernel. Please note\nvanilla Redis is not really suitable to be bound on a <strong>single</strong> CPU core.\nRedis can fork background tasks that can be extremely CPU consuming\nlike bgsave or AOF rewrite. These tasks must <strong>never</strong> run on the same core\nas the main event loop.</p><p>In most situations, these kind of system level optimizations are not needed.\nOnly do them if you require them, and if you are familiar with them.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"LATENCY INDUCED BY NETWORK AND COMMUNICATION"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-single-threaded-nature-of-redis\">Single threaded nature of Redis</h2><p>Redis uses a <em>mostly</em> single threaded design. This means that a single process\nserves all the client requests, using a technique called <strong>multiplexing</strong>.\nThis means that Redis can serve a single request in every given moment, so\nall the requests are served sequentially. This is very similar to how Node.js\nworks as well. However, both products are often not perceived as being slow.\nThis is caused in part by the small amount of time to complete a single request,\nbut primarily because these products are designed to not block on system calls,\nsuch as reading data from or writing data to a socket.</p><p>I said that Redis is <em>mostly</em> single threaded since actually from Redis 2.4\nwe use threads in Redis in order to perform some slow I/O operations in the\nbackground, mainly related to disk I/O, but this does not change the fact\nthat Redis serves all the requests using a single thread.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"SINGLE THREADED NATURE OF REDIS"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-latency-generated-by-slow-commands\">Latency generated by slow commands</h2><p>A consequence of being single thread is that when a request is slow to serve\nall the other clients will wait for this request to be served. When executing\nnormal commands, like <code>GET</code> or <code>SET</code> or <code>LPUSH</code> this is not a problem\nat all since this commands are executed in constant (and very small) time.\nHowever there are commands operating on many elements, like <code>SORT</code>, <code>LREM</code>,\n<code>SUNION</code> and others. For instance taking the intersection of two big sets\ncan take a considerable amount of time.</p><p>The algorithmic complexity of all commands is documented. A good practice\nis to systematically check it when using commands you are not familiar with.</p><p>If you have latency concerns you should either not use slow commands against\nvalues composed of many elements, or you should run a replica using Redis\nreplication where to run all your slow queries.</p><p>It is possible to monitor slow commands using the Redis\n<a href=\"/commands/slowlog\">Slow Log feature</a>.</p><p>Additionally, you can use your favorite per-process monitoring program\n(top, htop, prstat, etc …) to quickly check the CPU consumption of the\nmain Redis process. If it is high while the traffic is not, it is usually\na sign that slow commands are used.</p><p><strong>IMPORTANT NOTE</strong>: a VERY common source of latency generated by the execution\nof slow commands is the use of the <code>KEYS</code> command in production environments.\n<code>KEYS</code>, as documented in the Redis documentation, should only be used for\ndebugging purposes. Since Redis 2.8 a new commands were introduced in order to\niterate the key space and other large collections incrementally, please check\nthe <code>SCAN</code>, <code>SSCAN</code>, <code>HSCAN</code> and <code>ZSCAN</code> commands for more information.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"LATENCY GENERATED BY SLOW COMMANDS"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-latency-generated-by-fork\">Latency generated by fork</h2><p>In order to generate the RDB file in background, or to rewrite the Append Only File if AOF persistence is enabled, Redis has to fork background processes.\nThe fork operation (running in the main thread) can induce latency by itself.</p><p>Forking is an expensive operation on most Unix-like systems, since it involves\ncopying a good number of objects linked to the process. This is especially\ntrue for the page table associated to the virtual memory mechanism.</p><p>For instance on a Linux/AMD64 system, the memory is divided in 4 kB pages.\nTo convert virtual addresses to physical addresses, each process stores\na page table (actually represented as a tree) containing at least a pointer\nper page of the address space of the process. So a large 24 GB Redis instance\nrequires a page table of 24 GB / 4 kB * 8 = 48 MB.</p><p>When a background save is performed, this instance will have to be forked,\nwhich will involve allocating and copying 48 MB of memory. It takes time\nand CPU, especially on virtual machines where allocation and initialization\nof a large memory chunk can be expensive.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"LATENCY GENERATED BY FORK"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-fork-time-in-different-systems\">Fork time in different systems</h2><p>Modern hardware is pretty fast to copy the page table, but Xen is not.\nThe problem with Xen is not virtualization-specific, but Xen-specific. For instance using VMware or Virtual Box does not result into slow fork time.\nThe following is a table that compares fork time for different Redis instance\nsize. Data is obtained performing a BGSAVE and looking at the <code>latest_fork_usec</code> filed in the <code>INFO</code> command output.</p><p>However the good news is that <strong>new types of EC2 HVM based instances are much\nbetter with fork times</strong>, almost on pair with physical servers, so for example\nusing m3.medium (or better) instances will provide good results.</p><ul>\n<li><strong>Linux beefy VM on VMware</strong> 6.0GB RSS forked in 77 milliseconds (12.8 milliseconds per GB).</li>\n<li><strong>Linux running on physical machine (Unknown HW)</strong> 6.1GB RSS forked in 80 milliseconds (13.1 milliseconds per GB)</li>\n<li><strong>Linux running on physical machine (Xeon @ 2.27Ghz)</strong> 6.9GB RSS forked into 62 milliseconds (9 milliseconds per GB).</li>\n<li><strong>Linux VM on 6sync (KVM)</strong> 360 MB RSS forked in 8.2 milliseconds (23.3 milliseconds per GB).</li>\n<li><strong>Linux VM on EC2, old instance types (Xen)</strong> 6.1GB RSS forked in 1460 milliseconds (239.3 milliseconds per GB).</li>\n<li><strong>Linux VM on EC2, new instance types (Xen)</strong> 1GB RSS forked in 10 milliseconds (10 milliseconds per GB).</li>\n<li><strong>Linux VM on Linode (Xen)</strong> 0.9GBRSS forked into 382 milliseconds (424 milliseconds per GB).</li>\n</ul><p>As you can see certain VM running on Xen have a performance hit that is between one order to two orders of magnitude. For EC2 users the suggestion is simple: use modern HVM based instances.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"FORK TIME IN DIFFERENT SYSTEMS"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-latency-induced-by-transparent-huge-pages\">Latency induced by transparent huge pages</h2><p>Unfortunately when a Linux kernel has transparent huge pages enabled, Redis\nincurs to a big latency penalty after the <code>fork</code> call is used in order to\npersist on disk. Huge pages are the cause of the following issue:</p><p>Make sure to <strong>disable transparent huge pages</strong> using the following command:</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"LATENCY INDUCED BY TRANSPARENT HUGE PAGES"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-latency-induced-by-swapping-operating-system-paging\">Latency induced by swapping (operating system paging)</h2><p>Linux (and many other modern operating systems) is able to relocate memory\npages from the memory to the disk, and vice versa, in order to use the\nsystem memory efficiently.</p><p>If a Redis page is moved by the kernel from the memory to the swap file, when\nthe data stored in this memory page is used by Redis (for example accessing\na key stored into this memory page) the kernel will stop the Redis process\nin order to move the page back into the main memory. This is a slow operation\ninvolving random I/Os (compared to accessing a page that is already in memory)\nand will result into anomalous latency experienced by Redis clients.</p><p>The kernel relocates Redis memory pages on disk mainly because of three reasons:</p><ul>\n<li>The system is under memory pressure since the running processes are demanding\nmore physical memory than the amount that is available. The simplest instance of\nthis problem is simply Redis using more memory than the one available.</li>\n<li>The Redis instance data set, or part of the data set, is mostly completely idle\n(never accessed by clients), so the kernel could swap idle memory pages on disk.\nThis problem is very rare since even a moderately slow instance will touch all\nthe memory pages often, forcing the kernel to retain all the pages in memory.</li>\n<li>Some processes are generating massive read or write I/Os on the system. Because\nfiles are generally cached, it tends to put pressure on the kernel to increase\nthe filesystem cache, and therefore generate swapping activity. Please note it\nincludes Redis RDB and/or AOF background threads which can produce large files.</li>\n</ul><p>Fortunately Linux offers good tools to investigate the problem, so the simplest\nthing to do is when latency due to swapping is suspected is just to check if\nthis is the case.</p><p>The first thing to do is to checking the amount of Redis memory that is swapped\non disk. In order to do so you need to obtain the Redis instance pid:</p><p>Now enter the /proc file system directory for this process:</p><p>Here you’ll find a file called <strong>smaps</strong> that describes the memory layout of\nthe Redis process (assuming you are using Linux 2.6.16 or newer).\nThis file contains very detailed information about our process memory maps,\nand one field called <strong>Swap</strong> is exactly what we are looking for. However\nthere is not just a single swap field since the smaps file contains the\ndifferent memory maps of our Redis process (The memory layout of a process\nis more complex than a simple linear array of pages).</p><p>Since we are interested in all the memory swapped by our process the first thing\nto do is to grep for the Swap field across all the file:</p><p>If everything is 0 kB, or if there are sporadic 4k entries, everything is\nperfectly normal. Actually in our example instance (the one of a real web\nsite running Redis and serving hundreds of users every second) there are a\nfew entries that show more swapped pages. To investigate if this is a serious\nproblem or not we change our command in order to also print the size of the\nmemory map:</p><p>As you can see from the output, there is a map of 720896 kB\n(with just 12 kB swapped) and 156 kB more swapped in another map:\nbasically a very small amount of our memory is swapped so this is not\ngoing to create any problem at all.</p><p>If instead a non trivial amount of the process memory is swapped on disk your\nlatency problems are likely related to swapping. If this is the case with your\nRedis instance you can further verify it using the <strong>vmstat</strong> command:</p><p>The interesting part of the output for our needs are the two columns <strong>si</strong>\nand <strong>so</strong>, that counts the amount of memory swapped from/to the swap file. If\nyou see non zero counts in those two columns then there is swapping activity\nin your system.</p><p>Finally, the <strong>iostat</strong> command can be used to check the global I/O activity of\nthe system.</p><p>If your latency problem is due to Redis memory being swapped on disk you need\nto lower the memory pressure in your system, either adding more RAM if Redis\nis using more memory than the available, or avoiding running other memory\nhungry processes in the same system.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"LATENCY INDUCED BY SWAPPING (OPERATING SYSTEM PAGING)"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-latency-due-to-aof-and-disk-io\">Latency due to AOF and disk I/O</h2><p>Another source of latency is due to the Append Only File support on Redis.\nThe AOF basically uses two system calls to accomplish its work. One is\nwrite(2) that is used in order to write data to the append only file, and\nthe other one is fdatasync(2) that is used in order to flush the kernel\nfile buffer on disk in order to ensure the durability level specified by\nthe user.</p><p>Both the write(2) and fdatasync(2) calls can be source of latency.\nFor instance write(2) can block both when there is a system wide sync\nin progress, or when the output buffers are full and the kernel requires\nto flush on disk in order to accept new writes.</p><p>The fdatasync(2) call is a worse source of latency as with many combinations\nof kernels and file systems used it can take from a few milliseconds to\na few seconds to complete, especially in the case of some other process\ndoing I/O. For this reason when possible Redis does the fdatasync(2) call\nin a different thread since Redis 2.4.</p><p>We’ll see how configuration can affect the amount and source of latency\nwhen using the AOF file.</p><p>The AOF can be configured to perform an fsync on disk in three different\nways using the <strong>appendfsync</strong> configuration option (this setting can be\nmodified at runtime using the <strong>CONFIG SET</strong> command).</p><ul>\n<li><p>When appendfsync is set to the value of <strong>no</strong> Redis performs no fsync.\nIn this configuration the only source of latency can be write(2).\nWhen this happens usually there is no solution since simply the disk can’t\ncope with the speed at which Redis is receiving data, however this is\nuncommon if the disk is not seriously slowed down by other processes doing\nI/O.</p>\n</li>\n<li><p>When appendfsync is set to the value of <strong>everysec</strong> Redis performs an\nfsync every second. It uses a different thread, and if the fsync is still\nin progress Redis uses a buffer to delay the write(2) call up to two seconds\n(since write would block on Linux if an fsync is in progress against the\nsame file). However if the fsync is taking too long Redis will eventually\nperform the write(2) call even if the fsync is still in progress, and this\ncan be a source of latency.</p>\n</li>\n<li><p>When appendfsync is set to the value of <strong>always</strong> an fsync is performed\nat every write operation before replying back to the client with an OK code\n(actually Redis will try to cluster many commands executed at the same time\ninto a single fsync). In this mode performances are very low in general and\nit is strongly recommended to use a fast disk and a file system implementation\nthat can perform the fsync in short time.</p>\n</li>\n</ul><p>When appendfsync is set to the value of <strong>no</strong> Redis performs no fsync.\nIn this configuration the only source of latency can be write(2).\nWhen this happens usually there is no solution since simply the disk can’t\ncope with the speed at which Redis is receiving data, however this is\nuncommon if the disk is not seriously slowed down by other processes doing\nI/O.</p><p>When appendfsync is set to the value of <strong>everysec</strong> Redis performs an\nfsync every second. It uses a different thread, and if the fsync is still\nin progress Redis uses a buffer to delay the write(2) call up to two seconds\n(since write would block on Linux if an fsync is in progress against the\nsame file). However if the fsync is taking too long Redis will eventually\nperform the write(2) call even if the fsync is still in progress, and this\ncan be a source of latency.</p><p>When appendfsync is set to the value of <strong>always</strong> an fsync is performed\nat every write operation before replying back to the client with an OK code\n(actually Redis will try to cluster many commands executed at the same time\ninto a single fsync). In this mode performances are very low in general and\nit is strongly recommended to use a fast disk and a file system implementation\nthat can perform the fsync in short time.</p><p>Most Redis users will use either the <strong>no</strong> or <strong>everysec</strong> setting for the\nappendfsync configuration directive. The suggestion for minimum latency is\nto avoid other processes doing I/O in the same system.\nUsing an SSD disk can help as well, but usually even non SSD disks perform\nwell with the append only file if the disk is spare as Redis writes\nto the append only file without performing any seek.</p><p>If you want to investigate your latency issues related to the append only\nfile you can use the strace command under Linux:</p><p>The above command will show all the fdatasync(2) system calls performed by\nRedis in the main thread. With the above command you’ll not see the\nfdatasync system calls performed by the background thread when the\nappendfsync config option is set to <strong>everysec</strong>. In order to do so\njust add the -f switch to strace.</p><p>If you wish you can also see both fdatasync and write system calls with the\nfollowing command:</p><p>However since write(2) is also used in order to write data to the client\nsockets this will likely show too many things unrelated to disk I/O.\nApparently there is no way to tell strace to just show slow system calls so\nI use the following command:</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"LATENCY DUE TO AOF AND DISK I/O"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-latency-generated-by-expires\">Latency generated by expires</h2><p>Redis evict expired keys in two ways:</p><ul>\n<li>One <em>lazy</em> way expires a key when it is requested by a command, but it is found to be already expired.</li>\n<li>One <em>active</em> way expires a few keys every 100 milliseconds.</li>\n</ul><p>The active expiring is designed to be adaptive. An expire cycle is started every 100 milliseconds (10 times per second), and will do the following:</p><ul>\n<li>Sample <code>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP</code> keys, evicting all the keys already expired.</li>\n<li>If the more than 25% of the keys were found expired, repeat.</li>\n</ul><p>Given that <code>ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP</code> is set to 20 by default, and the process is performed ten times per second, usually just 200 keys per second are actively expired. This is enough to clean the DB fast enough even when already expired keys are not accessed for a long time, so that the <em>lazy</em> algorithm does not help. At the same time expiring just 200 keys per second has no effects in the latency a Redis instance.</p><p>However the algorithm is adaptive and will loop if it founds more than 25% of keys already expired in the set of sampled keys. But given that we run the algorithm ten times per second, this means that the unlucky event of more than 25% of the keys in our random sample are expiring at least <em>in the same second</em>.</p><p>Basically this means that <strong>if the database has many many keys expiring in the same second, and these make up at least 25% of the current population of keys with an expire set</strong>, Redis can block in order to get the percentage of keys already expired below 25%.</p><p>This approach is needed in order to avoid using too much memory for keys that area already expired, and usually is absolutely harmless since it’s strange that a big number of keys are going to expire in the same exact second, but it is not impossible that the user used <code>EXPIREAT</code> extensively with the same Unix time.</p><p>In short: be aware that many keys expiring at the same moment can be a source of latency.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"LATENCY GENERATED BY EXPIRES"},{"content":"<h2 id=\"redis-latency-problems-troubleshooting-redis-software-watchdog\">Redis software watchdog</h2><p>Redis 2.6 introduces the <em>Redis Software Watchdog</em> that is a debugging tool\ndesigned to track those latency problems that for one reason or the other\nescaped an analysis using normal tools.</p><p>The software watchdog is an experimental feature. While it is designed to\nbe used in production environments care should be taken to backup the database\nbefore proceeding as it could possibly have unexpected interactions with the\nnormal execution of the Redis server.</p><p>It is important to use it only as <em>last resort</em> when there is no way to track the issue by other means.</p><p>This is how this feature works:</p><ul>\n<li>The user enables the software watchdog using the <code>CONFIG SET</code> command.</li>\n<li>Redis starts monitoring itself constantly.</li>\n<li>If Redis detects that the server is blocked into some operation that is not returning fast enough, and that may be the source of the latency issue, a low level report about where the server is blocked is dumped on the log file.</li>\n<li>The user contacts the developers writing a message in the Redis Google Group, including the watchdog report in the message.</li>\n</ul><p>Note that this feature can not be enabled using the redis.conf file, because it is designed to be enabled only in already running instances and only for debugging purposes.</p><p>To enable the feature just use the following:</p><p>The period is specified in milliseconds. In the above example I specified to log latency issues only if the server detects a delay of 500 milliseconds or greater. The minimum configurable period is 200 milliseconds.</p><p>When you are done with the software watchdog you can turn it off setting the <code>watchdog-period</code> parameter to 0. <strong>Important:</strong> remember to do this because keeping the instance with the watchdog turned on for a longer time than needed is generally not a good idea.</p><p>The following is an example of what you’ll see printed in the log file once the software watchdog detects a delay longer than the configured one:</p><p>Note: in the example the <strong>DEBUG SLEEP</strong> command was used in order to block the server. The stack trace is different if the server blocks in a different context.</p><p>If you happen to collect multiple watchdog stack traces you are encouraged to send everything to the Redis Google Group: the more traces we obtain, the simpler it will be to understand what the problem with your instance is.</p>","link":"./alpha/topics/latency.html","spaLink":"#/alpha/topics/latency","title":"REDIS SOFTWARE WATCHDOG"},{"content":"<h1 id=\"redis-cluster-tutorial\">Redis cluster tutorial</h1><p>This document is a gentle introduction to Redis Cluster, that does not use\ncomplex to understand distributed systems concepts. It provides instructions\nabout how to setup a cluster, test, and operate it, without\ngoing into the details that are covered in\nthe <a href=\"/topics/cluster-spec\">Redis Cluster specification</a> but just describing\nhow the system behaves from the point of view of the user.</p><p>However this tutorial tries to provide information about the availability\nand consistency characteristics of Redis Cluster from the point of view\nof the final user, stated in a simple to understand way.</p><p>Note this tutorial requires Redis version 3.0 or higher.</p><p>If you plan to run a serious Redis Cluster deployment, the\nmore formal specification is a suggested reading, even if not\nstrictly required. However it is a good idea to start from this document,\nplay with Redis Cluster some time, and only later read the specification.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER TUTORIAL"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-101\">Redis Cluster 101</h2><p>Redis Cluster provides a way to run a Redis installation where data is\n<strong>automatically sharded across multiple Redis nodes</strong>.</p><p>Redis Cluster also provides <strong>some degree of availability during partitions</strong>,\nthat is in practical terms the ability to continue the operations when\nsome nodes fail or are not able to communicate. However the cluster stops\nto operate in the event of larger failures (for example when the majority of\nmasters are unavailable).</p><p>So in practical terms, what you get with Redis Cluster?</p><ul>\n<li>The ability to <strong>automatically split your dataset among multiple nodes</strong>.</li>\n<li>The ability to <strong>continue operations when a subset of the nodes are experiencing failures</strong> or are unable to communicate with the rest of the cluster.</li>\n</ul>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER 101"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-tcp-ports\">Redis Cluster TCP ports</h2><p>Every Redis Cluster node requires two TCP connections open. The normal Redis\nTCP port used to serve clients, for example 6379, plus the port obtained by\nadding 10000 to the data port, so 16379 in the example.</p><p>This second <em>high</em> port is used for the Cluster bus, that is a node-to-node\ncommunication channel using a binary protocol. The Cluster bus is used by\nnodes for failure detection, configuration update, failover authorization\nand so forth. Clients should never try to communicate with the cluster bus\nport, but always with the normal Redis command port, however make sure you\nopen both ports in your firewall, otherwise Redis cluster nodes will be\nnot able to communicate.</p><p>The command port and cluster bus port offset is fixed and is always 10000.</p><p>Note that for a Redis Cluster to work properly you need, for each node:</p><p>If you don’t open both TCP ports, your cluster will not work as expected.</p><p>The cluster bus uses a different, binary protocol, for node to node data\nexchange, which is more suited to exchange information between nodes using\nlittle bandwidth and processing time.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER TCP PORTS"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-and-docker\">Redis Cluster and Docker</h2><p>Currently Redis Cluster does not support NATted environments and in general\nenvironments where IP addresses or TCP ports are remapped.</p><p>Docker uses a technique called <em>port mapping</em>: programs running inside Docker\ncontainers may be exposed with a different port compared to the one the\nprogram believes to be using. This is useful in order to run multiple\ncontainers using the same ports, at the same time, in the same server.</p><p>In order to make Docker compatible with Redis Cluster you need to use\nthe <strong>host networking mode</strong> of Docker. Please check the <code>--net=host</code> option\nin the <a href=\"https://docs.docker.com/engine/userguide/networking/dockernetworks/\">Docker documentation</a> for more information.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER AND DOCKER"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-data-sharding\">Redis Cluster data sharding</h2><p>Redis Cluster does not use consistent hashing, but a different form of sharding\nwhere every key is conceptually part of what we call an <strong>hash slot</strong>.</p><p>There are 16384 hash slots in Redis Cluster, and to compute what is the hash\nslot of a given key, we simply take the CRC16 of the key modulo\n16384.</p><p>Every node in a Redis Cluster is responsible for a subset of the hash slots,\nso for example you may have a cluster with 3 nodes, where:</p><ul>\n<li>Node A contains hash slots from 0 to 5500.</li>\n<li>Node B contains hash slots from 5501 to 11000.</li>\n<li>Node C contains hash slots from 11001 to 16383.</li>\n</ul><p>This allows to add and remove nodes in the cluster easily. For example if\nI want to add a new node D, I need to move some hash slot from nodes A, B, C\nto D. Similarly if I want to remove node A from the cluster I can just\nmove the hash slots served by A to B and C. When the node A will be empty\nI can remove it from the cluster completely.</p><p>Because moving hash slots from a node to another does not require to stop\noperations, adding and removing nodes, or changing the percentage of hash\nslots hold by nodes, does not require any downtime.</p><p>Redis Cluster supports multiple key operations as long as all the keys involved\ninto a single command execution (or whole transaction, or Lua script\nexecution) all belong to the same hash slot. The user can force multiple keys\nto be part of the same hash slot by using a concept called <em>hash tags</em>.</p><p>Hash tags are documented in the Redis Cluster specification, but the gist is\nthat if there is a substring between {} brackets in a key, only what is\ninside the string is hashed, so for example <code>this{foo}key</code> and <code>another{foo}key</code>\nare guaranteed to be in the same hash slot, and can be used together in a\ncommand with multiple keys as arguments.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER DATA SHARDING"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-master-slave-model\">Redis Cluster master-slave model</h2><p>In order to remain available when a subset of master nodes are failing or are\nnot able to communicate with the majority of nodes, Redis Cluster uses a\nmaster-slave model where every hash slot has from 1 (the master itself) to N\nreplicas (N-1 additional slaves nodes).</p><p>In our example cluster with nodes A, B, C, if node B fails the cluster is not\nable to continue, since we no longer have a way to serve hash slots in the\nrange 5501-11000.</p><p>However when the cluster is created (or at a latter time) we add a slave\nnode to every master, so that the final cluster is composed of A, B, C\nthat are masters nodes, and A1, B1, C1 that are slaves nodes, the system is\nable to continue if node B fails.</p><p>Node B1 replicates B, and B fails, the cluster will promote node B1 as the new\nmaster and will continue to operate correctly.</p><p>However note that if nodes B and B1 fail at the same time Redis Cluster is not\nable to continue to operate.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER MASTER-SLAVE MODEL"},{"content":"<h2 id=\"redis-cluster-tutorial-redis-cluster-consistency-guarantees\">Redis Cluster consistency guarantees</h2><p>Redis Cluster is not able to guarantee <strong>strong consistency</strong>. In practical\nterms this means that under certain conditions it is possible that Redis\nCluster will lose writes that were acknowledged by the system to the client.</p><p>The first reason why Redis Cluster can lose writes is because it uses\nasynchronous replication. This means that during writes the following\nhappens:</p><ul>\n<li>Your client writes to the master B.</li>\n<li>The master B replies OK to your client.</li>\n<li>The master B propagates the write to its slaves B1, B2 and B3.</li>\n</ul><p>As you can see B does not wait for an acknowledge from B1, B2, B3 before\nreplying to the client, since this would be a prohibitive latency penalty\nfor Redis, so if your client writes something, B acknowledges the write,\nbut crashes before being able to send the write to its slaves, one of the\nslaves (that did not receive the write) can be promoted to master, losing\nthe write forever.</p><p>This is <strong>very similar to what happens</strong> with most databases that are\nconfigured to flush data to disk every second, so it is a scenario you\nare already able to reason about because of past experiences with traditional\ndatabase systems not involving distributed systems. Similarly you can\nimprove consistency by forcing the database to flush data on disk before\nreplying to the client, but this usually results into prohibitively low\nperformance. That would be the equivalent of synchronous replication in\nthe case of Redis Cluster.</p><p>Basically there is a trade-off to take between performance and consistency.</p><p>Redis Cluster has support for synchronous writes when absolutely needed,\nimplemented via the <code>WAIT</code> command, this makes losing writes a lot less\nlikely, however note that Redis Cluster does not implement strong consistency\neven when synchronous replication is used: it is always possible under more\ncomplex failure scenarios that a slave that was not able to receive the write\nis elected as master.</p><p>There is another notable scenario where Redis Cluster will lose writes, that\nhappens during a network partition where a client is isolated with a minority\nof instances including at least a master.</p><p>Take as an example our 6 nodes cluster composed of A, B, C, A1, B1, C1,\nwith 3 masters and 3 slaves. There is also a client, that we will call Z1.</p><p>After a partition occurs, it is possible that in one side of the\npartition we have A, C, A1, B1, C1, and in the other side we have B and Z1.</p><p>Z1 is still able to write to B, that will accept its writes. If the\npartition heals in a very short time, the cluster will continue normally.\nHowever if the partition lasts enough time for B1 to be promoted to master\nin the majority side of the partition, the writes that Z1 is sending to B\nwill be lost.</p><p>Note that there is a <strong>maximum window</strong> to the amount of writes Z1 will be able\nto send to B: if enough time has elapsed for the majority side of the\npartition to elect a slave as master, every master node in the minority\nside stops accepting writes.</p><p>This amount of time is a very important configuration directive of Redis\nCluster, and is called the <strong>node timeout</strong>.</p><p>After node timeout has elapsed, a master node is considered to be failing,\nand can be replaced by one of its replicas.\nSimilarly after node timeout has elapsed without a master node to be able\nto sense the majority of the other master nodes, it enters an error state\nand stops accepting writes.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER CONSISTENCY GUARANTEES"},{"content":"<h1 id=\"redis-cluster-configuration-parameters\">Redis Cluster configuration parameters</h1><p>We are about to create an example cluster deployment. Before to continue\nlet’s introduce the configuration parameters that Redis Cluster introduces\nin the <code>redis.conf</code> file. Some will be obvious, others will be more clear\nas you continue reading.</p><ul>\n<li><strong>cluster-enabled <code>&lt;yes/no&gt;</code></strong>: If yes enables Redis Cluster support in a specific Redis instance. Otherwise the instance starts as a stand alone instance as usually.</li>\n<li><strong>cluster-config-file <code>&lt;filename&gt;</code></strong>: Note that despite the name of this option, this is not an user editable configuration file, but the file where a Redis Cluster node automatically persists the cluster configuration (the state, basically) every time there is a change, in order to be able to re-read it at startup. The file lists things like the other nodes in the cluster, their state, persistent variables, and so forth. Often this file is rewritten and flushed on disk as a result of some message reception.</li>\n<li><strong>cluster-node-timeout <code>&lt;milliseconds&gt;</code></strong>: The maximum amount of time a Redis Cluster node can be unavailable, without it being considered as failing. If a master node is not reachable for more than the specified amount of time, it will be failed over by its slaves. This parameter controls other important things in Redis Cluster. Notably, every node that can’t reach the majority of master nodes for the specified amount of time, will stop accepting queries.</li>\n<li><strong>cluster-slave-validity-factor <code>&lt;factor&gt;</code></strong>: If set to zero, a slave will always try to failover a master, regardless of the amount of time the link between the master and the slave remained disconnected. If the value is positive, a maximum disconnection time is calculated as the <em>node timeout</em> value multiplied by the factor provided with this option, and if the node is a slave, it will not try to start a failover if the master link was disconnected for more than the specified amount of time. For example if the node timeout is set to 5 seconds, and the validity factor is set to 10, a slave disconnected from the master for more than 50 seconds will not try to failover its master. Note that any value different than zero may result in Redis Cluster to be unavailable after a master failure if there is no slave able to failover it. In that case the cluster will return back available only when the original master rejoins the cluster.</li>\n<li><strong>cluster-migration-barrier <code>&lt;count&gt;</code></strong>: Minimum number of slaves a master will remain connected with, for another slave to migrate to a master which is no longer covered by any slave. See the appropriate section about replica migration in this tutorial for more information.</li>\n<li><strong>cluster-require-full-coverage <code>&lt;yes/no&gt;</code></strong>: If this is set to yes, as it is by default, the cluster stops accepting writes if some percentage of the key space is not covered by any node. If the option is set to no, the cluster will still serve queries even if only requests about a subset of keys can be processed.</li>\n</ul>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REDIS CLUSTER CONFIGURATION PARAMETERS"},{"content":"<h1 id=\"creating-and-using-a-redis-cluster\">Creating and using a Redis Cluster</h1><p>Note: to deploy a Redis Cluster manually is <strong>very important to learn</strong> certain\noperation aspects of it. However if you want to get a cluster up and running\nASAP skip this section and the next one and go directly to <strong>Creating a Redis Cluster using the create-cluster script</strong>.</p><p>To create a cluster, the first thing we need is to have a few empty\nRedis instances running in <strong>cluster mode</strong>. This basically means that\nclusters are not created using normal Redis instances, but a special mode\nneeds to be configured so that the Redis instance will enable the Cluster\nspecific features and commands.</p><p>The following is a minimal Redis cluster configuration file:</p><p>As you can see what enables the cluster mode is simply the <code>cluster-enabled</code>\ndirective. Every instance also contains the path of a file where the\nconfiguration for this node is stored, that by default is <code>nodes.conf</code>.\nThis file is never touched by humans, it is simply generated at startup\nby the Redis Cluster instances, and updated every time it is needed.</p><p>Note that the <strong>minimal cluster</strong> that works as expected requires to contain\nat least three master nodes. For your first tests it is strongly suggested\nto start a six nodes cluster with three masters and three slaves.</p><p>To do so, enter a new directory, and create the following directories named\nafter the port number of the instance we’ll run inside any given directory.</p><p>Something like:</p><p>Create a <code>redis.conf</code> file inside each of the directories, from 7000 to 7005.\nAs a template for your configuration file just use the small example above,\nbut make sure to replace the port number <code>7000</code> with the right port number\naccording to the directory name.</p><p>Now copy your redis-server executable, <strong>compiled from the latest sources in the unstable branch at GitHub</strong>, into the <code>cluster-test</code> directory, and finally open 6 terminal tabs in your favorite terminal application.</p><p>Start every instance like that, one every tab:</p><p>As you can see from the logs of every instance, since no <code>nodes.conf</code> file\nexisted, every node assigns itself a new ID.</p><p>This ID will be used forever by this specific instance in order for the instance\nto have a unique name in the context of the cluster. Every node\nremembers every other node using this IDs, and not by IP or port.\nIP addresses and ports may change, but the unique node identifier will never\nchange for all the life of the node. We call this identifier simply <strong>Node ID</strong>.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"CREATING AND USING A REDIS CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-creating-the-cluster\">Creating the cluster</h2><p>Now that we have a number of instances running, we need to create our\ncluster by writing some meaningful configuration to the nodes.</p><p>This is very easy to accomplish as we are helped by the Redis Cluster\ncommand line utility called <code>redis-trib</code>, a Ruby program\nexecuting special commands on instances in order to create new clusters,\ncheck or reshard an existing cluster, and so forth.</p><p>The <code>redis-trib</code> utility is in the <code>src</code> directory of the Redis source code\ndistribution.\nYou need to install <code>redis</code> gem to be able to run <code>redis-trib</code>.</p><p> To create your cluster simply type:</p><p>The command used here is <strong>create</strong>, since we want to create a new cluster.\nThe option <code>--replicas 1</code> means that we want a slave for every master created.\nThe other arguments are the list of addresses of the instances I want to use\nto create the new cluster.</p><p>Obviously the only setup with our requirements is to create a cluster with\n3 masters and 3 slaves.</p><p>Redis-trib will propose you a configuration. Accept typing <strong>yes</strong>.\nThe cluster will be configured and <em>joined</em>, that means, instances will be\nbootstrapped into talking with each other. Finally if everything went ok\nyou’ll see a message like that:</p><p>This means that there is at least a master instance serving each of the\n16384 slots available.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"CREATING THE CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-creating-a-redis-cluster-using-the-create-cluster-script\">Creating a Redis Cluster using the create-cluster script</h2><p>If you don’t want to create a Redis Cluster by configuring and executing\nindividual instances manually as explained above, there is a much simpler\nsystem (but you’ll not learn the same amount of operational details).</p><p>Just check <code>utils/create-cluster</code> directory in the Redis distribution.\nThere is a script called <code>create-cluster</code> inside (same name as the directory\nit is contained into), it’s a simple bash script. In order to start\na 6 nodes cluster with 3 masters and 3 slaves just type the following\ncommands:</p><p>Reply to <code>yes</code> in step 2 when the <code>redis-trib</code> utility wants you to accept\nthe cluster layout.</p><p>You can now interact with the cluster, the first node will start at port 30001\nby default. When you are done, stop the cluster with:</p><p>Please read the <code>README</code> inside this directory for more information on how\nto run the script.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"CREATING A REDIS CLUSTER USING THE CREATE-CLUSTER SCRIPT"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-playing-with-the-cluster\">Playing with the cluster</h2><p>At this stage one of the problems with Redis Cluster is the lack of\nclient libraries implementations.</p><p>I’m aware of the following implementations:</p><ul>\n<li><a href=\"http://github.com/antirez/redis-rb-cluster\">redis-rb-cluster</a> is a Ruby implementation written by me (@antirez) as a reference for other languages. It is a simple wrapper around the original redis-rb, implementing the minimal semantics to talk with the cluster efficiently.</li>\n<li><a href=\"https://github.com/Grokzen/redis-py-cluster\">redis-py-cluster</a> A port of redis-rb-cluster to Python. Supports majority of <em>redis-py</em> functionality. Is in active development.</li>\n<li>The popular <a href=\"https://github.com/nrk/predis\">Predis</a> has support for Redis Cluster, the support was recently updated and is in active development.</li>\n<li>The most used Java client, <a href=\"https://github.com/xetorthio/jedis\">Jedis</a> recently added support for Redis Cluster, see the <em>Jedis Cluster</em> section in the project README.</li>\n<li><a href=\"https://github.com/StackExchange/StackExchange.Redis\">StackExchange.Redis</a> offers support for C# (and should work fine with most .NET languages; VB, F#, etc)</li>\n<li><a href=\"https://github.com/thunks/thunk-redis\">thunk-redis</a> offers support for Node.js and io.js, it is a thunk/promise-based redis client with pipelining and cluster.</li>\n<li><a href=\"https://github.com/chasex/redis-go-cluster\">redis-go-cluster</a> is an implementation of Redis Cluster for the Go language using the <a href=\"https://github.com/garyburd/redigo\">Redigo library client</a> as the base client. Implements MGET/MSET via result aggregation.</li>\n<li>The <code>redis-cli</code> utility in the unstable branch of the Redis repository at GitHub implements a very basic cluster support when started with the <code>-c</code> switch.</li>\n</ul><p>An easy way to test Redis Cluster is either to try any of the above clients\nor simply the <code>redis-cli</code> command line utility. The following is an example\nof interaction using the latter:</p><p><strong>Note:</strong> if you created the cluster using the script your nodes may listen\nto different ports, starting from 30001 by default.</p><p>The redis-cli cluster support is very basic so it always uses the fact that\nRedis Cluster nodes are able to redirect a client to the right node.\nA serious client is able to do better than that, and cache the map between\nhash slots and nodes addresses, to directly use the right connection to the\nright node. The map is refreshed only when something changed in the cluster\nconfiguration, for example after a failover or after the system administrator\nchanged the cluster layout by adding or removing nodes.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"PLAYING WITH THE CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-writing-an-example-app-with-redis-rb-cluster\">Writing an example app with redis-rb-cluster</h2><p>Before going forward showing how to operate the Redis Cluster, doing things\nlike a failover, or a resharding, we need to create some example application\nor at least to be able to understand the semantics of a simple Redis Cluster\nclient interaction.</p><p>In this way we can run an example and at the same time try to make nodes\nfailing, or start a resharding, to see how Redis Cluster behaves under real\nworld conditions. It is not very helpful to see what happens while nobody\nis writing to the cluster.</p><p>This section explains some basic usage of redis-rb-cluster showing two\nexamples. The first is the following, and is the <code>example.rb</code> file inside\nthe redis-rb-cluster distribution:</p><p>The application does a very simple thing, it sets keys in the form <code>foo&lt;number&gt;</code> to <code>number</code>, one after the other. So if you run the program the result is the\nfollowing stream of commands:</p><ul>\n<li>SET foo0 0</li>\n<li>SET foo1 1</li>\n<li>SET foo2 2</li>\n<li>And so forth…</li>\n</ul><p>The program looks more complex than it should usually as it is designed to\nshow errors on the screen instead of exiting with an exception, so every\noperation performed with the cluster is wrapped by <code>begin</code> <code>rescue</code> blocks.</p><p>The <strong>line 7</strong> is the first interesting line in the program. It creates the\nRedis Cluster object, using as argument a list of <em>startup nodes</em>, the maximum\nnumber of connections this object is allowed to take against different nodes,\nand finally the timeout after a given operation is considered to be failed.</p><p>The startup nodes don’t need to be all the nodes of the cluster. The important\nthing is that at least one node is reachable. Also note that redis-rb-cluster\nupdates this list of startup nodes as soon as it is able to connect with the\nfirst node. You should expect such a behavior with any other serious client.</p><p>Now that we have the Redis Cluster object instance stored in the <strong>rc</strong> variable\nwe are ready to use the object like if it was a normal Redis object instance.</p><p>This is exactly what happens in <strong>line 11 to 19</strong>: when we restart the example\nwe don’t want to start again with <code>foo0</code>, so we store the counter inside\nRedis itself. The code above is designed to read this counter, or if the\ncounter does not exist, to assign it the value of zero.</p><p>However note how it is a while loop, as we want to try again and again even\nif the cluster is down and is returning errors. Normal applications don’t need\nto be so careful.</p><p><strong>Lines between 21 and 30</strong> start the main loop where the keys are set or\nan error is displayed.</p><p>Note the <code>sleep</code> call at the end of the loop. In your tests you can remove\nthe sleep if you want to write to the cluster as fast as possible (relatively\nto the fact that this is a busy loop without real parallelism of course, so\nyou’ll get the usually 10k ops/second in the best of the conditions).</p><p>Normally writes are slowed down in order for the example application to be\neasier to follow by humans.</p><p>Starting the application produces the following output:</p><p>This is not a very interesting program and we’ll use a better one in a moment\nbut we can already see what happens during a resharding when the program\nis running.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"WRITING AN EXAMPLE APP WITH REDIS-RB-CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-resharding-the-cluster\">Resharding the cluster</h2><p>Now we are ready to try a cluster resharding. To do this please\nkeep the example.rb program running, so that you can see if there is some\nimpact on the program running. Also you may want to comment the <code>sleep</code>\ncall in order to have some more serious write load during resharding.</p><p>Resharding basically means to move hash slots from a set of nodes to another\nset of nodes, and like cluster creation it is accomplished using the\nredis-trib utility.</p><p>To start a resharding just type:</p><p>You only need to specify a single node, redis-trib will find the other nodes\nautomatically.</p><p>Currently redis-trib is only able to reshard with the administrator support,\nyou can’t just say move 5% of slots from this node to the other one (but\nthis is pretty trivial to implement). So it starts with questions. The first\nis how much a big resharding do you want to do:</p><p>We can try to reshard 1000 hash slots, that should already contain a non\ntrivial amount of keys if the example is still running without the sleep\ncall.</p><p>Then redis-trib needs to know what is the target of the resharding, that is,\nthe node that will receive the hash slots.\nI’ll use the first master node, that is, 127.0.0.1:7000, but I need\nto specify the Node ID of the instance. This was already printed in a\nlist by redis-trib, but I can always find the ID of a node with the following\ncommand if I need:</p><p>Ok so my target node is 97a3a64667477371c4479320d683e4c8db5858b1.</p><p>Now you’ll get asked from what nodes you want to take those keys.\nI’ll just type <code>all</code> in order to take a bit of hash slots from all the\nother master nodes.</p><p>After the final confirmation you’ll see a message for every slot that\nredis-trib is going to move from a node to another, and a dot will be printed\nfor every actual key moved from one side to the other.</p><p>While the resharding is in progress you should be able to see your\nexample program running unaffected. You can stop and restart it multiple times\nduring the resharding if you want.</p><p>At the end of the resharding, you can test the health of the cluster with\nthe following command:</p><p>All the slots will be covered as usually, but this time the master at\n127.0.0.1:7000 will have more hash slots, something around 6461.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"RESHARDING THE CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-scripting-a-resharding-operation\">Scripting a resharding operation</h2><p>Reshardings can be performed automatically without the need to manually\nenter the parameters in an interactive way. This is possible using a command\nline like the following:</p><p>This allows to build some automatism if you are likely to reshard often,\nhowever currently there is no way for <code>redis-trib</code> to automatically\nrebalance the cluster checking the distribution of keys across the cluster\nnodes and intelligently moving slots as needed. This feature will be added\nin the future.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"SCRIPTING A RESHARDING OPERATION"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-a-more-interesting-example-application\">A more interesting example application</h2><p>The example application we wrote early is not very good.\nIt writes to the cluster in a simple way without even checking if what was\nwritten is the right thing.</p><p>From our point of view the cluster receiving the writes could just always\nwrite the key <code>foo</code> to <code>42</code> to every operation, and we would not notice at\nall.</p><p>So in the <code>redis-rb-cluster</code> repository, there is a more interesting application\nthat is called <code>consistency-test.rb</code>. It uses a set of counters, by default 1000, and sends <code>INCR</code> commands in order to increment the counters.</p><p>However instead of just writing, the application does two additional things:</p><ul>\n<li>When a counter is updated using <code>INCR</code>, the application remembers the write.</li>\n<li>It also reads a random counter before every write, and check if the value is what we expected it to be, comparing it with the value it has in memory.</li>\n</ul><p>What this means is that this application is a simple <strong>consistency checker</strong>,\nand is able to tell you if the cluster lost some write, or if it accepted\na write that we did not receive acknowledgment for. In the first case we’ll\nsee a counter having a value that is smaller than the one we remember, while\nin the second case the value will be greater.</p><p>Running the consistency-test application produces a line of output every\nsecond:</p><p>The line shows the number of <strong>R</strong>eads and <strong>W</strong>rites performed, and the\nnumber of errors (query not accepted because of errors since the system was\nnot available).</p><p>If some inconsistency is found, new lines are added to the output.\nThis is what happens, for example, if I reset a counter manually while\nthe program is running:</p><p>When I set the counter to 0 the real value was 114, so the program reports\n114 lost writes (<code>INCR</code> commands that are not remembered by the cluster).</p><p>This program is much more interesting as a test case, so we’ll use it\nto test the Redis Cluster failover.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"A MORE INTERESTING EXAMPLE APPLICATION"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-testing-the-failover\">Testing the failover</h2><p>Note: during this test, you should take a tab open with the consistency test\napplication running.</p><p>In order to trigger the failover, the simplest thing we can do (that is also\nthe semantically simplest failure that can occur in a distributed system)\nis to crash a single process, in our case a single master.</p><p>We can identify a cluster and crash it with the following command:</p><p>Ok, so 7000, 7001, and 7002 are masters. Let’s crash node 7002 with the\n<strong>DEBUG SEGFAULT</strong> command:</p><p>Now we can look at the output of the consistency test to see what it reported.</p><p>As you can see during the failover the system was not able to accept 578 reads and 577 writes, however no inconsistency was created in the database. This may\nsound unexpected as in the first part of this tutorial we stated that Redis\nCluster can lose writes during the failover because it uses asynchronous\nreplication. What we did not say is that this is not very likely to happen\nbecause Redis sends the reply to the client, and the commands to replicate\nto the slaves, about at the same time, so there is a very small window to\nlose data. However the fact that it is hard to trigger does not mean that it\nis impossible, so this does not change the consistency guarantees provided\nby Redis cluster.</p><p>We can now check what is the cluster setup after the failover (note that\nin the meantime I restarted the crashed instance so that it rejoins the\ncluster as a slave):</p><p>Now the masters are running on ports 7000, 7001 and 7005. What was previously\na master, that is the Redis instance running on port 7002, is now a slave of\n7005.</p><p>The output of the <code>CLUSTER NODES</code> command may look intimidating, but it is actually pretty simple, and is composed of the following tokens:</p><ul>\n<li>Node ID</li>\n<li>ip:port</li>\n<li>flags: master, slave, myself, fail, …</li>\n<li>if it is a slave, the Node ID of the master</li>\n<li>Time of the last pending PING still waiting for a reply.</li>\n<li>Time of the last PONG received.</li>\n<li>Configuration epoch for this node (see the Cluster specification).</li>\n<li>Status of the link to this node.</li>\n<li>Slots served…</li>\n</ul>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"TESTING THE FAILOVER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-manual-failover\">Manual failover</h2><p>Sometimes it is useful to force a failover without actually causing any problem\non a master. For example in order to upgrade the Redis process of one of the\nmaster nodes it is a good idea to failover it in order to turn it into a slave\nwith minimal impact on availability.</p><p>Manual failovers are supported by Redis Cluster using the <code>CLUSTER FAILOVER</code>\ncommand, that must be executed in one of the <strong>slaves</strong> of the master you want\nto failover.</p><p>Manual failovers are special and are safer compared to failovers resulting from\nactual master failures, since they occur in a way that avoid data loss in the\nprocess, by switching clients from the original master to the new master only\nwhen the system is sure that the new master processed all the replication stream\nfrom the old one.</p><p>This is what you see in the slave log when you perform a manual failover:</p><p>Basically clients connected to the master we are failing over are stopped.\nAt the same time the master sends its replication offset to the slave, that\nwaits to reach the offset on its side. When the replication offset is reached,\nthe failover starts, and the old master is informed about the configuration\nswitch. When the clients are unblocked on the old master, they are redirected\nto the new master.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"MANUAL FAILOVER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-adding-a-new-node\">Adding a new node</h2><p>Adding a new node is basically the process of adding an empty node and then\nmoving some data into it, in case it is a new master, or telling it to\nsetup as a replica of a known node, in case it is a slave.</p><p>We’ll show both, starting with the addition of a new master instance.</p><p>In both cases the first step to perform is <strong>adding an empty node</strong>.</p><p>This is as simple as to start a new node in port 7006 (we already used\nfrom 7000 to 7005 for our existing 6 nodes) with the same configuration\nused for the other nodes, except for the port number, so what you should\ndo in order to conform with the setup we used for the previous nodes:</p><ul>\n<li>Create a new tab in your terminal application.</li>\n<li>Enter the <code>cluster-test</code> directory.</li>\n<li>Create a directory named <code>7006</code>.</li>\n<li>Create a redis.conf file inside, similar to the one used for the other nodes but using 7006 as port number.</li>\n<li>Finally start the server with <code>../redis-server ./redis.conf</code></li>\n</ul><p>At this point the server should be running.</p><p>Now we can use <strong>redis-trib</strong> as usually in order to add the node to\nthe existing cluster.</p><p>As you can see I used the <strong>add-node</strong> command specifying the address of the\nnew node as first argument, and the address of a random existing node in the\ncluster as second argument.</p><p>In practical terms redis-trib here did very little to help us, it just\nsent a <code>CLUSTER MEET</code> message to the node, something that is also possible\nto accomplish manually. However redis-trib also checks the state of the\ncluster before to operate, so it is a good idea to perform cluster operations\nalways via redis-trib even when you know how the internals work.</p><p>Now we can connect to the new node to see if it really joined the cluster:</p><p>Note that since this node is already connected to the cluster it is already\nable to redirect client queries correctly and is generally speaking part of\nthe cluster. However it has two peculiarities compared to the other masters:</p><ul>\n<li>It holds no data as it has no assigned hash slots.</li>\n<li>Because it is a master without assigned slots, it does not participate in the election process when a slave wants to become a master.</li>\n</ul><p>Now it is possible to assign hash slots to this node using the resharding\nfeature of <code>redis-trib</code>. It is basically useless to show this as we already\ndid in a previous section, there is no difference, it is just a resharding\nhaving as a target the empty node.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"ADDING A NEW NODE"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-adding-a-new-node-as-a-replica\">Adding a new node as a replica</h2><p>Adding a new Replica can be performed in two ways. The obvious one is to\nuse redis-trib again, but with the —slave option, like this:</p><p>Note that the command line here is exactly like the one we used to add\na new master, so we are not specifying to which master we want to add\nthe replica. In this case what happens is that redis-trib will add the new\nnode as replica of a random master among the masters with less replicas.</p><p>However you can specify exactly what master you want to target with your\nnew replica with the following command line:</p><p>This way we assign the new replica to a specific master.</p><p>A more manual way to add a replica to a specific master is to add the new\nnode as an empty master, and then turn it into a replica using the\n<code>CLUSTER REPLICATE</code> command. This also works if the node was added as a slave\nbut you want to move it as a replica of a different master.</p><p>For example in order to add a replica for the node 127.0.0.1:7005 that is\ncurrently serving hash slots in the range 11423-16383, that has a Node ID\n3c3a0c74aae0b56170ccb03a76b60cfe7dc1912e, all I need to do is to connect\nwith the new node (already added as empty master) and send the command:</p><p>That’s it. Now we have a new replica for this set of hash slots, and all\nthe other nodes in the cluster already know (after a few seconds needed to\nupdate their config). We can verify with the following command:</p><p>The node 3c3a0c… now has two slaves, running on ports 7002 (the existing one) and 7006 (the new one).</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"ADDING A NEW NODE AS A REPLICA"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-removing-a-node\">Removing a node</h2><p>To remove a slave node just use the <code>del-node</code> command of redis-trib:</p><p>The first argument is just a random node in the cluster, the second argument\nis the ID of the node you want to remove.</p><p>You can remove a master node in the same way as well, <strong>however in order to\nremove a master node it must be empty</strong>. If the master is not empty you need\nto reshard data away from it to all the other master nodes before.</p><p>An alternative to remove a master node is to perform a manual failover of it\nover one of its slaves and remove the node after it turned into a slave of the\nnew master. Obviously this does not help when you want to reduce the actual\nnumber of masters in your cluster, in that case, a resharding is needed.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REMOVING A NODE"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-replicas-migration\">Replicas migration</h2><p>In Redis Cluster it is possible to reconfigure a slave to replicate with a\ndifferent master at any time just using the following command:</p><p>However there is a special scenario where you want replicas to move from one\nmaster to another one automatically, without the help of the system administrator.\nThe automatic reconfiguration of replicas is called <em>replicas migration</em> and is\nable to improve the reliability of a Redis Cluster.</p><p>Note: you can read the details of replicas migration in the <a href=\"/topics/cluster-spec\">Redis Cluster Specification</a>, here we’ll only provide some information about the\ngeneral idea and what you should do in order to benefit from it.</p><p>The reason why you may want to let your cluster replicas to move from one master\nto another under certain condition, is that usually the Redis Cluster is as\nresistant to failures as the number of replicas attached to a given master.</p><p>For example a cluster where every master has a single replica can’t continue\noperations if the master and its replica fail at the same time, simply because\nthere is no other instance to have a copy of the hash slots the master was\nserving. However while netsplits are likely to isolate a number of nodes\nat the same time, many other kind of failures, like hardware or software failures\nlocal to a single node, are a very notable class of failures that are unlikely\nto happen at the same time, so it is possible that in your cluster where\nevery master has a slave, the slave is killed at 4am, and the master is killed\nat 6am. This still will result in a cluster that can no longer operate.</p><p>To improve reliability of the system we have the option to add additional\nreplicas to every master, but this is expensive. Replica migration allows to\nadd more slaves to just a few masters. So you have 10 masters with 1 slave\neach, for a total of 20 instances. However you add, for example, 3 instances\nmore as slaves of some of your masters, so certain masters will have more\nthan a single slave.</p><p>With replicas migration what happens is that if a master is left without\nslaves, a replica from a master that has multiple slaves will migrate to\nthe <em>orphaned</em> master. So after your slave goes down at 4am as in the example\nwe made above, another slave will take its place, and when the master\nwill fail as well at 5am, there is still a slave that can be elected so that\nthe cluster can continue to operate.</p><p>So what you should know about replicas migration in short?</p><ul>\n<li>The cluster will try to migrate a replica from the master that has the greatest number of replicas in a given moment.</li>\n<li>To benefit from replica migration you have just to add a few more replicas to a single master in your cluster, it does not matter what master.</li>\n<li>There is a configuration parameter that controls the replica migration feature that is called <code>cluster-migration-barrier</code>: you can read more about it in the example <code>redis.conf</code> file provided with Redis Cluster.</li>\n</ul>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"REPLICAS MIGRATION"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-upgrading-nodes-in-a-redis-cluster\">Upgrading nodes in a Redis Cluster</h2><p>Upgrading slave nodes is easy since you just need to stop the node and restart\nit with an updated version of Redis. If there are clients scaling reads using\nslave nodes, they should be able to reconnect to a different slave if a given\none is not available.</p><p>Upgrading masters is a bit more complex, and the suggested procedure is:</p><p>Following this procedure you should upgrade one node after the other until\nall the nodes are upgraded.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"UPGRADING NODES IN A REDIS CLUSTER"},{"content":"<h2 id=\"creating-and-using-a-redis-cluster-migrating-to-redis-cluster\">Migrating to Redis Cluster</h2><p>Users willing to migrate to Redis Cluster may have just a single master, or\nmay already using a preexisting sharding setup, where keys\nare split among N nodes, using some in-house algorithm or a sharding algorithm\nimplemented by their client library or Redis proxy.</p><p>In both cases it is possible to migrate to Redis Cluster easily, however\nwhat is the most important detail is if multiple-keys operations are used\nby the application, and how. There are three different cases:</p><p>The third case is not handled by Redis Cluster: the application requires to\nbe modified in order to don’t use multi keys operations or only use them in\nthe context of the same hash tag.</p><p>Case 1 and 2 are covered, so we’ll focus on those two cases, that are handled\nin the same way, so no distinction will be made in the documentation.</p><p>Assuming you have your preexisting data set split into N masters, where\nN=1 if you have no preexisting sharding, the following steps are needed\nin order to migrate your data set to Redis Cluster:</p><p>There is an alternative way to import data from external instances to a Redis\nCluster, which is to use the <code>redis-trib import</code> command.</p><p>The command moves all the keys of a running instance (deleting the keys from\nthe source instance) to the specified pre-existing Redis Cluster. However\nnote that if you use a Redis 2.8 instance as source instance the operation\nmay be slow since 2.8 does not implement migrate connection caching, so you\nmay want to restart your source instance with a Redis 3.x version before\nto perform such operation.</p>","link":"./alpha/topics/cluster-tutorial.html","spaLink":"#/alpha/topics/cluster-tutorial","title":"MIGRATING TO REDIS CLUSTER"},{"content":"<h1 id=\"redis-trademark-guidelines\">Redis TRADEMARK GUIDELINES</h1><p><strong>PURPOSE</strong>. The Redis trademark and logo identify the Redis community and individual Redis projects. This policy outlines our policy and guidelines about the use of the Redis trademarks and logo by members of the Redis development and user community.</p><p><strong>WHY HAVE TRADEMARK GUIDELINES?</strong> The Redis trademarks are a symbol of the quality and community support associated with the Redis open source software. Trademarks protect not only those using the marks, but the entire community as well. Our community members need to know that they can rely on the quality represented by the brand.  We also want to provide a level playing field.  No one should use the Redis marks in ways that mislead or take advantage of the community, or make unfair use of the trademarks. Also, use of our marks should not be in a disparaging manner because we prefer that our marks not be used to be rude about the Redis open source project or its members.    </p><p><strong>OPEN SOURCE LICENSE VS. TRADEMARKS</strong>. The three-clause BSD license gives you the right to redistribute and use the software in source and binary forms, with or without modification, under certain conditions. However, open source licenses like the three-clause BSD license do not address trademarks.  Redis trademarks and brands need to be used in a way consistent with trademark law, and that is why we have prepared this policy – to help you understand what branding is allowed or required when using our software.    </p><p><strong>PROPER USE OF THE Redis TRADEMARKS AND LOGO</strong>. We want to encourage a robust community for the Redis open source project. Therefore, you may do any of the following, as long as you do so in a way that does not devalue, dilute, or disparage the Redis brand. In other words, when you do these things, you should behave responsibly and reasonably in the interest of the community, but you do not need a trademark license from us to do them.</p><ul>\n<li>a. Nominative Use. You may engage in “nominative use” of the Redis name, but this does not allow you to use the logo.  Nominative use is sometimes called fair use of a trademark, and does not require a trademark license from us.  Here are examples:<ul>\n<li>a.i. If you develop applications for Redis, you may state that your application is designed to work with Redis, without using the Redis logo. For example, if you are developing a Foobar tool for Redis, acceptable project titles would be “Foobar for Redis” or “Redis-powered Foobar Tool”. We strongly discourage, and likely would consider it a trademark problem, to use a name such as “Redis Foobar.”  </li>\n<li>a.ii. If you offer maintenance, support, or hosting services for Redis software, you may accurately state that in your marketing materials or portfolio, without using the Redis logo.  </li>\n<li>a.iii. You may modify the Redis software and state that your modified software is “based on the Redis software” or a similar accurate statement, without using the Redis logo.</li>\n<li>a.iv. You may engage in community advocacy. The Redis software is developed by and for its community. We will allow the use of the trademarks in this context, provided:<ul>\n<li>a.iv.1. The trademark is used in a manner consistent with this policy</li>\n<li>a.iv.2. There is no commercial purpose behind the use</li>\n<li>a.iv.3. There is no suggestion that your project is approved, sponsored, or affiliated with Redis.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>b. Attribution. Identify the trademarks and logo as trademarks and logo of Redis.</li>\n<li>c. User or Development Groups. You may create Redis user or development groups, and publicize meetings or discussions for those groups.  Please consider joining our official group.</li>\n<li>d. Capitalization. “Redis” should be capitalized.</li>\n<li>e. Adjectives. Use the Redis mark as an adjective, not a noun or verb. </li>\n</ul><ul>\n<li>a.i. If you develop applications for Redis, you may state that your application is designed to work with Redis, without using the Redis logo. For example, if you are developing a Foobar tool for Redis, acceptable project titles would be “Foobar for Redis” or “Redis-powered Foobar Tool”. We strongly discourage, and likely would consider it a trademark problem, to use a name such as “Redis Foobar.”  </li>\n<li>a.ii. If you offer maintenance, support, or hosting services for Redis software, you may accurately state that in your marketing materials or portfolio, without using the Redis logo.  </li>\n<li>a.iii. You may modify the Redis software and state that your modified software is “based on the Redis software” or a similar accurate statement, without using the Redis logo.</li>\n<li>a.iv. You may engage in community advocacy. The Redis software is developed by and for its community. We will allow the use of the trademarks in this context, provided:<ul>\n<li>a.iv.1. The trademark is used in a manner consistent with this policy</li>\n<li>a.iv.2. There is no commercial purpose behind the use</li>\n<li>a.iv.3. There is no suggestion that your project is approved, sponsored, or affiliated with Redis.</li>\n</ul>\n</li>\n</ul><ul>\n<li>a.iv.1. The trademark is used in a manner consistent with this policy</li>\n<li>a.iv.2. There is no commercial purpose behind the use</li>\n<li>a.iv.3. There is no suggestion that your project is approved, sponsored, or affiliated with Redis.</li>\n</ul><p><strong>IMPROPER USE OF THE TRADEMARKS AND LOGOS</strong>. Use of the logo is reserved solely for use by Redis and its projects in its unaltered form. Examples of unauthorized use of the Redis trademarks include:</p><ul>\n<li>a. Entity Names. You may not form a company, use a company name, or create a software product name that implies any foundational or authorship role. If you have a software product that works with Redis, it is suggested you use terms such as “<code>&lt;product name&gt;</code> for Redis” or “<code>&lt;product name&gt;</code>, Redis Edition”. If you wish to form an entity for a user or developer group, please contact us and we will be glad to discuss a license for a suitable name. </li>\n<li>b. Class or Quality. You may not imply that you are providing a class or quality of Redis (e.g., “enterprise-class” or “commercial quality”) in a way that implies Redis is not of that class, grade or quality, nor that other parties are not of that class, grade, or quality. </li>\n<li>c. False or Misleading Statements. You may not make false or misleading statements regarding your use of Redis (e.g., “we wrote the majority of the code” or “we are major contributors” or “we are committers”).</li>\n<li>d. Domain Names. You must not use Redis or any confusingly similar phrase in a domain name. For instance “www.Redishost.com” is not allowed. If you wish to use such a domain name for a user or developer group, please contact us and we will be glad to discuss a license for a suitable domain name.  Because of the many persons who, unfortunately, seek to spoof, swindle or deceive the community by using confusing domain names, we must be very strict about this rule.</li>\n<li>e. Merchandise. You must not manufacture, sell or give away merchandise items, such as T-shirts and mugs, bearing the Redis logo, or create any mascot for Redis.  If you wish to use the logo to do this for a user or developer group, please contact us and we will be glad to discuss a license to do this.</li>\n<li>f. Variations, takeoffs or abbreviations. You may not use a variation of the Redis name or logo for any purpose. For example, the following are not acceptable: <ul>\n<li>f.i. Red</li>\n<li>f.ii. MyRedis</li>\n<li>f.iii. RedisHost</li>\n</ul>\n</li>\n<li>g. Endorsement or Sponsorship. You may not use the Redis logo in a manner that would imply Redis’ affiliation with or endorsement, sponsorship, or support of a product or service.</li>\n<li>h. Rebranding. You may not change the brand or logo on unmodified Redis software to your own brand or logo.  You may not hold yourself out as the source of the Redis software, except to the extent you have modified it as allowed under the three-clause BSD license, and you make it clear that you are the source only of the modification.</li>\n<li>i. Combination Marks. Do not use our logos or trademarks in combination with any other marks or logos (for example Foobar Redis, or the name of your company or product typeset to look like the Redis logo).</li>\n<li>j. Web Tags. Do not use the Redis trademark in a title or metatag of a web page to influence search engine rankings or result listings, rather than for discussion or advocacy of the Redis project.</li>\n</ul><ul>\n<li>f.i. Red</li>\n<li>f.ii. MyRedis</li>\n<li>f.iii. RedisHost</li>\n</ul><p><strong>PROPER NOTICE AND ATTRIBUTION</strong>. The appropriate trademark symbol (i.e.,  ®) should appear at least with the first use of the Redis trademarks and all occurrences of the Redis logo. When you use a Redis trademark or logo you should include a statement attributing the trademark to Salvatore Sanfilippo. For example, “Redis, and the Redis logo are the trademarks of Salvatore Sanfilippo in the U.S. and other countries.”</p><p><strong>MORE QUESTIONS?</strong> If you have questions about this policy, please contact us at <strong>antirez@gmail.com</strong>.</p>","link":"./alpha/topics/trademark.html","spaLink":"#/alpha/topics/trademark","title":"REDIS TRADEMARK GUIDELINES"},{"content":"<h1 id=\"redis-sponsors\">Redis Sponsors</h1><p>Starting from June 2015 the work <a href=\"http://twitter.com/antirez\">Salvatore Sanfilippo</a> is doing in order to develop Redis is sponsored by <a href=\"https://redislabs.com\">Redis Labs</a>.</p><p>Past sponsorships:</p><ul>\n<li>The <a href=\"http://www.shuttleworthfoundation.org\">Shuttleworth Foundation</a> donated 5000 USD to the Redis project in form of a flash grant. The details will be posted soon on a blog post documenting how the money was used.\n<img src=\"http://redis.io/images/shuttleworth.png\" alt=\"Shuttleworth Foundation\"></li>\n<li>From May 2013 to June 2015 the work <a href=\"http://twitter.com/antirez\">Salvatore Sanfilippo</a> did in order to develop Redis was sponsored by <a href=\"http://gopivotal.com\">Pivotal</a>.</li>\n<li>Before May 2013 the project was sponsored by VMware with the work of <a href=\"http://twitter.com/antirez\">Salvatore Sanfilippo</a> and <a href=\"http://twitter.com/pnoordhuis\">Pieter Noordhuis</a>.</li>\n<li><a href=\"http://vmware.com\">VMware</a> and later <a href=\"http://pivotal.io\">Pivotal</a> provided a 24 GB RAM workstation for me to run the <a href=\"http://ci.redis.io\">Redis CI test</a> and other long running tests. Later I (Salvatore) equipped the server with an SSD drive in order to test in the same hardware with rotating and flash drives.</li>\n<li><a href=\"http://linode.com\">Linode</a> 15 January 2010, provided Virtual Machines for Redis testing in a virtualized environment.</li>\n<li><a href=\"http://slicehost.com\">Slicehost</a> 14 January 2010, provided Virtual Machines for Redis testing in a virtualized environment.</li>\n<li><a href=\"http://citrusbyte.com\">Citrusbyte</a> 18 Dec 2009, part of Virtual Memory. Citrusbyte is also the company developing the Redis-rb bindings for Redis and this very web site.</li>\n<li><a href=\"http://www.hitmeister.de/\">Hitmeister</a> 15 Dec 2009, part of Redis Cluster.</li>\n<li><a href=\"http://engineyard.com\">Engine Yard</a> 13 Dec 2009, for blocking POP (BLPOP) and part of the Virtual Memory implementation.</li>\n</ul><p>Also thanks to the following people or organizations that donated to the Project:</p><ul>\n<li>Emil Vladev</li>\n<li><a href=\"http://bradjasper.com/\">Brad Jasper</a></li>\n<li><a href=\"http://www.mrkris.com/\">Mrkris</a></li>\n</ul><p>We are grateful to <a href=\"http://redislabs.com\">Redis Labs</a>, <a href=\"http://gopivotal.com\">Pivotal</a>, <a href=\"http://vmware.com\">VMware</a> and to the other companies and people that donated to the Redis project. Thank you.</p>","link":"./alpha/topics/sponsors.html","spaLink":"#/alpha/topics/sponsors","title":"REDIS SPONSORS"},{"content":"<h2 id=\"redis-sponsors-redisio\">redis.io</h2><p><a href=\"https://citrusbyte.com\">Citrusbyte</a> sponsored the creation of the official\nRedis logo (designed by <a href=\"http://carlosprioglio.com\">Carlos Prioglio</a>) and\ntransferred its copyright to Salvatore Sanfilippo.</p><p>They also sponsored the initial implementation of this site by\n<a href=\"https://twitter.com/djanowski\">Damian Janowski</a> and <a href=\"https://twitter.com/soveran\">Michel\nMartens</a>. Damian and Michel remain the current\nmaintainers.</p><p>The <code>redis.io</code> domain was donated for a few years to the project by <a href=\"https://iwantmyname.com\">I Want My\nName</a>. Now is sponsored by myself (Salvatore Sanfilippo).</p>","link":"./alpha/topics/sponsors.html","spaLink":"#/alpha/topics/sponsors","title":"REDIS.IO"},{"content":"<h1 id=\"redis-signals-handling\">Redis Signals Handling</h1><p>This document provides information about how Redis reacts to the reception\nof different POSIX signals such as <code>SIGTERM</code>, <code>SIGSEGV</code> and so forth.</p><p>The information contained in this document is <strong>only applicable to Redis version 2.6 or greater</strong>.</p>","link":"./alpha/topics/signals.html","spaLink":"#/alpha/topics/signals","title":"REDIS SIGNALS HANDLING"},{"content":"<h2 id=\"redis-signals-handling-handling-of-sigterm\">Handling of SIGTERM</h2><p>The <code>SIGTERM</code> signals tells Redis to shutdown gracefully. When this signal is\nreceived the server does not actually exits as a result, but it schedules\na shutdown very similar to the one performed when the <code>SHUTDOWN</code> command is\ncalled. The scheduled shutdown starts ASAP, specifically as long as the\ncurrent command in execution terminates (if any), with a possible additional\ndelay of 0.1 seconds or less.</p><p>In case the server is blocked by a Lua script that is taking too much time,\nif the script is killable with <code>SCRIPT KILL</code> the scheduled shutdown will be\nexecuted just after the script is killed, or if terminates spontaneously.</p><p>The Shutdown performed in this condition includes the following actions:</p><ul>\n<li>If there is a background child saving the RDB file or performing an AOF rewrite, the child is killed.</li>\n<li>If the AOF is active, Redis calls the <code>fsync</code> system call on the AOF file descriptor in order to flush the buffers on disk.</li>\n<li>If Redis is configured to persist on disk using RDB files, a synchronous (blocking) save is performed. Since the save is performed in a synchronous way no additional memory is used.</li>\n<li>If the server is daemonized, the pid file is removed.</li>\n<li>If the Unix domain socket is enabled, it gets removed.</li>\n<li>The server exits with an exit code of zero.</li>\n</ul><p>In case the RDB file can’t be saved, the shutdown fails, and the server continues to run in order to ensure no data loss. Since Redis 2.6.11 no further attempt to shut down will be made unless a new <code>SIGTERM</code> will be received or the <code>SHUTDOWN</code> command issued.</p>","link":"./alpha/topics/signals.html","spaLink":"#/alpha/topics/signals","title":"HANDLING OF SIGTERM"},{"content":"<h2 id=\"redis-signals-handling-handling-of-sigsegv-sigbus-sigfpe-and-sigill\">Handling of SIGSEGV, SIGBUS, SIGFPE and SIGILL</h2><p>The following follow signals are handled as a Redis crash:</p><ul>\n<li>SIGSEGV</li>\n<li>SIGBUS</li>\n<li>SIGFPE</li>\n<li>SIGILL</li>\n</ul><p>Once one of these signals is trapped, Redis aborts any current operation and performs the following actions:</p><ul>\n<li>A bug report is produced on the log file. This includes a stack trace, dump of registers, and information about the state of clients.</li>\n<li>Since Redis 2.8 (currently a development version) a fast memory test is performed as a first check of the reliability of the crashing system.</li>\n<li>If the server was daemonized, the pid file is removed.</li>\n<li>Finally the server unregisters its own signal handler for the received signal, and sends the same signal again to itself, in order to make sure that the default action is performed, for instance dumping the core on the file system.</li>\n</ul>","link":"./alpha/topics/signals.html","spaLink":"#/alpha/topics/signals","title":"HANDLING OF SIGSEGV, SIGBUS, SIGFPE AND SIGILL"},{"content":"<h2 id=\"redis-signals-handling-what-happens-when-a-child-process-gets-killed\">What happens when a child process gets killed</h2><p>When the child performing the Append Only File rewrite gets killed by a signal,\nRedis handles this as an error and discards the (probably partial or corrupted)\nAOF file. The rewrite will be re-triggered again later.</p><p>When the child performing an RDB save is killed Redis will handle the\ncondition as a more severe error, because while the effect of a lack of\nAOF file rewrite is a the AOF file enlargement, the effect of failed RDB file\ncreation is lack of durability.</p><p>As a result of the child producing the RDB file being killed by a signal,\nor when the child exits with an error (non zero exit code), Redis enters\na special error condition where no further write command is accepted.</p><ul>\n<li>Redis will continue to reply to read commands.</li>\n<li>Redis will reply to all write commands with a <code>MISCONFIG</code> error.</li>\n</ul><p>This error condition is cleared only once it will be possible to create\nan RDB file with success.</p>","link":"./alpha/topics/signals.html","spaLink":"#/alpha/topics/signals","title":"WHAT HAPPENS WHEN A CHILD PROCESS GETS KILLED"},{"content":"<h2 id=\"redis-signals-handling-killing-the-rdb-file-without-triggering-an-error-condition\">Killing the RDB file without triggering an error condition</h2><p>However sometimes the user may want to kill the RDB saving child without\ngenerating an error. Since Redis version 2.6.10 this can be done using the\nspecial signal <code>SIGUSR1</code> that is handled in a special way:\nit kills the child process as any other signal, but the parent process will\nnot detect this as a critical error and will continue to serve write\nrequests as usually.</p>","link":"./alpha/topics/signals.html","spaLink":"#/alpha/topics/signals","title":"KILLING THE RDB FILE WITHOUT TRIGGERING AN ERROR CONDITION"},{"content":"<h1 id=\"redis-sentinel-documentation\">Redis Sentinel Documentation</h1><p>Redis Sentinel is a system designed to help managing Redis instances.\nIt performs the following three tasks:</p><ul>\n<li><strong>Monitoring</strong>. Sentinel constantly check if your master and slave instances are working as expected.</li>\n<li><strong>Notification</strong>. Sentinel can notify the system administrator, or another computer program, via an API, that something is wrong with one of the monitored Redis instances.</li>\n<li><strong>Automatic failover</strong>. If a master is not working as expected, Sentinel can start a failover process where a slave is promoted to master, the other additional slaves are reconfigured to use the new master, and the applications using the Redis server informed about the new address to use when connecting.</li>\n</ul><p>Redis Sentinel is a distributed system, this means that usually you want to run\nmultiple Sentinel processes across your infrastructure, and this processes\nwill use agreement protocols in order to understand if a master is down and\nto perform the failover.</p><p>Redis Sentinel is shipped as a stand-alone executable called <code>redis-sentinel</code>\nbut actually it is a special execution mode of the Redis server itself, and\ncan be also invoked using the <code>--sentinel</code> option of the normal <code>redis-sever</code>\nexecutable.</p><p><strong>WARNING:</strong> Redis Sentinel is currently a work in progress. This document\ndescribes how to use what we is already implemented, and may change as the\nSentinel implementation evolves.</p><p>Redis Sentinel is compatible with Redis 2.4.16 or greater, and redis 2.6.0-rc6 or greater.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"REDIS SENTINEL DOCUMENTATION"},{"content":"<h2 id=\"redis-sentinel-documentation-obtaining-sentinel\">Obtaining Sentinel</h2><p>Currently Sentinel is part of the Redis <em>unstable</em> branch at GitHub.\nTo compile it you need to clone the <em>unstable</em> branch and compile Redis.\nYou’ll see a <code>redis-sentinel</code> executable in your <code>src</code> directory.</p><p>Alternatively you can use directly the <code>redis-server</code> executable itself,\nstarting it in Sentinel mode as specified in the next paragraph.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"OBTAINING SENTINEL"},{"content":"<h2 id=\"redis-sentinel-documentation-running-sentinel\">Running Sentinel</h2><p>If you are using the <code>redis-sentinel</code> executable (or if you have a symbolic\nlink with that name to the <code>redis-server</code> executable) you can run Sentinel\nwith the following command line:</p><p>Otherwise you can use directly the <code>redis-server</code> executable starting it in\nSentinel mode:</p><p>Both ways work the same.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"RUNNING SENTINEL"},{"content":"<h2 id=\"redis-sentinel-documentation-configuring-sentinel\">Configuring Sentinel</h2><p>The Redis source distribution contains a file called <code>sentinel.conf</code>\nthat is a self-documented example configuration file you can use to\nconfigure Sentinel, however a typical minimal configuration file looks like the\nfollowing:</p><p>The first line is used to tell Redis to monitor a master called <em>mymaster</em>,\nthat is at address 127.0.0.1 and port 6379, with a level of agreement needed\nto detect this master as failing of 2 sentinels (if the agreement is not reached\nthe automatic failover does not start).</p><p>The other options are almost always in the form:</p><p>And are used for the following purposes:</p><ul>\n<li><code>down-after-milliseconds</code> is the time in milliseconds an instance should not be reachable (either does not reply to our PINGs or it is replying with an error) for a Sentinel starting to think it is down. After this time has elapsed the Sentinel will mark an instance as <strong>subjectively down</strong> (also known as\n<code>SDOWN</code>), that is not enough to\nstart the automatic failover. However if enough instances will think that there\nis a subjectively down condition, then the instance is marked as\n<strong>objectively down</strong>. The number of sentinels that needs to agree depends on\nthe configured agreement for this master.</li>\n<li><code>can-failover</code> tells this Sentinel if it should start a failover when an\ninstance is detected as objectively down (also called <code>ODOWN</code> for simplicity).\nYou may configure all the Sentinels to perform the failover if needed, or you\nmay have a few Sentinels used only to reach the agreement, and a few more\nthat are actually in charge to perform the failover.</li>\n<li><code>parallel-syncs</code> sets the number of slaves that can be reconfigured to use\nthe new master after a failover at the same time. The lower the number, the\nmore time it will take for the failover process to complete, however if the\nslaves are configured to serve old data, you may not want all the slaves to\nresync at the same time with the new master, as while the replication process\nis mostly non blocking for a slave, there is a moment when it stops to load\nthe bulk data from the master during a resync. You may make sure only one\nslave at a time is not reachable by setting this option to the value of 1.</li>\n</ul><p>The other options are described in the rest of this document and\ndocumented in the example sentinel.conf file shipped with the Redis\ndistribution.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"CONFIGURING SENTINEL"},{"content":"<h2 id=\"redis-sentinel-documentation-sdown-and-odown\">SDOWN and ODOWN</h2><p>As already briefly mentioned in this document Redis Sentinel has two different\nconcepts of <em>being down</em>, one is called a <em>Subjectively Down</em> condition\n(SDOWN) and is a down condition that is local to a given Sentinel instance.\nAnother is called <em>Objectively Down</em> condition (ODOWN) and is reached when\nenough Sentinels (at least the number configured as the <code>quorum</code> parameter\nof the monitored master) have an SDOWN condition, and get feedback from\nother Sentinels using the <code>SENTINEL is-master-down-by-addr</code> command.</p><p>From the point of view of a Sentinel an SDOWN condition is reached if we\ndon’t receive a valid reply to PING requests for the number of seconds\nspecified in the configuration as <code>is-master-down-after-milliseconds</code>\nparameter.</p><p>An acceptable reply to PING is one of the following:</p><ul>\n<li>PING replied with +PONG.</li>\n<li>PING replied with -LOADING error.</li>\n<li>PING replied with -MASTERDOWN error.</li>\n</ul><p>Any other reply (or no reply) is considered non valid.</p><p>Note that SDOWN requires that no acceptable reply is received for the whole\ninterval configured, so for instance if the interval is 30000 milliseconds\n(30 seconds) and we receive an acceptable ping reply every 29 seconds, the\ninstance is considered to be working.</p><p>The ODOWN condition <strong>only applies to masters</strong>. For other kind of instances\nSentinel don’t require any agreement, so the ODOWN state is never reached\nfor slaves and other sentinels.</p><p>The behavior of Redis Sentinel can be described by a set of rules that every\nSentinel follows. The complete behavior of Sentinel as a distributed system\ncomposed of multiple Sentinels only results from this rules followed by\nevery single Sentinel instance. The following is the first set of rules.\nIn the course of this document more rules will be added in the appropriate\nsections.</p><p><strong>Sentinel Rule #1</strong>: Every Sentinel sends a <strong>PING</strong> request to every known master, slave, and sentinel instance, every second.</p><p><strong>Sentinel Rule #2</strong>: An instance is Subjectively Down (<strong>SDOWN</strong>) if the latest valid reply to <strong>PING</strong> was received more than <code>down-after-milliseconds</code> milliseconds ago. Acceptable PING replies are: +PONG, -LOADING, -MASTERDOWN.</p><p><strong>Sentinel Rule #3</strong>: Every Sentinel is able to reply to the command <strong>SENTINEL is-master-down-by-addr <code>&lt;ip&gt; &lt;port&gt;</code></strong>. This command replies true if the specified address is the one of a master instance, and the master is in <strong>SDOWN</strong> state.</p><p><strong>Sentinel Rule #4</strong>: If a master is in <strong>SDOWN</strong> condition, every other Sentinel also monitoring this master, is queried for confirmation of this state, every second, using the <strong>SENTINEL is-master-down-by-addr</strong> command.</p><p><strong>Sentinel Rule #5</strong>: If a master is in <strong>SDOWN</strong> condition, and enough other Sentinels (to reach the configured quorum) agree about the condition, with a reply to <strong>SENTINEL is-master-down-by-addr</strong> that is no older than five seconds, then the master is marked as Objectively Down (<strong>ODOWN</strong>).</p><p><strong>Sentinel Rule #6</strong>: Every Sentinel sends an <strong>INFO</strong> request to every known master and slave instance, one time every 10 seconds. If a master is in <strong>ODOWN</strong> condition, its slaves are asked for <strong>INFO</strong> every second instead of being asked every 10 seconds.</p><p><strong>Sentinel Rule #7</strong>: If the <strong>first</strong> INFO reply a Sentinel receives about a master shows that it is actually a slave, Sentinel will update the configuration to actually monitor the master reported by the INFO output instead. So it is safe to start Sentinel against slaves.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"SDOWN AND ODOWN"},{"content":"<h2 id=\"redis-sentinel-documentation-sentinels-and-slaves-auto-discovery\">Sentinels and Slaves auto discovery</h2><p>While Sentinels stay connected with other Sentinels in order to reciprocally\ncheck the availability of each other, and to exchange messages, you don’t\nneed to configure the other Sentinel addresses in every Sentinel instance you\nrun, as Sentinel uses the Redis master Pub/Sub capabilities in order to\ndiscover the other Sentinels that are monitoring the same master.</p><p>This is obtained by sending <em>Hello Messages</em> into the channel named\n<code>__sentinel__:hello</code>.</p><p>Similarly you don’t need to configure what is the list of the slaves attached\nto a master, as Sentinel will auto discover this list querying Redis.</p><p><strong>Sentinel Rule #8</strong>: Every Sentinel publishes a message to every monitored master Pub/Sub channel <code>__sentinel__:hello</code>, every five seconds, announcing its presence with ip, port, runid, and ability to failover (accordingly to <code>can-failover</code> configuration directive in <code>sentinel.conf</code>).</p><p><strong>Sentinel Rule #9</strong>: Every Sentinel is subscribed to the Pub/Sub channel <code>__sentinel__:hello</code> of every master, looking for unknown sentinels. When new sentinels are detected, we add them as sentinels of this master.</p><p><strong>Sentinel Rule #10</strong>: Before adding a new sentinel to a master a Sentinel always checks if there is already a sentinel with the same runid or the same address (ip and port pair). In that case all the matching sentinels are removed, and the new added.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"SENTINELS AND SLAVES AUTO DISCOVERY"},{"content":"<h1 id=\"sentinel-api\">Sentinel API</h1><p>By default Sentinel runs using TCP port 26379 (note that 6379 is the normal\nRedis port). Sentinels accept commands using the Redis protocol, so you can\nuse <code>redis-cli</code> or any other unmodified Redis client in order to talk with\nSentinel.</p><p>There are two ways to talk with Sentinel: it is possible to directly query\nit to check what is the state of the monitored Redis instances from its point\nof view, to see what other Sentinels it knows, and so forth.</p><p>An alternative is to use Pub/Sub to receive <em>push style</em> notifications from\nSentinels, every time some event happens, like a failover, or an instance\nentering an error condition, and so forth.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"SENTINEL API"},{"content":"<h2 id=\"sentinel-api-sentinel-commands\">Sentinel commands</h2><p>The following is a list of accepted commands:</p><ul>\n<li><strong>PING</strong> this command simply returns PONG.</li>\n<li><strong>SENTINEL masters</strong> show a list of monitored masters and their state.</li>\n<li><strong>SENTINEL slaves <code>&lt;master name&gt;</code></strong> show a list of slaves for this master, and their state.</li>\n<li><strong>SENTINEL is-master-down-by-addr <code>&lt;ip&gt; &lt;port&gt;</code></strong> return a two elements multi bulk reply where the first is 0 or 1 (0 if the master with that address is known and is in <code>SDOWN</code> state, 1 otherwise). The second element of the reply is the\n<em>subjective leader</em> for this master, that is, the <code>runid</code> of the Redis\nSentinel instance that should perform the failover accordingly to the queried\ninstance.</li>\n<li><strong>SENTINEL get-master-addr-by-name <code>&lt;master name&gt;</code></strong> return the ip and port number of the master with that name. If a failover is in progress or terminated successfully for this master it returns the address and port of the promoted slave.</li>\n<li><strong>SENTINEL reset <code>&lt;pattern&gt;</code></strong> this command will reset all the masters with matching name. The pattern argument is a glob-style pattern. The reset process clears any previous state in a master (including a failover in progress), and removes every slave and sentinel already discovered and associated with the master.</li>\n</ul>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"SENTINEL COMMANDS"},{"content":"<h2 id=\"sentinel-api-pubsub-messages\">Pub/Sub Messages</h2><p>A client can use a Sentinel as it was a Redis compatible Pub/Sub server\n(but you can’t use <code>PUBLISH</code>) in order to <code>SUBSCRIBE</code> or <code>PSUBSCRIBE</code> to\nchannels and get notified about specific events.</p><p>The channel name is the same as the name of the event. For instance the\nchannel named <code>+sdown</code> will receive all the notifications related to instances\nentering an <code>SDOWN</code> condition.</p><p>To get all the messages simply subscribe using <code>PSUBSCRIBE *</code>.</p><p>The following is a list of channels and message formats you can receive using\nthis API. The first word is the channel / event name, the rest is the format of the data.</p><p>Note: where <em>instance details</em> is specified it means that the following arguments are provided to identify the target instance:</p><p>The part identifying the master (from the @ argument to the end) is optional\nand is only specified if the instance is not a master itself.</p><ul>\n<li><strong>+reset-master</strong> <code>&lt;instance details&gt;</code> — The master was reset.</li>\n<li><strong>+slave</strong> <code>&lt;instance details&gt;</code> — A new slave was detected and attached.</li>\n<li><strong>+failover-state-reconf-slaves</strong> <code>&lt;instance details&gt;</code> — Failover state changed to <code>reconf-slaves</code> state.</li>\n<li><strong>+failover-detected</strong> <code>&lt;instance details&gt;</code> — A failover started by another Sentinel or any other external entity was detected (An attached slave turned into a master).</li>\n<li><strong>+slave-reconf-sent</strong> <code>&lt;instance details&gt;</code> — The leader sentinel sent the <code>SLAVEOF</code> command to this instance in order to reconfigure it for the new slave.</li>\n<li><strong>+slave-reconf-inprog</strong> <code>&lt;instance details&gt;</code> — The slave being reconfigured showed to be a slave of the new master ip:port pair, but the synchronization process is not yet complete.</li>\n<li><strong>+slave-reconf-done</strong> <code>&lt;instance details&gt;</code> — The slave is now synchronized with the new master.</li>\n<li><strong>-dup-sentinel</strong> <code>&lt;instance details&gt;</code> — One or more sentinels for the specified master were removed as duplicated (this happens for instance when a Sentinel instance is restarted).</li>\n<li><strong>+sentinel</strong> <code>&lt;instance details&gt;</code> — A new sentinel for this master was detected and attached.</li>\n<li><strong>+sdown</strong> <code>&lt;instance details&gt;</code> — The specified instance is now in Subjectively Down state.</li>\n<li><strong>-sdown</strong> <code>&lt;instance details&gt;</code> — The specified instance is no longer in Subjectively Down state.</li>\n<li><strong>+odown</strong> <code>&lt;instance details&gt;</code> — The specified instance is now in Objectively Down state.</li>\n<li><strong>-odown</strong> <code>&lt;instance details&gt;</code> — The specified instance is no longer in Objectively Down state.</li>\n<li><strong>+failover-takedown</strong> <code>&lt;instance details&gt;</code> — 25% of the configured failover timeout has elapsed, but this sentinel can’t see any progress, and is the new leader. It starts to act as the new leader reconfiguring the remaining slaves to replicate with the new master.</li>\n<li><strong>+failover-triggered</strong> <code>&lt;instance details&gt;</code> — We are starting a new failover as a the leader sentinel.</li>\n<li><strong>+failover-state-wait-start</strong> <code>&lt;instance details&gt;</code> — New failover state is <code>wait-start</code>: we are waiting a fixed number of seconds, plus a random number of seconds before starting the failover.</li>\n<li><strong>+failover-state-select-slave</strong> <code>&lt;instance details&gt;</code> — New failover state is <code>select-slave</code>: we are trying to find a suitable slave for promotion.</li>\n<li><strong>no-good-slave</strong> <code>&lt;instance details&gt;</code> — There is no good slave to promote. Currently we’ll try after some time, but probably this will change and the state machine will abort the failover at all in this case.</li>\n<li><strong>selected-slave</strong> <code>&lt;instance details&gt;</code> — We found the specified good slave to promote.</li>\n<li><strong>failover-state-send-slaveof-noone</strong> <code>&lt;instance details&gt;</code> — We are trying to reconfigure the promoted slave as master, waiting for it to switch.</li>\n<li><strong>failover-end-for-timeout</strong> <code>&lt;instance details&gt;</code> — The failover terminated for timeout. If we are the failover leader, we sent a <em>best effort</em> <code>SLAVEOF</code> command to all the slaves yet to reconfigure.</li>\n<li><strong>failover-end</strong> <code>&lt;instance details&gt;</code> — The failover terminated with success. All the slaves appears to be reconfigured to replicate with the new master.</li>\n<li><strong>switch-master</strong> <code>&lt;master name&gt; &lt;oldip&gt; &lt;oldport&gt; &lt;newip&gt; &lt;newport&gt;</code> — We are starting to monitor the new master, using the same name of the old one. The old master will be completely removed from our tables.</li>\n<li><strong>failover-abort-x-sdown</strong> <code>&lt;instance details&gt;</code> — The failover was undone (aborted) because the promoted slave appears to be in extended SDOWN state.</li>\n<li><strong>-slave-reconf-undo</strong> <code>&lt;instance details&gt;</code> — The failover aborted so we sent a <code>SLAVEOF</code> command to the specified instance to reconfigure it back to the original master instance.</li>\n<li><strong>+tilt</strong> — Tilt mode entered.</li>\n<li><strong>-tilt</strong> — Tilt mode exited.</li>\n</ul>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"PUB/SUB MESSAGES"},{"content":"<h1 id=\"sentinel-failover\">Sentinel failover</h1><p>The failover process consists on the following steps:</p><ul>\n<li>Recognize that the master is in ODOWN state.</li>\n<li>Understand who is the Sentinel that should start the failover, called <strong>The Leader</strong>. All the other Sentinels will be <strong>The Observers</strong>.</li>\n<li>The leader selects a slave to promote to master.</li>\n<li>The promoted slave is turned into a master with the command <strong>SLAVEOF NO ONE</strong>.</li>\n<li>The observers see that a slave was turned into a master, so they know the failover started. <strong>Note:</strong> this means that any event that turns one of the slaves of a monitored master into a master (<code>SLAVEOF NO ONE</code> command) will be sensed as the start of a failover process.</li>\n<li>All the other slaves attached to the original master are configured with the <strong>SLAVEOF</strong> command in order to start the replication process with the new master.</li>\n<li>The leader terminates the failover process when all the slaves are reconfigured. It removes the old master from the table of monitored masters and adds the new master, <em>under the same name</em> of the original master.</li>\n<li>The observers detect the end of the failover process when all the slaves are reconfigured. They remove the old master from the table and start monitoring the new master, exactly as the leader does.</li>\n</ul><p>The election of the Leader is performed using the same mechanism used to reach\nthe ODOWN state, that is, the <strong>SENTINEL is-master-down-by-addr</strong> command.\nIt returns the leader from the point of view of the queried Sentinel, we call\nit the <strong>Subjective Leader</strong>, and is selected using the following rule:</p><ul>\n<li>We remove all the Sentinels that can’t failover for configuration (this information is propagated using the Hello Channel to all the Sentinels).</li>\n<li>We remove all the Sentinels in SDOWN, disconnected, or with the last ping reply received more than <code>SENTINEL_INFO_VALIDITY_TIME</code> milliseconds ago (currently defined as 5 seconds).</li>\n<li>Of all the remaining instances, we get the one with the lowest <code>runid</code>, lexicographically (every Redis instance has a Run ID, that is an identifier of every single execution).</li>\n</ul><p>For a Sentinel to sense to be the <strong>Objective Leader</strong>, that is, the Sentinel that should start the failover process, the following conditions are needed.</p><ul>\n<li>It thinks it is the subjective leader itself.</li>\n<li>It receives acknowledges from other Sentinels about the fact it is the leader: at least 50% plus one of all the Sentinels that were able to reply to the <code>SENTINEL is-master-down-by-addr</code> request should agree it is the leader, and additionally we need a total level of agreement at least equal to the configured quorum of the master instance that we are going to failover.</li>\n</ul><p>Once a Sentinel things it is the Leader, the failover starts, but there is always a delay of five seconds plus an additional random delay. This is an additional layer of protection because if during this period we see another instance turning a slave into a master, we detect it as another instance staring the failover and turn ourselves into an observer instead. This is just a redundancy layer and should in theory never happen.</p><p><strong>Sentinel Rule #11</strong>: A <strong>Good Slave</strong> is a slave with the following requirements:\n<em> It is not in SDOWN nor in ODOWN condition.\n</em> We have a valid connection to it currently (not in DISCONNECTED state).\n<em> Latest PING reply we received from it is not older than five seconds.\n</em> Latest INFO reply we received from it is not older than five seconds.\n<em> The latest INFO reply reported that the link with the master is down for no more than the time elapsed since we saw the master entering SDOWN state, plus ten times the configured <code>down_after_milliseconds</code> parameter. So for instance if a Sentinel is configured to sense the SDOWN condition after 10 seconds, and the master is down since 50 seconds, we accept a slave as a Good Slave only if the replication link was disconnected less than `50+(10</em>10)` seconds (two minutes and half more or less).\n* It is not flagged as DEMOTE (see the section about resurrecting masters).</p><p><strong>Sentinel Rule #12</strong>: A <strong>Subjective Leader</strong> from the point of view of a Sentinel, is the Sentinel (including itself) with the lower runid monitoring a given master, that also replied to PING less than 5 seconds ago, reported to be able to do the failover via Pub/Sub hello channel, and is not in DISCONNECTED state.</p><p><strong>Sentinel Rule #12</strong>: If a master is down we ask <code>SENTINEL is-master-down-by-addr</code> to every other connected Sentinel as explained in Sentinel Rule #4. This command will also reply with the runid of the <strong>Subjective Leader</strong> from the point of view of the asked Sentinel. A given Sentinel believes to be the <strong>Objective Leader</strong> of a master if it is reported to be the subjective leader by N Sentinels (including itself), where:\n<em> N must be equal or greater to the configured quorum for this master.\n</em> N mast be equal or greater to the majority of the voters (<code>num_votres/2+1</code>), considering only the Sentinels that also reported the master to be down.</p><p><strong>Sentinel Rule #13</strong>: A Sentinel starts the failover as a <strong>Leader</strong> (that is, the Sentinel actually sending the commands to reconfigure the Redis servers) if the following conditions are true at the same time:\n<em> The master is in ODOWN condition.\n</em> The Sentinel is configured to perform the failover with <code>can-failover</code> set to yes.\n<em> There is at least a Good Slave from the point of view of the Sentinel.\n</em> The Sentinel believes to be the Objective Leader.\n* There is no failover in progress already detected for this master.</p><p><strong>Sentinel Rule #14</strong>: A Sentinel detects a failover as an <strong>Observer</strong> (that is, the Sentinel just follows the failover generating the appropriate events in the log file and Pub/Sub interface, but without actively reconfiguring instances) if the following conditions are true at the same time:\n<em> There is no failover already in progress.\n</em> A slave instance of the monitored master turned into a master.\nHowever the failover <strong>will NOT be sensed as started if the slave instance turns into a master and at the same time the runid has changed</strong> from the previous one. This means the instance turned into a master because of a restart, and is not a valid condition to consider it a slave election.</p><p><strong>Sentinel Rule #15</strong>: A Sentinel starting a failover as leader does not immediately starts it. It enters a state called <strong>wait-start</strong>, that lasts a random amount of time between 5 seconds and 15 seconds. During this time <strong>Sentinel Rule #14</strong> still applies: if a valid slave promotion is detected the failover as leader is aborted and the failover as observer is detected.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"SENTINEL FAILOVER"},{"content":"<h2 id=\"sentinel-failover-end-of-failover\">End of failover</h2><p>The failover process is considered terminated from the point of view of a\nsingle Sentinel if:</p><ul>\n<li>The promoted slave is not in SDOWN condition.</li>\n<li>A slave was promoted as new master.</li>\n<li>All the other slaves are configured to use the new master.</li>\n</ul><p>Note: Slaves that are in SDOWN state are ignored.</p><p>Also the failover state is considered terminate if:</p><ul>\n<li>The promoted slave is not in SDOWN condition.</li>\n<li>A slave was promoted as new master.</li>\n<li>At least <code>failover-timeout</code> milliseconds elapsed since the last progress.</li>\n</ul><p>The <code>failover-timeout</code> value can be configured in sentinel.conf for every\ndifferent slave.</p><p>Note that when a leader terminates a failover for timeout, it sends a\n<code>SLAVEOF</code> command in a best-effort way to all the slaves yet to be\nconfigured, in the hope that they’ll receive the command and replicate\nwith the new master eventually.</p><p><strong>Sentinel Rule #16</strong> A failover is considered complete if for a leader or observer if:\n<em> One slave was promoted to master (and the Sentinel can detect that this actually happened via INFO output), and all the additional slaves are all configured to replicate with the new slave (again, the sentinel needs to sense it using the INFO output).\n</em> There is already a correctly promoted slave, but the configured <code>failover-timeout</code> time has already elapsed without any progress in the reconfiguration of the additional slaves. In this case a leader sends a best effort <code>SLAVEOF</code> command is sent to all the not yet configured slaves.\nIn both the two above conditions the promoted slave <strong>must be reachable</strong> (not in SDOWN state), otherwise a failover is never considered to be complete.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"END OF FAILOVER"},{"content":"<h2 id=\"sentinel-failover-leader-failing-during-failover\">Leader failing during failover</h2><p>If the leader fails when it has yet to promote the slave into a master, and it\nfails in a way that makes it in SDOWN state from the point of view of the other\nSentinels, if enough Sentinels remained to reach the quorum the failover\nwill automatically continue using a new leader (the subjective leader of\nall the remaining Sentinels will change because of the SDOWN state of the\nprevious leader).</p><p>If the failover was already in progress and the slave\nwas already promoted, and possibly a few other slaves were already reconfigured,\nan observer that is the new objective leader will continue the failover in\ncase no progresses are made for more than 25% of the time specified by the\n<code>failover-timeout</code> configuration option.</p><p>Note that this is safe as multiple Sentinels trying to reconfigure slaves\nwith duplicated SLAVEOF commands do not create any race condition, but at the\nsame time we want to be sure that all the slaves are reconfigured in the\ncase the original leader is no longer working.</p><p><strong>Sentinel Rule #17</strong> A Sentinel that is an observer for a failover in progress\nwill turn itself into a failover leader, continuing the configuration of the\nadditional slaves, if all the following conditions are true:\n<em> A failover is in progress, and this Sentinel is an observer.\n</em> It detects to be an objective leader (so likely the previous leader is no longer reachable by other sentinels).\n* At least 25% of the configured <code>failover-timeout</code> has elapsed without any progress in the observed failover process.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"LEADER FAILING DURING FAILOVER"},{"content":"<h2 id=\"sentinel-failover-promoted-slave-failing-during-failover\">Promoted slave failing during failover</h2><p>If the promoted slave has an active SDOWN condition, a Sentinel will never\nsense the failover as terminated.</p><p>Additionally if there is an <em>extended SDOWN condition</em> (that is an SDOWN that\nlasts for more than ten times <code>down-after-milliseconds</code> milliseconds) the\nfailover is aborted (this happens for leaders and observers), and the master\nstarts to be monitored again as usually, so that a new failover can start with\na different slave in case the master is still failing.</p><p>Note that when this happens it is possible that there are a few slaves already\nconfigured to replicate from the (now failing) promoted slave, so when the\nleader sentinel aborts a failover it sends a <code>SLAVEOF</code> command to all the\nslaves already reconfigured or in the process of being reconfigured to switch\nthe configuration back to the original master.</p><p><strong>Sentinel Rule #18</strong> A Sentinel will consider the failover process aborted, both when acting as leader and when acting as an observer, in the following conditions are true:\n<em> A failover is in progress and a slave to promote was already selected (or in the case of the observer was already detected as master).\n</em> The promoted slave is in <strong>Extended SDOWN</strong> condition (continually in SDOWN condition for at least ten times the configured <code>down-after-milliseconds</code>).</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"PROMOTED SLAVE FAILING DURING FAILOVER"},{"content":"<h2 id=\"sentinel-failover-resurrecting-master\">Resurrecting master</h2><p>After the failover, at some point the old master may return back online. Starting with Redis 2.6.13 Sentinel is able to handle this condition by automatically reconfiguring the old master as a slave of the new master.</p><p>This happens in the following way:</p><ul>\n<li>After the failover has started from the point of view of a Sentinel, either as a leader, or as an observer that detected the promotion of a slave, the old master is put in the list of slaves of the new master, but with a special <code>DEMOTE</code> flag (the flag can be seen in the <code>SENTINEL SLAVES</code> command output).</li>\n<li>Once the master is back online and it is possible to contact it again, if it still claims to be a master (from INFO output) Sentinels will send a <code>SLAVEOF</code> command trying to reconfigure it. Once the instance claims to be a slave, the <code>DEMOTE</code> flag is cleared.</li>\n</ul><p>There is no single Sentinel in charge of turning the old master into a slave, so the process is resistant against failing sentinels. At the same time instances with the <code>DEMOTE</code> flag set are never selected as promotable slaves.</p><p>In this specific case the <code>+slave</code> event is only generated only when the old master will report to be actually a slave again in its <code>INFO</code> output.</p><p><strong>Sentinel Rule #19</strong>: Once the failover starts (either as observer or leader), the old master is added as a slave of the new master, flagged as <code>DEMOTE</code>.</p><p><strong>Sentinel Rule #20</strong>: A slave instance claiming to be a master, and flagged as <code>DEMOTE</code>, is reconfigured via <code>SLAVEOF</code> every time a Sentinel receives an <code>INFO</code> output where the wrong role is detected.</p><p><strong>Sentinel Rule #21</strong>: The <code>DEMOTE</code> flag is cleared as soon as an <code>INFO</code> output shows the instance to report itself as a slave.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"RESURRECTING MASTER"},{"content":"<h2 id=\"sentinel-failover-manual-interactions\">Manual interactions</h2><ul>\n<li>TODO: Manually triggering a failover with SENTINEL FAILOVER.</li>\n<li>TODO: Pausing Sentinels with SENTINEL PAUSE, RESUME.</li>\n</ul>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"MANUAL INTERACTIONS"},{"content":"<h2 id=\"sentinel-failover-the-failback-process\">The failback process</h2><ul>\n<li>TODO: Sentinel does not perform automatic Failback.</li>\n<li>TODO: Document correct steps for the failback.</li>\n</ul>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"THE FAILBACK PROCESS"},{"content":"<h2 id=\"sentinel-failover-clients-configuration-update\">Clients configuration update</h2><p>Work in progress.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"CLIENTS CONFIGURATION UPDATE"},{"content":"<h2 id=\"sentinel-failover-tilt-mode\">TILT mode</h2><p>Redis Sentinel is heavily dependent on the computer time: for instance in\norder to understand if an instance is available it remembers the time of the\nlatest successful reply to the PING command, and compares it with the current\ntime to understand how old it is.</p><p>However if the computer time changes in an unexpected way, or if the computer\nis very busy, or the process blocked for some reason, Sentinel may start to\nbehave in an unexpected way.</p><p>The TILT mode is a special “protection” mode that a Sentinel can enter when\nsomething odd is detected that can lower the reliability of the system.\nThe Sentinel timer interrupt is normally called 10 times per second, so we\nexpect that more or less 100 milliseconds will elapse between two calls\nto the timer interrupt.</p><p>What a Sentinel does is to register the previous time the timer interrupt\nwas called, and compare it with the current call: if the time difference\nis negative or unexpectedly big (2 seconds or more) the TILT mode is entered\n(or if it was already entered the exit from the TILT mode postponed).</p><p>When in TILT mode the Sentinel will continue to monitor everything, but:</p><ul>\n<li>It stops acting at all.</li>\n<li>It starts to reply negatively to <code>SENTINEL is-master-down-by-addr</code> requests as the ability to detect a failure is no longer trusted.</li>\n</ul><p>If everything appears to be normal for 30 second, the TILT mode is exited.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"TILT MODE"},{"content":"<h2 id=\"sentinel-failover-handling-of-busy-state\">Handling of -BUSY state</h2><p>(Warning: Yet not implemented)</p><p>The -BUSY error is returned when a script is running for more time than the\nconfigured script time limit. When this happens before triggering a fail over\nRedis Sentinel will try to send a “SCRIPT KILL” command, that will only\nsucceed if the script was read-only.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"HANDLING OF -BUSY STATE"},{"content":"<h2 id=\"sentinel-failover-notifications-via-user-script\">Notifications via user script</h2><p>Work in progress.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"NOTIFICATIONS VIA USER SCRIPT"},{"content":"<h2 id=\"sentinel-failover-suggested-setup\">Suggested setup</h2><p>Work in progress.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"SUGGESTED SETUP"},{"content":"<h1 id=\"appendix-a-implementation-and-algorithms\">APPENDIX A - Implementation and algorithms</h1>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"APPENDIX A - IMPLEMENTATION AND ALGORITHMS"},{"content":"<h2 id=\"appendix-a-implementation-and-algorithms-duplicate-sentinels-removal\">Duplicate Sentinels removal</h2><p>In order to reach the configured quorum we absolutely want to make sure that\nthe quorum is reached by different physical Sentinel instances. Under\nno circumstance we should get agreement from the same instance that for some\nreason appears to be two or multiple distinct Sentinel instances.</p><p>This is enforced by an aggressive removal of duplicated Sentinels: every time\na Sentinel sends a message in the Hello Pub/Sub channel with its address\nand runid, if we can’t find a perfect match (same runid and address) inside\nthe Sentinels table for that master, we remove any other Sentinel with the same\nrunid OR the same address. And later add the new Sentinel.</p><p>For instance if a Sentinel instance is restarted, the Run ID will be different,\nand the old Sentinel with the same IP address and port pair will be removed.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"DUPLICATE SENTINELS REMOVAL"},{"content":"<h2 id=\"appendix-a-implementation-and-algorithms-selection-of-the-slave-to-promote\">Selection of the Slave to promote</h2><p>If a master has multiple slaves, the slave to promote to master is selected\nchecking the slave priority (a new configuration option of Redis instances\nthat is propagated via INFO output, still not implemented), and picking the\none with lower priority value (it is an integer similar to the one of the\nMX field of the DNS system).</p><p>All the slaves that appears to be disconnected from the master for a long\ntime are discarded.</p><p>If slaves with the same priority exist, the one with the lexicographically\nsmaller Run ID is selected.</p><p>Note: because currently slave priority is not implemented, the selection is\nperformed only discarding unreachable slaves and picking the one with the\nlower Run ID.</p><p><strong>Sentinel Rule #22</strong>: A Sentinel performing the failover as leader will select the slave to promote, among the existing <strong>Good Slaves</strong> (See rule #11), taking the one with the lower slave priority. When priority is the same the slave with lexicographically lower runid is preferred.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"SELECTION OF THE SLAVE TO PROMOTE"},{"content":"<h1 id=\"appendix-b-get-started-with-sentinel-in-five-minutes\">APPENDIX B - Get started with Sentinel in five minutes</h1><p>If you want to try Redis Sentinel, please follow this steps:</p><ul>\n<li>Clone the <em>unstable</em> branch of the Redis repository at github (it is the default branch).</li>\n<li>Compile it with “make”.</li>\n<li>Start a few normal Redis instances, using the <code>redis-server</code> compiled in the <em>unstable</em> branch. One master and one slave is enough.</li>\n<li>Use the <code>redis-sentinel</code> executable to start three instances of Sentinel, with <code>redis-sentinel /path/to/config</code>.</li>\n</ul><p>To create the three configurations just create three files where you put something like that:</p><p>Note: where you see <code>port 26379</code>, use 26380 for the second Sentinel, and 26381 for the third Sentinel (any other different non colliding port will do of course). Also note that the <code>down-after-milliseconds</code> configuration option is set to just five seconds, that is a good value to play with Sentinel, but not good for production environments.</p><p>At this point you should see something like the following in every Sentinel you are running:</p><p>To see how the failover works, just put down your slave (for instance sending <code>DEBUG SEGFAULT</code> to crash it) and see what happens.</p><p>This HOWTO is a work in progress, more information will be added in the near future.</p>","link":"./alpha/topics/sentinel-old.html","spaLink":"#/alpha/topics/sentinel-old","title":"APPENDIX B - GET STARTED WITH SENTINEL IN FIVE MINUTES"},{"content":"<h1 id=\"virtual-memory\">Virtual Memory</h1><p>Redis Virtual Memory is a feature that will appear for the first time in a\nstable Redis distribution in Redis 2.0. However Virtual Memory (called VM\nstarting from now) is already available and stable enough to be tests in the\nunstable branch of Redis available <a href=\"http://github.com/antirez/redis\">on Git</a>.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"VIRTUAL MEMORY"},{"content":"<h2 id=\"virtual-memory-virtual-memory-explained-in-simple-words\">Virtual Memory explained in simple words</h2><p>Redis follows a Key-Value model. You have keys associated with some values.\nUsually Redis takes both Keys and associated Values in memory. Sometimes this\nis not the best option, and while Keys <em>must</em> be taken in memory by design\n(and in order to ensure fast lookups), Values can be swapped out to disk when\nthey are rarely used.</p><p>In practical terms this means that if you have a dataset of 100,000 keys in\nmemory, but only 10% of this keys are often used, Redis with Virtual Memory\nenabled will try to transfer the values associated to the rarely used keys on\ndisk.</p><p>When these values are requested, as a result of a command issued by a client,\nthe values are loaded back from the swap file to the main memory.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"VIRTUAL MEMORY EXPLAINED IN SIMPLE WORDS"},{"content":"<h2 id=\"virtual-memory-when-using-virtual-memory-is-a-good-idea\">When using Virtual Memory is a good idea</h2><p>Before using VM you should ask yourself if you really need it. Redis is a disk\nbacked, in memory database. The right way to use Redis is almost always to have\nenough RAM to fit all the data in memory. Still there are scenarios where this\nis not possible:</p><ul>\n<li>Data access is very biased. Only a small percentage of keys (for instance\nrelated to active users in your web site) gets the vast majority of accesses.\nAt the same time there is too much data per key to take everything in memory.</li>\n<li>There is simply not enough memory available to hold all the data in memory,\nregardless of the data access pattern, and values are large. In this\nconfiguration Redis can be used as an on-disk DB where keys are in memory, so\nthe key lookup is fast, but the access to the actual values require accessing\nthe (slower) disk.</li>\n</ul><p>An important concept to take in mind is that Redis <em>is not able to swap the\nkeys</em>, so if your memory problems are related to the fact you have too much\nkeys with very small values, VM is not the solution.</p><p>However if a good amount of memory is used because values are pretty large (for\nexample large strings, lists, sets or hashes with many elements), then VM can\nbe a good idea.</p><p>Sometimes you can turn your “many keys with small values” problem into a “few\nkeys but with very large values” one just using Hashes in order to group\nrelated data into fields of a single key. For example, instead of having a key\nfor every attribute of your object you have a single key per object where Hash\nfields represent the different attributes.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"WHEN USING VIRTUAL MEMORY IS A GOOD IDEA"},{"content":"<h2 id=\"virtual-memory-vm-configuration\">VM Configuration</h2><p>Configuring the VM is not hard but requires some care to set the best\nparameters according to the requirements.</p><p>The VM is enabled and configured by editing redis.conf, the first step is\nswitching it on with:</p><p>Many other configuration options are able to change the behavior of VM. The\nrule is that you don’t want to run with the default configuration, as every\nproblem and dataset requires some fine-tuning to get the maximum advantage.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"VM CONFIGURATION"},{"content":"<h2 id=\"virtual-memory-the-vm-max-memory-setting\">The vm-max-memory setting</h2><p>The <code>vm-max-memory</code> setting specifies how much memory Redis is free to use\nbefore starting swapping values on disk.</p><p>Basically if this memory limit is not reached, no object will be swapped,\nRedis will work with all objects in memory as usual. Once this limit is hit\nhowever, enough objects are swapped out to return the memory into just under\nthe limit.</p><p>The swapped objects are primarily the ones with the highest “age” (that is,\nthe number of seconds since they have not been used), but the “swappability” of\nan object is also proportional to the logarithm of it’s size in memory. So\nalthough older objects are preferred, bigger objects are swapped out first when\nthey are about the same age.</p><p><em>WARNING:</em> Because keys can’t be swapped out, Redis will not be able to honor\nthe <em>vm-max-memory</em> setting if the keys alone are using more space than the\nlimit.</p><p>The best value for this setting is enough RAM to hold the “working set” of data.\nIn practical terms, just give Redis as much memory as you can, and swapping will\nwork better.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"THE VM-MAX-MEMORY SETTING"},{"content":"<h2 id=\"virtual-memory-configuring-the-swap-file\">Configuring the swap file</h2><p>In order to transfer data from memory to disk, Redis uses a swap file. The swap\nfile has nothing to do with the durability of data, and can be removed when a\nRedis instance is terminated. However, the swap file should not be moved,\ndeleted, or altered in any other way while Redis is running.</p><p>Because the Redis swap file is used mostly in a random access fashion, to put\nthe swap file into a Solid State Disk will lead to better performance.</p><p>The swap file is divided into “pages”. A value can be swapped into one or\nmultiple pages, but a single page can’t hold more than a value.</p><p>There is no direct way to tell Redis how much bytes of swap file it should be\nusing. Instead two different values are configured, that when multiplied together\nwill produce the total number of bytes used. These two values are the number of\npages inside the swap file, and the page size. It is possible to configure these\ntwo parameters in redis.conf.</p><ul>\n<li>The <em>vm-pages</em> configuration directive is used to set the total number of\npages in the swap file.</li>\n<li>the <em>vm-page-size</em> configuration directive is used in order to set the page\nsize in bytes.</li>\n</ul><p>So for instance if the page size is set to the value of 32 bytes, and the total\nnumber of pages is set to 10000000 (10 million), then the swap file can hold a\ntotal of 320 MB of data.</p><p>Because a single page can’t be used to hold more than a value (but a value can\nbe stored into multiple pages), care must be taken in setting these parameters.\nUsually the best idea is setting the page size so that the majority of the\nvalues can be swapped using a few pages.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"CONFIGURING THE SWAP FILE"},{"content":"<h2 id=\"virtual-memory-threaded-vm-vs-blocking-vm\">Threaded VM vs Blocking VM</h2><p>Another very important configuration parameter is <em>vm-max-threads</em>:</p><p>This is the maximum number of threads used in order to perform I/O from/to the\nswap file. A good value is just to match the number of cores in your system.</p><p>However the special value of “0” will enable blocking VM. When VM is configured\nto be blocking it performs the I/O in a synchronous blocking way. This is what\nyou can expect from blocking VM:</p><ul>\n<li>Clients accessing swapped out keys will block other clients while reading\nfrom disk, so the latency experienced by clients can be larger, especially\nif the disk is slow or busy and/or if there are big values swapped on disk.</li>\n<li>The blocking VM performance is better <em>overall</em>, as there is no time lost\nin synchronization, spawning of threads, and resuming blocked clients waiting\nfor values. So if you are willing to accept an higher latency from time to time,\nblocking VM can be a good pick. Especially if swapping happens rarely and most\nof your often accessed data happens to fit in your memory.</li>\n</ul><p>If instead you have a lot of swap in and swap out operations and you have many\ncores that you want to exploit, and in general when you don’t want that clients\ndealing with swapped values will block other clients for a few milliseconds (or\nmore if the swapped value is very big), then it’s better to use threaded VM.</p><p>To experiment with your dataset and different configurations is warmly\nencouraged…</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"THREADED VM VS BLOCKING VM"},{"content":"<h1 id=\"random-things-to-know\">Random things to know</h1>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"RANDOM THINGS TO KNOW"},{"content":"<h2 id=\"random-things-to-know-a-good-place-for-the-swap-file\">A good place for the swap file</h2><p>In many configurations the swap file can be fairly large, amounting to 40GB or\nmore. Not all kinds of file systems are able to deal with large files in a good\nway, especially the Mac OS X file system which tends to be really lame about it.</p><p>The recommendation is to use Linux ext3 file system, or any other file system\nwith good support for <em>sparse files</em>. What are sparse files?</p><p>Sparse files are files where a lot of the content happens to be empty. Advanced\nfile systems like ext2, ext3, ext4, ReiserFS, Reiser4, and many others, are\nable to encode these files in a more efficient way and will allocate more space\nfor the file when needed, that is, when more actual blocks of the file will be\nused.</p><p>The swap file is obviously pretty sparse, especially if the server is running\nsince little time or it is much bigger compared to the amount of data swapped\nout. A file system not supporting sparse files can at some point block the\nRedis process while creating a very big file at once.</p><p>For a list of file systems supporting spare files, <a href=\"http://en.wikipedia.org/wiki/Comparison_of_file_systems\">check this check this\nWikipedia page comparing different files systems</a>.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"A GOOD PLACE FOR THE SWAP FILE"},{"content":"<h2 id=\"random-things-to-know-monitoring-the-vm\">Monitoring the VM</h2><p>Once you have a Redis system with VM enabled up and running, you may be very\ninterested to know how it’s working: how many objects are swapped in total,\nthe number of objects swapped and loaded every second, and so forth.</p><p>There is an utility that is very handy in checking how the VM is working, that\nis part of <a href=\"http://github.com/antirez/redis-tools\">Redis Tools</a>. This tool is\ncalled redis-stat, and using it is pretty straightforward:</p><p>The above output is about a redis-server with VM enabled, around 1 million of\nkeys inside, and a lot of simulated load using the redis-load utility.</p><p>As you can see from the output a number of load-in and swap-out operations are\nhappening every second. Note that the first line reports the actual values\nsince the server was started, while the next lines are differences compared to\nthe previous reading.</p><p>If you assigned enough memory to hold your working set of data, probably you\nshould see a lot less dramatic swapping happening, so redis-stat can be a\nreally valuable tool in order to understand if you need to shop for RAM ;)</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"MONITORING THE VM"},{"content":"<h2 id=\"random-things-to-know-redis-with-vm-enabled-better-rdb-files-or-append-only-file\">Redis with VM enabled: better .rdb files or Append Only File?</h2><p>When VM is enabled, saving and loading the database are <em>much slower</em>\noperations. A DB that usually loads in 2 seconds takes 13 seconds with VM\nenabled if the server is configured to use the smallest memory possible (that\nis, vm-max-memory set to 0).</p><p>So you probably want to switch to a configuration using the Append Only File\nfor persistence, so that you can perform the BGREWRITEAOF from time to time.</p><p>It is important to note that while a BGSAVE or BGREWRITEAOF is in progress\nRedis does <em>not</em> swap new values on disk. The VM will be read-only while there\nis another child accessing it. So if you have a lot of writes while there is a\nchild working, the memory usage may grow.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"REDIS WITH VM ENABLED: BETTER .RDB FILES OR APPEND ONLY FILE?"},{"content":"<h2 id=\"random-things-to-know-using-as-little-memory-as-possible\">Using as little memory as possible</h2><p>An interesting setup to turn Redis into an on-disk DB with just keys in memory\nis setting vm-max-memory to 0. If you don’t mind some latency more and poorer\nperformance but want to use very little memory for very big values, this is a\ngood setup.</p><p>In this setup you should first try setting the VM as blocking (vm-max-threads\n0) as with this configuration and high traffic the number of swap in and swap\nout operations will be huge, and threading will consume a lot of resources\ncompared to a simple blocking implementation.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"USING AS LITTLE MEMORY AS POSSIBLE"},{"content":"<h2 id=\"random-things-to-know-vm-stability\">VM Stability</h2><p>VM is still experimental code, but over the last few weeks it was tested in many\nways in development environments, and even in some production environment. No\nbugs were noticed during this testing period. Still the more obscure bugs may\nhappen in non-controlled environments where there are setups that we are not\nable to reproduce for some reason.</p><p>In this stage you are encouraged to try VM in your development environment, and\neven in production if your DB is not mission critical, but for instance just a\nbig persistent cache of data that may go away without too much problems.</p><p>Please report any problem you will notice to the Redis Google Group or by IRC\njoining the #redis IRC channel on freenode.</p>","link":"./alpha/topics/virtual-memory.html","spaLink":"#/alpha/topics/virtual-memory","title":"VM STABILITY"},{"content":"<h1 id=\"redis-sentinel-design-draft-13\">Redis Sentinel design draft 1.3</h1><p>Changelog:</p><ul>\n<li>1.0 first version.</li>\n<li>1.1 fail over steps modified: slaves are pointed to new master one after the other and not simultaneously. New section about monitoring slaves to ensure they are replicating correctly.</li>\n<li>1.2 Fixed a typo in the fail over section about: critical error is in step 5 and not 6. Added TODO section.</li>\n<li>1.3 Document updated to reflect the actual implementation of the monitoring and leader election.</li>\n</ul>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"REDIS SENTINEL DESIGN DRAFT 1.3"},{"content":"<h1 id=\"introduction\">Introduction</h1><p>Redis Sentinel is the name of the Redis high availability solution that’s\ncurrently under development. It has nothing to do with Redis Cluster and\nis intended to be used by people that don’t need Redis Cluster, but simply\na way to perform automatic fail over when a master instance is not functioning\ncorrectly.</p><p>The plan is to provide a usable beta implementation of Redis Sentinel in a\nshort time, preferably in mid July 2012.</p><p>In short this is what Redis Sentinel will be able to do:</p><ul>\n<li>Monitor master and slave instances to see if they are available.</li>\n<li>Promote a slave to master when the master fails.</li>\n<li>Modify clients configurations when a slave is elected.</li>\n<li>Inform the system administrator about incidents using notifications.</li>\n</ul><p>So the three different roles of Redis Sentinel can be summarized in the following three big aspects:</p><ul>\n<li>Monitoring.</li>\n<li>Notification.</li>\n<li>Automatic failover.</li>\n</ul><p>The following document explains what is the design of Redis Sentinel in order\nto accomplish this goals.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"INTRODUCTION"},{"content":"<h1 id=\"redis-sentinel-idea\">Redis Sentinel idea</h1><p>The idea of Redis Sentinel is to have multiple “monitoring devices” in\ndifferent places of your network, monitoring the Redis master instance.</p><p>However this independent devices can’t act without agreement with other\nsentinels.</p><p>Once a Redis master instance is detected as failing, for the failover process\nto start, the sentinel must verify that there is a given level of agreement.</p><p>The amount of sentinels, their location in the network, and the\nconfigured quorum, select the desired behavior among many possibilities.</p><p>Redis Sentinel does not use any proxy: clients reconfiguration is performed\nrunning user-provided executables (for instance a shell script or a\nPython program) in a user setup specific way.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"REDIS SENTINEL IDEA"},{"content":"<h1 id=\"in-what-form-it-will-be-shipped\">In what form it will be shipped</h1><p>Redis Sentinel is just a special mode of the redis-server executable.</p><p>If the redis-server is called with “redis-sentinel” as <code>argv[0]</code> (for instance\nusing a symbolic link or copying the file), or if —sentinel option is passed,\nthe Redis instance starts in sentinel mode and will only understand sentinel\nrelated commands. All the other commands will be refused.</p><p>The whole implementation of sentinel will live in a separated file sentinel.c\nwith minimal impact on the rest of the code base. However this solution allows\nto use all the facilities already implemented inside Redis without any need\nto reimplement them or to maintain a separated code base for Redis Sentinel.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"IN WHAT FORM IT WILL BE SHIPPED"},{"content":"<h1 id=\"sentinels-networking\">Sentinels networking</h1><p>All the sentinels take persistent connections with:</p><ul>\n<li>The monitored masters.</li>\n<li>All its slaves, that are discovered using the master’s INFO output.</li>\n<li>All the other Sentinels connected to this master, discovered via Pub/Sub.</li>\n</ul><p>Sentinels use the Redis protocol to talk with each other, and to reply to\nexternal clients.</p><p>Redis Sentinels export a SENTINEL command. Subcommands of the SENTINEL\ncommand are used in order to perform different actions.</p><p>For instance the <code>SENTINEL masters</code> command enumerates all the monitored\nmasters and their states. However Sentinels can also reply to the PING command\nas a normal Redis instance, so that it is possible to monitor a Sentinel\nconsidering it a normal Redis instance.</p><p>The list of networking tasks performed by every sentinel is the following:</p><ul>\n<li>A Sentinel PUBLISH its presence using the master Pub/Sub multiple times every five seconds.</li>\n<li>A Sentinel accepts commands using a TCP port. By default the port is 26379.</li>\n<li>A Sentinel constantly monitors masters, slaves, other sentinels sending PING commands.</li>\n<li>A Sentinel sends INFO commands to the masters and slaves every ten seconds in order to take a fresh list of connected slaves, the state of the master, and so forth.</li>\n<li>A Sentinel monitors the sentinel Pub/Sub “hello” channel in order to discover newly connected Sentinels, or to detect no longer connected Sentinels. The channel used is <code>__sentinel__:hello</code>.</li>\n</ul>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"SENTINELS NETWORKING"},{"content":"<h1 id=\"sentinels-discovering\">Sentinels discovering</h1><p>To make the configuration of sentinels as simple as possible every sentinel\nbroadcasts its presence using the Redis master Pub/Sub functionality.</p><p>Every sentinel is subscribed to the same channel, and broadcast information\nabout its existence to the same channel, including the Run ID of the Sentinel,\nand the IP address and port where it is listening for commands.</p><p>Every sentinel maintains a list of other sentinels Run ID, IP and port.\nA sentinel that does no longer announce its presence using Pub/Sub for too\nlong time is removed from the list, assuming the Master appears to be working well. In that case a notification is delivered to the system administrator.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"SENTINELS DISCOVERING"},{"content":"<h1 id=\"detection-of-failing-masters\">Detection of failing masters</h1><p>An instance is not available from the point of view of Redis Sentinel when\nit is no longer able to reply to the PING command correctly for longer than\nthe specified number of seconds, consecutively.</p><p>For a PING reply to be considered valid, one of the following conditions\nshould be true:</p><ul>\n<li>PING replied with +PONG.</li>\n<li>PING replied with -LOADING error.</li>\n<li>PING replied with -MASTERDOWN error.</li>\n</ul><p>What is not considered an acceptable reply:</p><ul>\n<li>PING replied with -BUSY error.</li>\n<li>PING replied with -MISCONF error.</li>\n<li>PING reply not received after more than a specified number of milliseconds.</li>\n</ul><p>PING should never reply with a different error code than the ones listed above\nbut any other error code is considered an acceptable reply by Redis Sentinel.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"DETECTION OF FAILING MASTERS"},{"content":"<h1 id=\"handling-of-busy-state\">Handling of -BUSY state</h1><p>The -BUSY error is returned when a script is running for more time than the\nconfigured script time limit. When this happens before triggering a fail over\nRedis Sentinel will try to send a “SCRIPT KILL” command, that will only\nsucceed if the script was read-only.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"HANDLING OF -BUSY STATE"},{"content":"<h1 id=\"subjectively-down-and-objectively-down\">Subjectively down and Objectively down</h1><p>From the point of view of a Sentinel there are two different error conditions for a master:</p><ul>\n<li><em>Subjectively Down</em> (aka <code>S_DOWN</code>) means that a master is down from the point of view of a Sentinel.</li>\n<li><em>Objectively Down</em> (aka <code>O_DOWN</code>) means that a master is subjectively down from the point of view of enough Sentinels to reach the configured quorum for that master.</li>\n</ul>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"SUBJECTIVELY DOWN AND OBJECTIVELY DOWN"},{"content":"<h1 id=\"how-sentinels-agree-to-mark-a-master-o_down\">How Sentinels agree to mark a master <code>O_DOWN</code>.</h1><p>Once a Sentinel detects that a master is in <code>S_DOWN</code> condition it starts to\nsend other sentinels a <code>SENTINEL is-master-down-by-addr</code> request every second.\nThe reply is stored inside the state that every Sentinel takes in memory.</p><p>Ten times every second a Sentinel scans the state and checks if there are\nenough Sentinels thinking that a master is down (this is not specific for\nthis operation, most state checks are performed with this frequency).</p><p>If this Sentinel has already an <code>S_DOWN</code> condition for this master, and there\nare enough other sentinels that recently reported this condition\n(the validity time is currently set to 5 seconds), then the master is marked\nas <code>O_DOWN</code> (Objectively Down).</p><p>Note that the <code>O_DOWN</code> state is not propagated among Sentinels. Every single\nSentinel can reach independently this state.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"HOW SENTINELS AGREE TO MARK A MASTER O_DOWN."},{"content":"<h1 id=\"the-sentinel-is-master-down-by-addr-command\">The SENTINEL is-master-down-by-addr command</h1><p>Sentinels ask other Sentinels for the state of a master from their local point\nof view using the <code>SENTINEL is-master-down-by-addr</code> command. This command\nreplies with a boolean value (in the form of a 0 or 1 integer reply, as\na first element of a multi bulk reply).</p><p>However in order to avoid false positives, the command acts in the following\nway:</p><ul>\n<li>If the specified ip and port is not known, 0 is returned.</li>\n<li>If the specified ip and port are found but don’t belong to a Master instance, 0 is returned.</li>\n<li>If the Sentinel is in TILT mode (see later in this document) 0 is returned.</li>\n<li>The value of 1 is returned only if the instance is known, is a master, is flagged <code>S_DOWN</code> and the Sentinel is in TILT mode.</li>\n</ul>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"THE SENTINEL IS-MASTER-DOWN-BY-ADDR COMMAND"},{"content":"<h1 id=\"duplicate-sentinels-removal\">Duplicate Sentinels removal</h1><p>In order to reach the configured quorum we absolutely want to make sure that\nthe quorum is reached by different physical Sentinel instances. Under\nno circumstance we should get agreement from the same instance that for some\nreason appears to be two or multiple distinct Sentinel instances.</p><p>This is enforced by an aggressive removal of duplicated Sentinels: every time\na Sentinel sends a message in the Hello Pub/Sub channel with its address\nand runid, if we can’t find a perfect match (same runid and address) inside\nthe Sentinels table for that master, we remove any other Sentinel with the same\nrunid OR the same address. And later add the new Sentinel.</p><p>For instance if a Sentinel instance is restarted, the Run ID will be different,\nand the old Sentinel with the same IP address and port pair will be removed.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"DUPLICATE SENTINELS REMOVAL"},{"content":"<h1 id=\"starting-the-failover-leaders-and-observers\">Starting the failover: Leaders and Observers</h1><p>The fact that a master is marked as <code>O_DOWN</code> is not enough to star the\nfailover process. What Sentinel should start the failover is also to be\ndecided.</p><p>Also Sentinels can be configured in two ways: only as monitors that can’t\nperform the fail over, or as Sentinels that can start the failover.</p><p>What is desirable is that only a Sentinel will start the failover process,\nand this Sentinel should be selected among the Sentinels that are allowed\nto perform the failover.</p><p>In Sentinel there are two roles during a fail over:</p><ul>\n<li>The Leader Sentinel is the one selected to perform the failover.</li>\n<li>The Observers Sentinels are the other sentinels just following the failover process without doing active operations.</li>\n</ul><p>So the condition to start the failover is:</p><ul>\n<li>A Master in <code>O_DOWN</code> condition.</li>\n<li>A Sentinel that is elected Leader.</li>\n</ul>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"STARTING THE FAILOVER: LEADERS AND OBSERVERS"},{"content":"<h1 id=\"leader-sentinel-election\">Leader Sentinel election</h1><p>The election process works as follows:</p><ul>\n<li>Every Sentinel with a master in <code>O_DOWN</code> condition updates its internal state with frequency of 10 HZ to refresh what is the <em>Subjective Leader</em> from its point of view.</li>\n</ul><p>A Subjective Leader is selected in this way by every sentinel.</p><ul>\n<li>Every Sentinel we know about a given master, that is reachable (no <code>S_DOWN</code> state), that is allowed to perform the failover (this Sentinel-specific configuration is propagated using the Hello channel), is a possible candidate.</li>\n<li>Among all the possible candidates, the one with lexicographically smaller Run ID is selected.</li>\n</ul><p>Every time a Sentinel replies with to the <code>MASTER is-sentinel-down-by-addr</code> command it also replies with the Run ID of its Subjective Leader.</p><p>Every Sentinel with a failing master (<code>O_DOWN</code>) checks its subjective leader\nand the subjective leaders of all the other Sentinels with a frequency of\n10 HZ, and will flag itself as the Leader if the following conditions happen:</p><ul>\n<li>It is the Subjective Leader of itself.</li>\n<li>At least N-1 other Sentinels that see the master as down, and are reachable, also think that it is the Leader. With N being the quorum configured for this master.</li>\n<li>At least 50% + 1 of all the Sentinels involved in the voting process (that are reachable and that also see the master as failing) should agree on the Leader.</li>\n</ul><p>So for instance if there are a total of three sentinels, the master is failing,\nand all the three sentinels are able to communicate (no Sentinel is failing)\nand the configured quorum for this master is 2, a Sentinel will feel itself\nan Objective Leader if at least it and another Sentinel is agreeing that\nit is the subjective leader.</p><p>Once a Sentinel detects that it is the objective leader, it flags the master\nwith <code>FAILOVER_IN_PROGRESS</code> and <code>IM_THE_LEADER</code> flags, and starts the failover\nprocess in <code>SENTINEL_FAILOVER_DELAY</code> (5 seconds currently) plus a random\nadditional time between 0 milliseconds and 10000 milliseconds.</p><p>During that time we ask INFO to all the slaves with an increased frequency\nof one time per second (usually the period is 10 seconds). If a slave is\nturned into a master in the meantime the failover is suspended and the\nLeader clears the <code>IM_THE_LEADER</code> flag to turn itself into an observer.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"LEADER SENTINEL ELECTION"},{"content":"<h1 id=\"guarantees-of-the-leader-election-process\">Guarantees of the Leader election process</h1><p>As you can see for a Sentinel to become a leader the majority is not strictly\nrequired. A user can force the majority to be needed just setting the master\nquorum to, for instance, the value of 5 if there are a total of 9 sentinels.</p><p>However it is also possible to set the quorum to the value of 2 with 9\nsentinels in order to improve the resistance to netsplits or failing Sentinels\nor other error conditions. In such a case the protection against race\nconditions (multiple Sentinels starting to perform the fail over at the same\ntime) is given by the random delay used to start the fail over, and the\ncontinuous monitor of the slave instances to detect if another Sentinel\n(or a human) started the failover process.</p><p>Moreover the slave to promote is selected using a deterministic process to\nminimize the chance that two different Sentinels with full vision of the\nworking slaves may pick two different slaves to promote.</p><p>However it is possible to easily imagine netsplits and specific configurations\nwhere two Sentinels may start to act as a leader at the same time, electing two\ndifferent slaves as masters, in two different parts of the net that can’t\ncommunicate. The Redis Sentinel user should evaluate the network topology and\nselect an appropriate quorum considering his or her goals and the different\ntrade offs.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"GUARANTEES OF THE LEADER ELECTION PROCESS"},{"content":"<h1 id=\"how-observers-understand-that-the-failover-started\">How observers understand that the failover started</h1><p>An observer is just a Sentinel that does not believe to be the Leader, but\nstill sees a master in <code>O_DOWN</code> condition.</p><p>The observer is still able to follow and update the internal state based on\nwhat is happening with the failover, but does not directly rely on the\nLeader to communicate with it to be informed by progresses. It simply observes\nthe state of the slaves to understand what is happening.</p><p>Specifically the observers flags the master as <code>FAILOVER_IN_PROGRESS</code> if a slave\nattached to a master turns into a master (observers can see it in the INFO output). An observer will also consider the failover complete once all the other\nreachable slaves appear to be slaves of this slave that was turned into a\nmaster.</p><p>If a Slave is in <code>FAILOVER_IN_PROGRESS</code> and the failover is not progressing for\ntoo much time, and at the same time the other Sentinels start claiming that\nthis Sentinel is the objective leader (because for example the old leader\nis no longer reachable), the Sentinel will flag itself as <code>IM_THE_LEADER</code> and\nwill proceed with the failover.</p><p>Note: all the Sentinel state, including the subjective and objective leadership\nis a dynamic process that is continuously refreshed with period of 10 HZ.\nThere is no “one time decision” step in Sentinel.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"HOW OBSERVERS UNDERSTAND THAT THE FAILOVER STARTED"},{"content":"<h1 id=\"selection-of-the-slave-to-promote\">Selection of the Slave to promote</h1><p>If a master has multiple slaves, the slave to promote to master is selected\nchecking the slave priority (a new configuration option of Redis instances\nthat is propagated via INFO output), and picking the one with lower priority\nvalue (it is an integer similar to the one of the MX field of the DNS system).\nAll the slaves that appears to be disconnected from the master for a long\ntime are discarded (stale data).</p><p>If slaves with the same priority exist, the one with the lexicographically\nsmaller Run ID is selected.</p><p>If there is no Slave to select because all the salves are failing the failover\nis not started at all. Instead if there is no Slave to select because the\nmaster <em>never</em> used to have slaves in the monitoring session, then the\nfailover is performed nonetheless just calling the user scripts.\nHowever for this to happen a special configuration option must be set for\nthat master (force-failover-without-slaves).</p><p>This is useful because there are configurations where a new Instance can be\nprovisioned at IP protocol level by the script, but there are no attached\nslaves.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"SELECTION OF THE SLAVE TO PROMOTE"},{"content":"<h1 id=\"fail-over-process\">Fail over process</h1><p>The fail over process consists of the following steps:</p><ul>\n<li>1) Turn the selected slave into a master using the SLAVEOF NO ONE command.</li>\n<li>2) Turn all the remaining slaves, if any, to slaves of the new master. This is done incrementally, one slave after the other, waiting for the previous slave to complete the synchronization process before starting with the next one.</li>\n<li>3) Call a user script to inform the clients that the configuration changed.</li>\n<li>4) Completely remove the old failing master from the table, and add the new master with the same name.</li>\n</ul><p>If Steps “1” fails, the fail over is aborted.</p><p>All the other errors are considered to be non-fatal.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"FAIL OVER PROCESS"},{"content":"<h1 id=\"tilt-mode\">TILT mode</h1><p>Redis Sentinel is heavily dependent on the computer time: for instance in\norder to understand if an instance is available it remembers the time of the\nlatest successful reply to the PING command, and compares it with the current\ntime to understand how old it is.</p><p>However if the computer time changes in an unexpected way, or if the computer\nis very busy, or the process blocked for some reason, Sentinel may start to\nbehave in an unexpected way.</p><p>The TILT mode is a special “protection” mode that a Sentinel can enter when\nsomething odd is detected that can lower the reliability of the system.\nThe Sentinel timer interrupt is normally called 10 times per second, so we\nexpect that more or less 100 milliseconds will elapse between two calls\nto the timer interrupt.</p><p>What a Sentinel does is to register the previous time the timer interrupt\nwas called, and compare it with the current call: if the time difference\nis negative or unexpectedly big (2 seconds or more) the TILT mode is entered\n(or if it was already entered the exit from the TILT mode postponed).</p><p>When in TILT mode the Sentinel will continue to monitor everything, but:</p><ul>\n<li>It stops acting at all.</li>\n<li>It starts to reply negatively to <code>SENTINEL is-master-down-by-addr</code> requests as the ability to detect a failure is no longer trusted.</li>\n</ul><p>If everything appears to be normal for 30 second, the TILT mode is exited.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"TILT MODE"},{"content":"<h1 id=\"sentinels-monitoring-other-sentinels\">Sentinels monitoring other sentinels</h1><p>When a sentinel no longer advertises itself using the Pub/Sub channel for too\nmuch time (30 minutes more the configured timeout for the master), but at the\nsame time the master appears to work correctly, the Sentinel is removed from\nthe table of Sentinels for this master, and a notification is sent to the\nsystem administrator. </p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"SENTINELS MONITORING OTHER SENTINELS"},{"content":"<h1 id=\"user-provided-scripts\">User provided scripts</h1><p>Sentinels can optionally call user-provided scripts to perform two tasks:</p><ul>\n<li>Inform clients that the configuration changed.</li>\n<li>Notify the system administrator of problems.</li>\n</ul><p>The script to inform clients of a configuration change has the following parameters:</p><ul>\n<li>ip:port of the calling Sentinel.</li>\n<li>old master ip:port.</li>\n<li>new master ip:port.</li>\n</ul><p>The script to send notifications is called with the following parameters:</p><ul>\n<li>ip:port of the calling Sentinel.</li>\n<li>The message to deliver to the system administrator is passed writing to the standard input.</li>\n</ul><p>Using the ip:port of the calling sentinel, scripts may call SENTINEL subcommands\nto get more info if needed.</p><p>Concrete implementations of notification scripts will likely use the “mail”\ncommand or some other command to deliver SMS messages, emails, tweets.</p><p>Implementations of the script to modify the configuration in web applications\nare likely to use HTTP GET requests to force clients to update the\nconfiguration, or any other sensible mechanism for the specific setup in use.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"USER PROVIDED SCRIPTS"},{"content":"<h1 id=\"setup-examples\">Setup examples</h1><p>Imaginary setup:</p><p>In this naive configuration it is possible to place a single sentinel, with\n“minimal agreement” set to the value of one (no acknowledge from other\nsentinels needed), running on “B”.</p><p>If “A” will fail the fail over process will start, the slave will be elected\nto master, and the client software will be reconfigured.</p><p>Imaginary setup:</p><p>In this setup it is possible to run five sentinels placed at C,D,E,F,G with\n“minimal agreement” set to 3.</p><p>In real production environments there is to evaluate how the different\ncomputers are networked together, and to check what happens during net splits\nin order to select where to place the sentinels, and the level of minimal\nagreement, so that a single arm of the network failing will not trigger a\nfail over.</p><p>In general if a complex network topology is present, the minimal agreement\nshould be set to the max number of sentinels existing at the same time in\nthe same network arm, plus one.</p>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"SETUP EXAMPLES"},{"content":"<h1 id=\"sentinel-subcommands\">SENTINEL SUBCOMMANDS</h1><ul>\n<li><code>SENTINEL masters</code>, provides a list of configured masters.</li>\n<li><code>SENTINEL slaves &lt;master name&gt;</code>, provides a list of slaves for the master with the specified name.</li>\n<li><code>SENTINEL sentinels &lt;master name&gt;</code>, provides a list of sentinels for the master with the specified name.</li>\n<li><code>SENTINEL is-master-down-by-addr &lt;ip&gt; &lt;port&gt;</code>, returns a two elements multi bulk reply where the first element is :0 or :1, and the second is the Subjective Leader for the failover.</li>\n</ul>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"SENTINEL SUBCOMMANDS"},{"content":"<h1 id=\"todo\">TODO</h1><ul>\n<li>More detailed specification of user script error handling, including what return codes may mean, like 0: try again. 1: fatal error. 2: try again, and so forth.</li>\n<li>More detailed specification of what happens when a user script does not return in a given amount of time.</li>\n<li>Add a “push” notification system for configuration changes.</li>\n<li>Document that for every master monitored the configuration specifies a name for the master that is reported by all the SENTINEL commands.</li>\n<li>Make clear that we handle a single Sentinel monitoring multiple masters.</li>\n</ul>","link":"./alpha/topics/sentinel-spec.html","spaLink":"#/alpha/topics/sentinel-spec","title":"TODO"},{"content":"<h1 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store\">Tutorial: Design and implementation of a simple Twitter clone using PHP and the Redis key-value store</h1><p>This article describes the design and implementation of a <a href=\"https://github.com/antirez/retwis\">very simple Twitter clone</a> written using PHP with Redis as the only database. The programming community has traditionally considered key-value stores as a special purpose database that couldn’t be used as a drop in replacement for a relational database for the development of web applications. This article will try to show that Redis data structures on top of a key-value layer are an effective data model to implement many kinds of applications.</p><p>Before to continue, you may want to play a few seconds with <a href=\"http://retwis.redis.io\">the Retwis online demo</a>, to check what we are going to actually\nmodel. Long story short: it is a toy, but complex enough to be a foundation\nin order to learn how to create more complex applications.</p><p>Note: the original version of this article was written in 2009 when Redis was\nreleased. It was not exactly clear at the time that the Redis data model was\nsuitable to write entire applications. Now after 5 years there are many cases of\napplications using Redis as their main store, so the goal of the article today\nis to be a tutorial for Redis newcomers. You’ll learn how to design a simple\ndata layout using Redis, and how to apply different data structures.</p><p>Our Twitter clone, called <a href=\"http://retwis.antirez.com\">Retwis</a>, is structurally simple, has very good performance, and can be distributed among any number of web and Redis servers with little efforts. You can find the source code <a href=\"http://code.google.com/p/redis/downloads/list\">here</a>.</p><p>I use PHP for the example since it can be read by everybody. The same (or better) results can be obtained using Ruby, Python, Erlang, and so on.\nA few clones exist (however not all the clones use the same data layout as the\ncurrent version of this tutorial, so please, stick with the official PHP\nimplementation for the sake of following the article better).</p><ul>\n<li><a href=\"http://retwisrb.danlucraft.com/\">Retwis-RB</a> is a port of Retwis to Ruby and Sinatra written by Daniel Lucraft! Full source code is included of course, and a link to its Git repository appears in the footer of this article. The rest of this article targets PHP, but Ruby programmers can also check the Retwis-RB source code since it’s conceptually very similar.</li>\n<li><a href=\"http://retwisj.cloudfoundry.com/\">Retwis-J</a> is a port of Retwis to Java, using the Spring Data Framework, written by <a href=\"http://twitter.com/costinl\">Costin Leau</a>. Its source code can be found on <a href=\"https://github.com/SpringSource/spring-data-keyvalue-examples\">GitHub</a>, and there is comprehensive documentation available at <a href=\"http://j.mp/eo6z6I\">springsource.org</a>.</li>\n</ul>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"TUTORIAL: DESIGN AND IMPLEMENTATION OF A SIMPLE TWITTER CLONE USING PHP AND THE REDIS KEY-VALUE STORE"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-what-is-a-key-value-store\">What is a Key-value store?</h2><p>The essence of a key-value store is the ability to store some data, called a <em>value</em>, inside a key. The value can be retrieved later only if we know the specific key it was stored in. There is no direct way to search for a key by value. In a sense, it is like a very large hash/dictionary, but it is persistent, i.e. when your application ends, the data doesn’t go away. So, for example, I can use the command <code>SET</code> to store the value <em>bar</em> in the key <em>foo</em>:</p><p>Redis stores data permanently, so if I later ask “<em>What is the value stored in key foo?</em>“ Redis will reply with <em>bar</em>:</p><p>Other common operations provided by key-value stores are <code>DEL</code>, to delete a given key and its associated value, SET-if-not-exists (called <code>SETNX</code> on Redis), to assign a value to a key only if the key does not already exist, and <code>INCR</code>, to atomically increment a number stored in a given key:</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"WHAT IS A KEY-VALUE STORE?"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-atomic-operations\">Atomic operations</h2><p>There is something special about <code>INCR</code>. Think about why Redis provides such an operation if we can do it ourselves with a bit of code? After all, it is as simple as:</p><p>The problem is that incrementing this way will work as long as there is only one client working with the key <em>foo</em> at one time. See what happens if two clients are accessing this key at the same time:</p><p>Something is wrong! We incremented the value two times, but instead of going from 10 to 12, our key holds 11. This is because the increment done with <code>GET / increment / SET</code> <em>is not an atomic operation</em>. Instead the INCR provided by Redis, Memcached, …, are atomic implementations, and the server will take care of protecting the key during the time needed to complete the increment in order to prevent simultaneous accesses.</p><p>What makes Redis different from other key-value stores is that it provides other operations similar to INCR that can be used to model complex problems. This is why you can use Redis to write whole web applications without using another database like an SQL database, and without going crazy.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"ATOMIC OPERATIONS"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-beyond-key-value-stores-lists\">Beyond key-value stores: lists</h2><p>In this section we will see which Redis features we need to build our Twitter clone. The first thing to know is that Redis values can be more than strings. Redis supports Lists, Sets, Hashes, Sorted Sets, Bitmaps, and HyperLogLog types as values, and there are atomic operations to operate on them so we are safe even with multiple accesses to the same key. Let’s start with Lists:</p><p><code>LPUSH</code> means <em>Left Push</em>, that is, add an element to the left (or to the head) of the list stored in <em>mylist</em>. If the key <em>mylist</em> does not exist it is automatically created as an empty list before the PUSH operation. As you can imagine, there is also an <code>RPUSH</code> operation that adds the element to the right of the list (on the tail). This is very useful for our Twitter clone. User updates can be added to a list stored in <code>username:updates</code>, for instance.</p><p>There are operations to get data from Lists, of course. For instance, LRANGE returns a range from the list, or the whole list.</p><p>LRANGE uses zero-based indexes - that is the first element is 0, the second 1, and so on. The command arguments are <code>LRANGE key first-index last-index</code>. The <em>last-index</em> argument can be negative, with a special meaning: -1 is the last element of the list, -2 the penultimate, and so on. So, to get the whole list use:</p><p>Other important operations are LLEN that returns the number of elements in the list, and LTRIM that is like LRANGE but instead of returning the specified range <em>trims</em> the list, so it is like <em>Get range from mylist, Set this range as new value</em> but does so atomically.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"BEYOND KEY-VALUE STORES: LISTS"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-the-set-data-type\">The Set data type</h2><p>Currently we don’t use the Set type in this tutorial, but since we use\nSorted Sets, which are kind of a more capable version of Sets, it is better\nto start introducing Sets first (which are a very useful data structure\nper se), and later Sorted Sets.</p><p>There are more data types than just Lists. Redis also supports Sets, which are unsorted collections of elements. It is possible to add, remove, and test for existence of members, and perform the intersection between different Sets. Of course it is possible to get the elements of a set. Some examples will make it more clear. Keep in mind that <code>SADD</code> is the <em>add to set</em> operation, <code>SREM</code> is the <em>remove from set</em> operation, <em>sismember</em> is the <em>test if member</em> operation, and <code>SINTER</code> is the <em>perform intersection</em> operation. Other operations are <code>SCARD</code> to get the cardinality (the number of elements) of a Set, and <code>SMEMBERS</code> to return all the members of a Set.</p><p>Note that <code>SMEMBERS</code> does not return the elements in the same order we added them since Sets are <em>unsorted</em> collections of elements. When you want to store in order it is better to use Lists instead. Some more operations against Sets:</p><p><code>SINTER</code> can return the intersection between Sets but it is not limited to two sets. You may ask for the intersection of 4,5, or 10000 Sets. Finally let’s check how SISMEMBER works:</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"THE SET DATA TYPE"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-the-sorted-set-data-type\">The Sorted Set data type</h2><p>Sorted Sets are similar to Sets: collection of elements. However in Sorted\nSets each element is associated with a floating point value, called the\n<em>element score</em>. Because of the score, elements inside a sorted set are\nordered, since we can always compare two elements by score (and if the score\nhappens to be the same, we compare the two elements as strings).</p><p>Like Sets in Sorted Sets it is not possible to add repeated elements, every\nelement is unique. However it is possible to update an element’s score.</p><p>Sorted Set commands are prefixed with <code>Z</code>. The following is an example\nof Sorted Sets usage:</p><p>In the above example we added a few elements with <code>ZADD</code>, and later retrieved\nthe elements with <code>ZRANGE</code>. As you can see the elements are returned in order\naccording to their score. In order to check if a given element exists, and\nalso to retrieve its score if it exists, we use the <code>ZSCORE</code> command:</p><p>Sorted Sets are a very powerful data structure, you can query elements by\nscore range, lexicographically, in reverse order, and so forth.\nTo know more <a href=\"http://redis.io/commands/#sorted_set\">please check the Sorted Set sections in the official Redis commands documentation</a>.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"THE SORTED SET DATA TYPE"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-the-hash-data-type\">The Hash data type</h2><p>This is the last data structure we use in our program, and is extremely easy\nto gasp since there is an equivalent in almost every programming language out\nthere: Hashes. Redis Hashes are basically like Ruby or Python hashes, a\ncollection of fields associated with values:</p><p><code>HMSET</code> can be used to set fields in the hash, that can be retrieved with\n<code>HGET</code> later. It is possible to check if a field exists with <code>HEXISTS</code>, or\nto increment a hash field with <code>HINCRBY</code> and so forth.</p><p>Hashes are the ideal data structure to represent <em>objects</em>. For example we\nuse Hashes in order to represent Users and Updates in our Twitter clone.</p><p>Okay, we just exposed the basics of the Redis main data structures,\nwe are ready to start coding!</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"THE HASH DATA TYPE"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-prerequisites\">Prerequisites</h2><p>If you haven’t downloaded the <a href=\"https://github.com/antirez/retwis\">Retwis source code</a> already please grab it now. It contains a few PHP files, and also a copy of <a href=\"https://github.com/nrk/predis\">Predis</a>, the PHP client library we use in this example.</p><p>Another thing you probably want is a working Redis server. Just get the source, build with make, run with ./redis-server, and you’re ready to go. No configuration is required at all in order to play with or run Retwis on your computer.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"PREREQUISITES"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-data-layout\">Data layout</h2><p>When working with a relational database, a database schema must be designed so that we’d know the tables, indexes, and so on that the database will contain. We don’t have tables in Redis, so what do we need to design? We need to identify what keys are needed to represent our objects and what kind of values this keys need to hold.</p><p>Let’s start with Users. We need to represent users, of course, with their username, userid, password, the set of users following a given user, the set of users a given user follows, and so on. The first question is, how should we identify a user? Like in a relational DB, a good solution is to identify different users with different numbers, so we can associate a unique ID with every user. Every other reference to this user will be done by id. Creating unique IDs is very simple to do by using our atomic <code>INCR</code> operation. When we create a new user we can do something like this, assuming the user is called “antirez”:</p><p><em>Note: you should use a hashed password in a real application, for simplicity\nwe store the password in clear text.</em></p><p>We use the <code>next_user_id</code> key in order to always get an unique ID for every new user. Then we use this unique ID to name the key holding a Hash with user’s data. <em>This is a common design pattern</em> with key-values stores! Keep it in mind.\nBesides the fields already defined, we need some more stuff in order to fully define a User. For example, sometimes it can be useful to be able to get the user ID from the username, so every time we add an user, we also populate the <code>users</code> key, which is a Hash, with the username as field, and its ID as value.</p><p>This may appear strange at first, but remember that we are only able to access data in a direct way, without secondary indexes. It’s not possible to tell Redis to return the key that holds a specific value. This is also <em>our strength</em>. This new paradigm is forcing us to organize data so that everything is accessible by <em>primary key</em>, speaking in relational DB terms.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"DATA LAYOUT"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-followers-following-and-updates\">Followers, following, and updates</h2><p>There is another central need in our system. A user might have users who follow them, which we’ll call their followers. A user might follow other users, which we’ll call a following. We have a perfect data structure for this. That is… Sets.\nThe uniqueness of Sets elements, and the fact we can test in constant time for\nexistence, are two interesting features. However what about also remembering\nthe time at which a given user started following another one? In an enhanced\nversion of our simple Twitter clone this may be useful, so instead of using\na simple Set, we use a Sorted Set, using the user ID of the following or follower\nuser as element, and the unix time at which the relation between the users\nwas created, as our score.</p><p>So let’s define our keys:</p><p>We can add new followers with:</p><p>Another important thing we need is a place were we can add the updates to display in the user’s home page. We’ll need to access this data in chronological order later, from the most recent update to the oldest, so the perfect kind of data structure for this is a List. Basically every new update will be <code>LPUSH</code>ed in the user updates key, and thanks to <code>LRANGE</code>, we can implement pagination and so on. Note that we use the words <em>updates</em> and <em>posts</em> interchangeably, since updates are actually “little posts” in some way.</p><p>This list is basically the User timeline. We’ll push the IDs of her/his own\nposts, and, the IDs of all the posts of created by the following users.\nBasically we implement a write fanout.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"FOLLOWERS, FOLLOWING, AND UPDATES"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-authentication\">Authentication</h2><p>OK, we have more or less everything about the user except for authentication. We’ll handle authentication in a simple but robust way: we don’t want to use PHP sessions, our system must be ready to be distributed among different web servers easily, so we’ll keep the whole state in our Redis database. All we need is a random <strong>unguessable</strong> string to set as the cookie of an authenticated user, and a key that will contain the user ID of the client holding the string.</p><p>We need two things in order to make this thing work in a robust way.\nFirst: the current authentication <em>secret</em> (the random unguessable string)\nshould be part of the User object, so when the user is created we also set\nan <code>auth</code> field in its Hash:</p><p>Moreover, we need a way to map authentication secrets to user IDs, so\nwe also take an <code>auths</code> key, which has as value a Hash type mapping\nauthentication secrets to user IDs.</p><p>In order to authenticate a user we’ll do these simple steps ( see the <code>login.php</code> file in the Retwis source code):</p><ul>\n<li>Get the username and password via the login form</li>\n<li>Check if the <code>username</code> field actually exists in the <code>users</code> Hash.</li>\n<li>If it exists we have the user id, (i.e. 1000)</li>\n<li>Check if user:1000 password matches, if not, return an error message</li>\n<li>Ok authenticated! Set “fea5e81ac8ca77622bed1c2132a021f9” (the value of user:1000 <code>auth</code> field) as the “auth” cookie.</li>\n</ul><p>This is the actual code:</p><p>This happens every time a user logs in, but we also need a function <code>isLoggedIn</code> in order to check if a given user is already authenticated or not. These are the logical steps preformed by the <code>isLoggedIn</code> function:</p><ul>\n<li>Get the “auth” cookie from the user. If there is no cookie, the user is not logged in, of course. Let’s call the value of the cookie <code>&lt;authcookie&gt;</code></li>\n<li>Check if <code>&lt;authcookie&gt;</code> field in the <code>auths</code> Hash exists, and what the value (the user ID) is (1000 in the example).</li>\n<li>In order for the system to be more robust, also verify that user:1000 auth field also matches.</li>\n<li>OK the user is authenticated, and we loaded a bit of information in the $User global variable.</li>\n</ul><p>The code is simpler than the description, possibly:</p><p>Having <code>loadUserInfo</code> as a separate function is overkill for our application, but it’s a good approach in a complex application. The only thing that’s missing from all the authentication is the logout. What do we do on logout? That’s simple, we’ll just change the random string in user:1000 <code>auth</code> field, remove the old authentication secret from the <code>auths</code> Hash., and add the new one.</p><p><em>Important:</em> the logout procedure explains why we don’t just authenticate the user after looking up the authentication secret in the <code>auths</code> Hash, but double check it against user:1000 <code>auth</code> field. The true authentication string is the latter, while the <code>auths</code> Hash is just an authentication field that may even be volatile, or, if there are bugs in the program or a script gets interrupted, we may even end with multiple entries in the <code>auths</code> key pointing to the same user ID. The logout code is the following (logout.php):</p><p>That is just what we described and should be simple to understand.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"AUTHENTICATION"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-updates\">Updates</h2><p>Updates, also known as posts, are even simpler. In order to create a new post in the database we do something like this:</p><p>As you can see each post is just represented by a Hash with three fields. The ID of the user owning the post, the time at which the post was published, and finally the body of the post, which is, the actual status message.</p><p>After we create a post and we obtain the post ID, we need to LPUSH the ID in the timeline of every user that is following the author of the post, and of course in the list of posts of the author itself (everybody is virtually following herself/himself). This is the file <code>post.php</code> that shows how this is performed:</p><p>The core of the function is the <code>foreach</code> loop. We use <code>ZRANGE</code> to get all the followers of the current user, then the loop will LPUSH the push the post in every follower timeline List.</p><p>Note that we also maintain a global timeline for all the posts, so that in the Retwis home page we can show everybody’s updates easily. This requires just doing an <code>LPUSH</code> to the <code>timeline</code> List. Let’s face it, aren’t you starting to think it was a bit strange to have to sort things added in chronological order using <code>ORDER BY</code> with SQL? I think so.</p><p>There is an interesting thing to notice in the code above: we use a new\ncommand called <code>LTRIM</code> after we perform the <code>LPUSH</code> operation in the global\ntimeline. This is used in order to trim the list to just 1000 elements. The\nglobal timeline is actually only used in order to show a few posts in the\nhome page, there is no need to have the full history of all the posts.</p><p>Basically <code>LTRIM</code> + <code>LPUSH</code> is a way to create a <em>capped collection</em> in Redis.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"UPDATES"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-paginating-updates\">Paginating updates</h2><p>Now it should be pretty clear how we can use <code>LRANGE</code> in order to get ranges of posts, and render these posts on the screen. The code is simple:</p><p><code>showPost</code> will simply convert and print a Post in HTML while <code>showUserPosts</code> gets a range of posts and then passes them to <code>showPosts</code>.</p><p><em>Note: <code>LRANGE</code> is not very efficient if the list of posts start to be very\nbig, and we want to access elements which are in the middle of the list, since Redis Lists are backed by linked lists. If a system is designed for\ndeep pagination of million of items, it is better to resort to Sorted Sets\ninstead.</em></p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"PAGINATING UPDATES"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-following-users\">Following users</h2><p>It is not hard, but we did not yet check how we create following / follower relationships. If user ID 1000 (antirez) wants to follow user ID 5000 (pippo), we need to create both a following and a follower relationship. We just need to <code>ZADD</code> calls:</p><p>Note the same pattern again and again. In theory with a relational database the list of following and followers would be contained in a single table with fields like <code>following_id</code> and <code>follower_id</code>. You can extract the followers or following of every user using an SQL query. With a key-value DB things are a bit different since we need to set both the <code>1000 is following 5000</code> and <code>5000 is followed by 1000</code> relations. This is the price to pay, but on the other hand accessing the data is simpler and extremely fast. Having these things as separate sets allows us to do interesting stuff. For example, using <code>ZINTERSTORE</code> we can have the intersection of ‘following’ of two different users, so we may add a feature to our Twitter clone so that it is able to tell you very quickly when you visit somebody else’s profile, “you and Alice have 34 followers in common”, and things like that.</p><p>You can find the code that sets or removes a following / follower relation in the <code>follow.php</code> file.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"FOLLOWING USERS"},{"content":"<h2 id=\"tutorial-design-and-implementation-of-a-simple-twitter-clone-using-php-and-the-redis-key-value-store-making-it-horizontally-scalable\">Making it horizontally scalable</h2><p>Gentle reader, if you reached this point you are already a hero. Thank you. Before talking about scaling horizontally it is worth checking performance on a single server. Retwis is <em>extremely fast</em>, without any kind of cache. On a very slow and loaded server, an Apache benchmark with 100 parallel clients issuing 100000 requests measured the average pageview to take 5 milliseconds. This means you can serve millions of users every day with just a single Linux box, and this one was monkey ass slow… Imagine the results with more recent hardware.</p><p>However you can’t go with a single server forever, how do you scale a key-value\nstore?</p><p>Retwis does not perform any multi-keys operation, so making it scalable is\nsimple: you may use client-side sharding, or something like a sharding proxy\nlike Twemproxy, or the upcoming Redis Cluster.</p><p>To know more about those topics please read\n<a href=\"/topics/partitioning\">our documentation about sharding</a>. However here the point\nto stress is that in a key-value store, if you design with care, the data set\nis split among <strong>many independent small keys</strong>. To distribute those keys\nto multiple nodes is more straightforward and predictable compared to using\na semantically more complex database system.</p>","link":"./alpha/topics/twitter-clone.html","spaLink":"#/alpha/topics/twitter-clone","title":"MAKING IT HORIZONTALLY SCALABLE"}]